Training started...
=> creating model 'FRAB_SDMP' with backbone 'resnet50_encoder'
FRAB(
  loss_weight=0.5, mask_type=attn, num_proto=64, teacher_temp=0.07, loss_w_obj=0.02, loss_w_cluster=0.5
  (online_net): EncoderObj(
    (backbone): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (avgpool): Identity()
    )
    (neck): ObjectNeck(
      scale=1.0, l2_norm=True, num_heads=8
      (proj): MLP1D(
        (mlp): Sequential(
          (0): Conv1d(2048, 4096, kernel_size=(1,), stride=(1,), bias=False)
          (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv1d(4096, 256, kernel_size=(1,), stride=(1,), bias=False)
        )
      )
      (proj_pixel): MLP1D(
        (mlp): Sequential(
          (0): Conv1d(2048, 4096, kernel_size=(1,), stride=(1,), bias=False)
          (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv1d(4096, 256, kernel_size=(1,), stride=(1,), bias=False)
        )
      )
      (proj_obj): MLP1D(
        (mlp): Sequential(
          (0): Conv1d(2048, 4096, kernel_size=(1,), stride=(1,), bias=False)
          (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv1d(4096, 256, kernel_size=(1,), stride=(1,), bias=False)
        )
      )
      (proj_attn): TransformerPredictor(
        (pe_layer): PositionEmbeddingSine()
        (transformer): Transformer(
          (encoder): TransformerEncoder(
            (layers): ModuleList()
          )
          (decoder): TransformerDecoder(
            (layers): ModuleList(
              (0-1): 2 x TransformerDecoderLayer(
                (self_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (multihead_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (linear1): Linear(in_features=256, out_features=256, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (linear2): Linear(in_features=256, out_features=256, bias=True)
                (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (dropout2): Dropout(p=0.1, inplace=False)
                (dropout3): Dropout(p=0.1, inplace=False)
              )
            )
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (query_embed): Embedding(64, 256)
        (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
        (mask_embed): MLP(
          (layers): ModuleList(
            (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
          )
        )
      )
      (heatmap_projection): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (target_net): EncoderObj(
    (backbone): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (avgpool): Identity()
    )
    (neck): ObjectNeck(
      scale=1.0, l2_norm=True, num_heads=8
      (proj): MLP1D(
        (mlp): Sequential(
          (0): Conv1d(2048, 4096, kernel_size=(1,), stride=(1,), bias=False)
          (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv1d(4096, 256, kernel_size=(1,), stride=(1,), bias=False)
        )
      )
      (proj_pixel): MLP1D(
        (mlp): Sequential(
          (0): Conv1d(2048, 4096, kernel_size=(1,), stride=(1,), bias=False)
          (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv1d(4096, 256, kernel_size=(1,), stride=(1,), bias=False)
        )
      )
      (proj_obj): MLP1D(
        (mlp): Sequential(
          (0): Conv1d(2048, 4096, kernel_size=(1,), stride=(1,), bias=False)
          (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv1d(4096, 256, kernel_size=(1,), stride=(1,), bias=False)
        )
      )
      (proj_attn): TransformerPredictor(
        (pe_layer): PositionEmbeddingSine()
        (transformer): Transformer(
          (encoder): TransformerEncoder(
            (layers): ModuleList()
          )
          (decoder): TransformerDecoder(
            (layers): ModuleList(
              (0-1): 2 x TransformerDecoderLayer(
                (self_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (multihead_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (linear1): Linear(in_features=256, out_features=256, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
                (linear2): Linear(in_features=256, out_features=256, bias=True)
                (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
                (dropout1): Dropout(p=0.1, inplace=False)
                (dropout2): Dropout(p=0.1, inplace=False)
                (dropout3): Dropout(p=0.1, inplace=False)
              )
            )
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (query_embed): Embedding(64, 256)
        (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
        (mask_embed): MLP(
          (layers): ModuleList(
            (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
          )
        )
      )
      (heatmap_projection): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (predictor): MLP1D(
    (mlp): Sequential(
      (0): Conv1d(256, 4096, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv1d(4096, 256, kernel_size=(1,), stride=(1,), bias=False)
    )
  )
  (predictor_obj): MLP1D(
    (mlp): Sequential(
      (0): Conv1d(256, 4096, kernel_size=(1,), stride=(1,), bias=False)
      (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv1d(4096, 256, kernel_size=(1,), stride=(1,), bias=False)
    )
  )
  (encoder_q): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): Identity()
  )
)
{'dataset': 'vggface2', 'data_root': 'data/Pre-training/VGGFace2', 'arch': 'FRAB_SDMP', 'backbone': 'resnet50_encoder', 'workers': 8, 'epochs': 1, 'start_epoch': 0, 'warmup_epoch': 0, 'batch_size': 64, 'lr': 1.8, 'schedule': [120, 160], 'cos': True, 'momentum': 0.9, 'weight_decay': 1.5e-06, 'save_dir': 'ckpts', 'save_filename_with_suffix': 'pretraining_sdmp_mixup', 'print_freq': 1, 'save_freq': 1, 'eval_freq': 1, 'resume': '', 'pretrained': '', 'super_pretrained': '', 'evaluate': False, 'seed': 23456, 'proj_dim': 256, 'enc_m': 0.996, 'norm': None, 'num_neck_mlp': 2, 'hid_dim': 4096, 'amp': True, 'lewel_l2_norm': True, 'lewel_scale': 1.0, 'lewel_num_heads': 8, 'lewel_loss_weight': 0.5, 'train_percent': 1.0, 'mask_type': 'attn', 'num_proto': 64, 'teacher_temp': 0.07, 'loss_w_cluster': 0.5, 'num_nn': 20, 'nn_mem_percent': 0.1, 'nn_query_percent': 0.5, 'gpu': 'cuda', 'generate_multi_scale_heatmaps': False}
weight params:
online_net.backbone.conv1.weight
online_net.backbone.layer1.0.conv1.weight
online_net.backbone.layer1.0.conv2.weight
online_net.backbone.layer1.0.conv3.weight
online_net.backbone.layer1.0.downsample.0.weight
online_net.backbone.layer1.1.conv1.weight
online_net.backbone.layer1.1.conv2.weight
online_net.backbone.layer1.1.conv3.weight
online_net.backbone.layer1.2.conv1.weight
online_net.backbone.layer1.2.conv2.weight
online_net.backbone.layer1.2.conv3.weight
online_net.backbone.layer2.0.conv1.weight
online_net.backbone.layer2.0.conv2.weight
online_net.backbone.layer2.0.conv3.weight
online_net.backbone.layer2.0.downsample.0.weight
online_net.backbone.layer2.1.conv1.weight
online_net.backbone.layer2.1.conv2.weight
online_net.backbone.layer2.1.conv3.weight
online_net.backbone.layer2.2.conv1.weight
online_net.backbone.layer2.2.conv2.weight
online_net.backbone.layer2.2.conv3.weight
online_net.backbone.layer2.3.conv1.weight
online_net.backbone.layer2.3.conv2.weight
online_net.backbone.layer2.3.conv3.weight
online_net.backbone.layer3.0.conv1.weight
online_net.backbone.layer3.0.conv2.weight
online_net.backbone.layer3.0.conv3.weight
online_net.backbone.layer3.0.downsample.0.weight
online_net.backbone.layer3.1.conv1.weight
online_net.backbone.layer3.1.conv2.weight
online_net.backbone.layer3.1.conv3.weight
online_net.backbone.layer3.2.conv1.weight
online_net.backbone.layer3.2.conv2.weight
online_net.backbone.layer3.2.conv3.weight
online_net.backbone.layer3.3.conv1.weight
online_net.backbone.layer3.3.conv2.weight
online_net.backbone.layer3.3.conv3.weight
online_net.backbone.layer3.4.conv1.weight
online_net.backbone.layer3.4.conv2.weight
online_net.backbone.layer3.4.conv3.weight
online_net.backbone.layer3.5.conv1.weight
online_net.backbone.layer3.5.conv2.weight
online_net.backbone.layer3.5.conv3.weight
online_net.backbone.layer4.0.conv1.weight
online_net.backbone.layer4.0.conv2.weight
online_net.backbone.layer4.0.conv3.weight
online_net.backbone.layer4.0.downsample.0.weight
online_net.backbone.layer4.1.conv1.weight
online_net.backbone.layer4.1.conv2.weight
online_net.backbone.layer4.1.conv3.weight
online_net.backbone.layer4.2.conv1.weight
online_net.backbone.layer4.2.conv2.weight
online_net.backbone.layer4.2.conv3.weight
online_net.neck.proj.mlp.0.weight
online_net.neck.proj.mlp.1.weight
online_net.neck.proj.mlp.3.weight
online_net.neck.proj_pixel.mlp.0.weight
online_net.neck.proj_pixel.mlp.1.weight
online_net.neck.proj_pixel.mlp.3.weight
online_net.neck.proj_obj.mlp.0.weight
online_net.neck.proj_obj.mlp.1.weight
online_net.neck.proj_obj.mlp.3.weight
online_net.neck.proj_attn.transformer.decoder.layers.0.self_attn.in_proj_weight
online_net.neck.proj_attn.transformer.decoder.layers.0.self_attn.out_proj.weight
online_net.neck.proj_attn.transformer.decoder.layers.0.multihead_attn.in_proj_weight
online_net.neck.proj_attn.transformer.decoder.layers.0.multihead_attn.out_proj.weight
online_net.neck.proj_attn.transformer.decoder.layers.0.linear1.weight
online_net.neck.proj_attn.transformer.decoder.layers.0.linear2.weight
online_net.neck.proj_attn.transformer.decoder.layers.0.norm1.weight
online_net.neck.proj_attn.transformer.decoder.layers.0.norm2.weight
online_net.neck.proj_attn.transformer.decoder.layers.0.norm3.weight
online_net.neck.proj_attn.transformer.decoder.layers.1.self_attn.in_proj_weight
online_net.neck.proj_attn.transformer.decoder.layers.1.self_attn.out_proj.weight
online_net.neck.proj_attn.transformer.decoder.layers.1.multihead_attn.in_proj_weight
online_net.neck.proj_attn.transformer.decoder.layers.1.multihead_attn.out_proj.weight
online_net.neck.proj_attn.transformer.decoder.layers.1.linear1.weight
online_net.neck.proj_attn.transformer.decoder.layers.1.linear2.weight
online_net.neck.proj_attn.transformer.decoder.layers.1.norm1.weight
online_net.neck.proj_attn.transformer.decoder.layers.1.norm2.weight
online_net.neck.proj_attn.transformer.decoder.layers.1.norm3.weight
online_net.neck.proj_attn.transformer.decoder.norm.weight
online_net.neck.proj_attn.query_embed.weight
online_net.neck.proj_attn.input_proj.weight
online_net.neck.proj_attn.mask_embed.layers.0.weight
online_net.neck.proj_attn.mask_embed.layers.1.weight
online_net.neck.proj_attn.mask_embed.layers.2.weight
online_net.neck.heatmap_projection.weight
target_net.backbone.conv1.weight
target_net.backbone.layer1.0.conv1.weight
target_net.backbone.layer1.0.conv2.weight
target_net.backbone.layer1.0.conv3.weight
target_net.backbone.layer1.0.downsample.0.weight
target_net.backbone.layer1.1.conv1.weight
target_net.backbone.layer1.1.conv2.weight
target_net.backbone.layer1.1.conv3.weight
target_net.backbone.layer1.2.conv1.weight
target_net.backbone.layer1.2.conv2.weight
target_net.backbone.layer1.2.conv3.weight
target_net.backbone.layer2.0.conv1.weight
target_net.backbone.layer2.0.conv2.weight
target_net.backbone.layer2.0.conv3.weight
target_net.backbone.layer2.0.downsample.0.weight
target_net.backbone.layer2.1.conv1.weight
target_net.backbone.layer2.1.conv2.weight
target_net.backbone.layer2.1.conv3.weight
target_net.backbone.layer2.2.conv1.weight
target_net.backbone.layer2.2.conv2.weight
target_net.backbone.layer2.2.conv3.weight
target_net.backbone.layer2.3.conv1.weight
target_net.backbone.layer2.3.conv2.weight
target_net.backbone.layer2.3.conv3.weight
target_net.backbone.layer3.0.conv1.weight
target_net.backbone.layer3.0.conv2.weight
target_net.backbone.layer3.0.conv3.weight
target_net.backbone.layer3.0.downsample.0.weight
target_net.backbone.layer3.1.conv1.weight
target_net.backbone.layer3.1.conv2.weight
target_net.backbone.layer3.1.conv3.weight
target_net.backbone.layer3.2.conv1.weight
target_net.backbone.layer3.2.conv2.weight
target_net.backbone.layer3.2.conv3.weight
target_net.backbone.layer3.3.conv1.weight
target_net.backbone.layer3.3.conv2.weight
target_net.backbone.layer3.3.conv3.weight
target_net.backbone.layer3.4.conv1.weight
target_net.backbone.layer3.4.conv2.weight
target_net.backbone.layer3.4.conv3.weight
target_net.backbone.layer3.5.conv1.weight
target_net.backbone.layer3.5.conv2.weight
target_net.backbone.layer3.5.conv3.weight
target_net.backbone.layer4.0.conv1.weight
target_net.backbone.layer4.0.conv2.weight
target_net.backbone.layer4.0.conv3.weight
target_net.backbone.layer4.0.downsample.0.weight
target_net.backbone.layer4.1.conv1.weight
target_net.backbone.layer4.1.conv2.weight
target_net.backbone.layer4.1.conv3.weight
target_net.backbone.layer4.2.conv1.weight
target_net.backbone.layer4.2.conv2.weight
target_net.backbone.layer4.2.conv3.weight
target_net.neck.proj.mlp.0.weight
target_net.neck.proj.mlp.1.weight
target_net.neck.proj.mlp.3.weight
target_net.neck.proj_pixel.mlp.0.weight
target_net.neck.proj_pixel.mlp.1.weight
target_net.neck.proj_pixel.mlp.3.weight
target_net.neck.proj_obj.mlp.0.weight
target_net.neck.proj_obj.mlp.1.weight
target_net.neck.proj_obj.mlp.3.weight
target_net.neck.proj_attn.transformer.decoder.layers.0.self_attn.in_proj_weight
target_net.neck.proj_attn.transformer.decoder.layers.0.self_attn.out_proj.weight
target_net.neck.proj_attn.transformer.decoder.layers.0.multihead_attn.in_proj_weight
target_net.neck.proj_attn.transformer.decoder.layers.0.multihead_attn.out_proj.weight
target_net.neck.proj_attn.transformer.decoder.layers.0.linear1.weight
target_net.neck.proj_attn.transformer.decoder.layers.0.linear2.weight
target_net.neck.proj_attn.transformer.decoder.layers.0.norm1.weight
target_net.neck.proj_attn.transformer.decoder.layers.0.norm2.weight
target_net.neck.proj_attn.transformer.decoder.layers.0.norm3.weight
target_net.neck.proj_attn.transformer.decoder.layers.1.self_attn.in_proj_weight
target_net.neck.proj_attn.transformer.decoder.layers.1.self_attn.out_proj.weight
target_net.neck.proj_attn.transformer.decoder.layers.1.multihead_attn.in_proj_weight
target_net.neck.proj_attn.transformer.decoder.layers.1.multihead_attn.out_proj.weight
target_net.neck.proj_attn.transformer.decoder.layers.1.linear1.weight
target_net.neck.proj_attn.transformer.decoder.layers.1.linear2.weight
target_net.neck.proj_attn.transformer.decoder.layers.1.norm1.weight
target_net.neck.proj_attn.transformer.decoder.layers.1.norm2.weight
target_net.neck.proj_attn.transformer.decoder.layers.1.norm3.weight
target_net.neck.proj_attn.transformer.decoder.norm.weight
target_net.neck.proj_attn.query_embed.weight
target_net.neck.proj_attn.input_proj.weight
target_net.neck.proj_attn.mask_embed.layers.0.weight
target_net.neck.proj_attn.mask_embed.layers.1.weight
target_net.neck.proj_attn.mask_embed.layers.2.weight
target_net.neck.heatmap_projection.weight
predictor.mlp.0.weight
predictor.mlp.1.weight
predictor.mlp.3.weight
predictor_obj.mlp.0.weight
predictor_obj.mlp.1.weight
predictor_obj.mlp.3.weight
bn and bias params:
online_net.backbone.bn1.weight
online_net.backbone.bn1.bias
online_net.backbone.layer1.0.bn1.weight
online_net.backbone.layer1.0.bn1.bias
online_net.backbone.layer1.0.bn2.weight
online_net.backbone.layer1.0.bn2.bias
online_net.backbone.layer1.0.bn3.weight
online_net.backbone.layer1.0.bn3.bias
online_net.backbone.layer1.0.downsample.1.weight
online_net.backbone.layer1.0.downsample.1.bias
online_net.backbone.layer1.1.bn1.weight
online_net.backbone.layer1.1.bn1.bias
online_net.backbone.layer1.1.bn2.weight
online_net.backbone.layer1.1.bn2.bias
online_net.backbone.layer1.1.bn3.weight
online_net.backbone.layer1.1.bn3.bias
online_net.backbone.layer1.2.bn1.weight
online_net.backbone.layer1.2.bn1.bias
online_net.backbone.layer1.2.bn2.weight
online_net.backbone.layer1.2.bn2.bias
online_net.backbone.layer1.2.bn3.weight
online_net.backbone.layer1.2.bn3.bias
online_net.backbone.layer2.0.bn1.weight
online_net.backbone.layer2.0.bn1.bias
online_net.backbone.layer2.0.bn2.weight
online_net.backbone.layer2.0.bn2.bias
online_net.backbone.layer2.0.bn3.weight
online_net.backbone.layer2.0.bn3.bias
online_net.backbone.layer2.0.downsample.1.weight
online_net.backbone.layer2.0.downsample.1.bias
online_net.backbone.layer2.1.bn1.weight
online_net.backbone.layer2.1.bn1.bias
online_net.backbone.layer2.1.bn2.weight
online_net.backbone.layer2.1.bn2.bias
online_net.backbone.layer2.1.bn3.weight
online_net.backbone.layer2.1.bn3.bias
online_net.backbone.layer2.2.bn1.weight
online_net.backbone.layer2.2.bn1.bias
online_net.backbone.layer2.2.bn2.weight
online_net.backbone.layer2.2.bn2.bias
online_net.backbone.layer2.2.bn3.weight
online_net.backbone.layer2.2.bn3.bias
online_net.backbone.layer2.3.bn1.weight
online_net.backbone.layer2.3.bn1.bias
online_net.backbone.layer2.3.bn2.weight
online_net.backbone.layer2.3.bn2.bias
online_net.backbone.layer2.3.bn3.weight
online_net.backbone.layer2.3.bn3.bias
online_net.backbone.layer3.0.bn1.weight
online_net.backbone.layer3.0.bn1.bias
online_net.backbone.layer3.0.bn2.weight
online_net.backbone.layer3.0.bn2.bias
online_net.backbone.layer3.0.bn3.weight
online_net.backbone.layer3.0.bn3.bias
online_net.backbone.layer3.0.downsample.1.weight
online_net.backbone.layer3.0.downsample.1.bias
online_net.backbone.layer3.1.bn1.weight
online_net.backbone.layer3.1.bn1.bias
online_net.backbone.layer3.1.bn2.weight
online_net.backbone.layer3.1.bn2.bias
online_net.backbone.layer3.1.bn3.weight
online_net.backbone.layer3.1.bn3.bias
online_net.backbone.layer3.2.bn1.weight
online_net.backbone.layer3.2.bn1.bias
online_net.backbone.layer3.2.bn2.weight
online_net.backbone.layer3.2.bn2.bias
online_net.backbone.layer3.2.bn3.weight
online_net.backbone.layer3.2.bn3.bias
online_net.backbone.layer3.3.bn1.weight
online_net.backbone.layer3.3.bn1.bias
online_net.backbone.layer3.3.bn2.weight
online_net.backbone.layer3.3.bn2.bias
online_net.backbone.layer3.3.bn3.weight
online_net.backbone.layer3.3.bn3.bias
online_net.backbone.layer3.4.bn1.weight
online_net.backbone.layer3.4.bn1.bias
online_net.backbone.layer3.4.bn2.weight
online_net.backbone.layer3.4.bn2.bias
online_net.backbone.layer3.4.bn3.weight
online_net.backbone.layer3.4.bn3.bias
online_net.backbone.layer3.5.bn1.weight
online_net.backbone.layer3.5.bn1.bias
online_net.backbone.layer3.5.bn2.weight
online_net.backbone.layer3.5.bn2.bias
online_net.backbone.layer3.5.bn3.weight
online_net.backbone.layer3.5.bn3.bias
online_net.backbone.layer4.0.bn1.weight
online_net.backbone.layer4.0.bn1.bias
online_net.backbone.layer4.0.bn2.weight
online_net.backbone.layer4.0.bn2.bias
online_net.backbone.layer4.0.bn3.weight
online_net.backbone.layer4.0.bn3.bias
online_net.backbone.layer4.0.downsample.1.weight
online_net.backbone.layer4.0.downsample.1.bias
online_net.backbone.layer4.1.bn1.weight
online_net.backbone.layer4.1.bn1.bias
online_net.backbone.layer4.1.bn2.weight
online_net.backbone.layer4.1.bn2.bias
online_net.backbone.layer4.1.bn3.weight
online_net.backbone.layer4.1.bn3.bias
online_net.backbone.layer4.2.bn1.weight
online_net.backbone.layer4.2.bn1.bias
online_net.backbone.layer4.2.bn2.weight
online_net.backbone.layer4.2.bn2.bias
online_net.backbone.layer4.2.bn3.weight
online_net.backbone.layer4.2.bn3.bias
online_net.neck.proj.mlp.1.bias
online_net.neck.proj_pixel.mlp.1.bias
online_net.neck.proj_obj.mlp.1.bias
online_net.neck.proj_attn.transformer.decoder.layers.0.self_attn.in_proj_bias
online_net.neck.proj_attn.transformer.decoder.layers.0.self_attn.out_proj.bias
online_net.neck.proj_attn.transformer.decoder.layers.0.multihead_attn.in_proj_bias
online_net.neck.proj_attn.transformer.decoder.layers.0.multihead_attn.out_proj.bias
online_net.neck.proj_attn.transformer.decoder.layers.0.linear1.bias
online_net.neck.proj_attn.transformer.decoder.layers.0.linear2.bias
online_net.neck.proj_attn.transformer.decoder.layers.0.norm1.bias
online_net.neck.proj_attn.transformer.decoder.layers.0.norm2.bias
online_net.neck.proj_attn.transformer.decoder.layers.0.norm3.bias
online_net.neck.proj_attn.transformer.decoder.layers.1.self_attn.in_proj_bias
online_net.neck.proj_attn.transformer.decoder.layers.1.self_attn.out_proj.bias
online_net.neck.proj_attn.transformer.decoder.layers.1.multihead_attn.in_proj_bias
online_net.neck.proj_attn.transformer.decoder.layers.1.multihead_attn.out_proj.bias
online_net.neck.proj_attn.transformer.decoder.layers.1.linear1.bias
online_net.neck.proj_attn.transformer.decoder.layers.1.linear2.bias
online_net.neck.proj_attn.transformer.decoder.layers.1.norm1.bias
online_net.neck.proj_attn.transformer.decoder.layers.1.norm2.bias
online_net.neck.proj_attn.transformer.decoder.layers.1.norm3.bias
online_net.neck.proj_attn.transformer.decoder.norm.bias
online_net.neck.proj_attn.input_proj.bias
online_net.neck.proj_attn.mask_embed.layers.0.bias
online_net.neck.proj_attn.mask_embed.layers.1.bias
online_net.neck.proj_attn.mask_embed.layers.2.bias
online_net.neck.heatmap_projection.bias
target_net.backbone.bn1.weight
target_net.backbone.bn1.bias
target_net.backbone.layer1.0.bn1.weight
target_net.backbone.layer1.0.bn1.bias
target_net.backbone.layer1.0.bn2.weight
target_net.backbone.layer1.0.bn2.bias
target_net.backbone.layer1.0.bn3.weight
target_net.backbone.layer1.0.bn3.bias
target_net.backbone.layer1.0.downsample.1.weight
target_net.backbone.layer1.0.downsample.1.bias
target_net.backbone.layer1.1.bn1.weight
target_net.backbone.layer1.1.bn1.bias
target_net.backbone.layer1.1.bn2.weight
target_net.backbone.layer1.1.bn2.bias
target_net.backbone.layer1.1.bn3.weight
target_net.backbone.layer1.1.bn3.bias
target_net.backbone.layer1.2.bn1.weight
target_net.backbone.layer1.2.bn1.bias
target_net.backbone.layer1.2.bn2.weight
target_net.backbone.layer1.2.bn2.bias
target_net.backbone.layer1.2.bn3.weight
target_net.backbone.layer1.2.bn3.bias
target_net.backbone.layer2.0.bn1.weight
target_net.backbone.layer2.0.bn1.bias
target_net.backbone.layer2.0.bn2.weight
target_net.backbone.layer2.0.bn2.bias
target_net.backbone.layer2.0.bn3.weight
target_net.backbone.layer2.0.bn3.bias
target_net.backbone.layer2.0.downsample.1.weight
target_net.backbone.layer2.0.downsample.1.bias
target_net.backbone.layer2.1.bn1.weight
target_net.backbone.layer2.1.bn1.bias
target_net.backbone.layer2.1.bn2.weight
target_net.backbone.layer2.1.bn2.bias
target_net.backbone.layer2.1.bn3.weight
target_net.backbone.layer2.1.bn3.bias
target_net.backbone.layer2.2.bn1.weight
target_net.backbone.layer2.2.bn1.bias
target_net.backbone.layer2.2.bn2.weight
target_net.backbone.layer2.2.bn2.bias
target_net.backbone.layer2.2.bn3.weight
target_net.backbone.layer2.2.bn3.bias
target_net.backbone.layer2.3.bn1.weight
target_net.backbone.layer2.3.bn1.bias
target_net.backbone.layer2.3.bn2.weight
target_net.backbone.layer2.3.bn2.bias
target_net.backbone.layer2.3.bn3.weight
target_net.backbone.layer2.3.bn3.bias
target_net.backbone.layer3.0.bn1.weight
target_net.backbone.layer3.0.bn1.bias
target_net.backbone.layer3.0.bn2.weight
target_net.backbone.layer3.0.bn2.bias
target_net.backbone.layer3.0.bn3.weight
target_net.backbone.layer3.0.bn3.bias
target_net.backbone.layer3.0.downsample.1.weight
target_net.backbone.layer3.0.downsample.1.bias
target_net.backbone.layer3.1.bn1.weight
target_net.backbone.layer3.1.bn1.bias
target_net.backbone.layer3.1.bn2.weight
target_net.backbone.layer3.1.bn2.bias
target_net.backbone.layer3.1.bn3.weight
target_net.backbone.layer3.1.bn3.bias
target_net.backbone.layer3.2.bn1.weight
target_net.backbone.layer3.2.bn1.bias
target_net.backbone.layer3.2.bn2.weight
target_net.backbone.layer3.2.bn2.bias
target_net.backbone.layer3.2.bn3.weight
target_net.backbone.layer3.2.bn3.bias
target_net.backbone.layer3.3.bn1.weight
target_net.backbone.layer3.3.bn1.bias
target_net.backbone.layer3.3.bn2.weight
target_net.backbone.layer3.3.bn2.bias
target_net.backbone.layer3.3.bn3.weight
target_net.backbone.layer3.3.bn3.bias
target_net.backbone.layer3.4.bn1.weight
target_net.backbone.layer3.4.bn1.bias
target_net.backbone.layer3.4.bn2.weight
target_net.backbone.layer3.4.bn2.bias
target_net.backbone.layer3.4.bn3.weight
target_net.backbone.layer3.4.bn3.bias
target_net.backbone.layer3.5.bn1.weight
target_net.backbone.layer3.5.bn1.bias
target_net.backbone.layer3.5.bn2.weight
target_net.backbone.layer3.5.bn2.bias
target_net.backbone.layer3.5.bn3.weight
target_net.backbone.layer3.5.bn3.bias
target_net.backbone.layer4.0.bn1.weight
target_net.backbone.layer4.0.bn1.bias
target_net.backbone.layer4.0.bn2.weight
target_net.backbone.layer4.0.bn2.bias
target_net.backbone.layer4.0.bn3.weight
target_net.backbone.layer4.0.bn3.bias
target_net.backbone.layer4.0.downsample.1.weight
target_net.backbone.layer4.0.downsample.1.bias
target_net.backbone.layer4.1.bn1.weight
target_net.backbone.layer4.1.bn1.bias
target_net.backbone.layer4.1.bn2.weight
target_net.backbone.layer4.1.bn2.bias
target_net.backbone.layer4.1.bn3.weight
target_net.backbone.layer4.1.bn3.bias
target_net.backbone.layer4.2.bn1.weight
target_net.backbone.layer4.2.bn1.bias
target_net.backbone.layer4.2.bn2.weight
target_net.backbone.layer4.2.bn2.bias
target_net.backbone.layer4.2.bn3.weight
target_net.backbone.layer4.2.bn3.bias
target_net.neck.proj.mlp.1.bias
target_net.neck.proj_pixel.mlp.1.bias
target_net.neck.proj_obj.mlp.1.bias
target_net.neck.proj_attn.transformer.decoder.layers.0.self_attn.in_proj_bias
target_net.neck.proj_attn.transformer.decoder.layers.0.self_attn.out_proj.bias
target_net.neck.proj_attn.transformer.decoder.layers.0.multihead_attn.in_proj_bias
target_net.neck.proj_attn.transformer.decoder.layers.0.multihead_attn.out_proj.bias
target_net.neck.proj_attn.transformer.decoder.layers.0.linear1.bias
target_net.neck.proj_attn.transformer.decoder.layers.0.linear2.bias
target_net.neck.proj_attn.transformer.decoder.layers.0.norm1.bias
target_net.neck.proj_attn.transformer.decoder.layers.0.norm2.bias
target_net.neck.proj_attn.transformer.decoder.layers.0.norm3.bias
target_net.neck.proj_attn.transformer.decoder.layers.1.self_attn.in_proj_bias
target_net.neck.proj_attn.transformer.decoder.layers.1.self_attn.out_proj.bias
target_net.neck.proj_attn.transformer.decoder.layers.1.multihead_attn.in_proj_bias
target_net.neck.proj_attn.transformer.decoder.layers.1.multihead_attn.out_proj.bias
target_net.neck.proj_attn.transformer.decoder.layers.1.linear1.bias
target_net.neck.proj_attn.transformer.decoder.layers.1.linear2.bias
target_net.neck.proj_attn.transformer.decoder.layers.1.norm1.bias
target_net.neck.proj_attn.transformer.decoder.layers.1.norm2.bias
target_net.neck.proj_attn.transformer.decoder.layers.1.norm3.bias
target_net.neck.proj_attn.transformer.decoder.norm.bias
target_net.neck.proj_attn.input_proj.bias
target_net.neck.proj_attn.mask_embed.layers.0.bias
target_net.neck.proj_attn.mask_embed.layers.1.bias
target_net.neck.proj_attn.mask_embed.layers.2.bias
target_net.neck.heatmap_projection.bias
predictor.mlp.1.bias
predictor_obj.mlp.1.bias/home/xt1/cs22mds15031/Facial_Region_Awareness/main_pretraining_novelty_sdmp_mixup.py:212: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler() if args.amp else None

train_dataset:
Dataset ImageFolderInstance
    Number of datapoints: 176398
    Root location: data/Pre-training/VGGFace2/train
    StandardTransform
Transform: TwoCropsTransform(
               transform1=Compose(
                   RandomResizedCrop(size=(224, 224), scale=(0.2, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)
                   RandomHorizontalFlip(p=0.5)
                   RandomApply(
                   p=0.8
                   ColorJitter(brightness=(0.6, 1.4), contrast=(0.6, 1.4), saturation=(0.8, 1.2), hue=(-0.1, 0.1))
               )
                   RandomGrayscale(p=0.2)
                   RandomApply(
                   p=1.0
                   <data.transforms.GaussianBlur object at 0x7fbebc3e7d60>
               )
                   RandomApply(
                   p=0.0
                   Solarize
               )
                   ToTensor()
                   Normalize(mean=[0.5231, 0.4044, 0.3489], std=[0.2536, 0.2194, 0.207])
               )
               transform2=Compose(
                   RandomResizedCrop(size=(224, 224), scale=(0.2, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)
                   RandomHorizontalFlip(p=0.5)
                   RandomApply(
                   p=0.8
                   ColorJitter(brightness=(0.6, 1.4), contrast=(0.6, 1.4), saturation=(0.8, 1.2), hue=(-0.1, 0.1))
               )
                   RandomGrayscale(p=0.2)
                   RandomApply(
                   p=0.1
                   <data.transforms.GaussianBlur object at 0x7fbebff36760>
               )
                   RandomApply(
                   p=0.2
                   Solarize
               )
                   ToTensor()
                   Normalize(mean=[0.5231, 0.4044, 0.3489], std=[0.2536, 0.2194, 0.207])
               )
           )
Files already downloaded and verified
/home/xt1/cs22mds15031/Facial_Region_Awareness/main_pretraining_novelty_sdmp_mixup.py:411: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [0/1]	[   0/2756]	LR 1.8000000	MOM 0.9960000	Time  4.247 ( 4.247)	Data  1.094 ( 1.094)	Loss 6.1554e+00 (6.1554e+00)	Loss_base 4.0758e+00 (4.0758e+00)	Loss_inst 1.9837e+00 (1.9837e+00)	Loss_obj 2.0921e+00 (2.0921e+00)	Loss_clu 4.1593e+00 (4.1593e+00)
Epoch: [0/1]	[   1/2756]	LR 1.8000000	MOM 0.9960000	Time  0.270 ( 2.259)	Data  0.001 ( 0.547)	Loss 6.1434e+00 (6.1494e+00)	Loss_base 4.0637e+00 (4.0697e+00)	Loss_inst 1.9699e+00 (1.9768e+00)	Loss_obj 2.0938e+00 (2.0930e+00)	Loss_clu 4.1593e+00 (4.1593e+00)
Epoch: [0/1]	[   2/2756]	LR 1.8000000	MOM 0.9960000	Time  0.290 ( 1.602)	Data  0.000 ( 0.365)	Loss 6.1616e+00 (6.1534e+00)	Loss_base 4.0819e+00 (4.0738e+00)	Loss_inst 1.9978e+00 (1.9838e+00)	Loss_obj 2.0841e+00 (2.0900e+00)	Loss_clu 4.1593e+00 (4.1593e+00)
Epoch: [0/1]	[   3/2756]	LR 1.8000000	MOM 0.9960000	Time  0.292 ( 1.275)	Data  0.000 ( 0.274)	Loss 5.7670e+00 (6.0568e+00)	Loss_base 3.6874e+00 (3.9772e+00)	Loss_inst 1.7862e+00 (1.9344e+00)	Loss_obj 1.9012e+00 (2.0428e+00)	Loss_clu 4.1591e+00 (4.1593e+00)
Epoch: [0/1]	[   4/2756]	LR 1.8000000	MOM 0.9960000	Time  0.301 ( 1.080)	Data  0.000 ( 0.219)	Loss 5.2555e+00 (5.8966e+00)	Loss_base 3.1760e+00 (3.8170e+00)	Loss_inst 1.5299e+00 (1.8535e+00)	Loss_obj 1.6461e+00 (1.9635e+00)	Loss_clu 4.1590e+00 (4.1592e+00)
Epoch: [0/1]	[   5/2756]	LR 1.8000000	MOM 0.9960000	Time  0.293 ( 0.949)	Data  0.000 ( 0.183)	Loss 4.7378e+00 (5.7034e+00)	Loss_base 2.6583e+00 (3.6238e+00)	Loss_inst 1.2811e+00 (1.7581e+00)	Loss_obj 1.3772e+00 (1.8657e+00)	Loss_clu 4.1589e+00 (4.1592e+00)
Epoch: [0/1]	[   6/2756]	LR 1.8000000	MOM 0.9960000	Time  0.296 ( 0.856)	Data  0.000 ( 0.157)	Loss 4.2679e+00 (5.4984e+00)	Loss_base 2.1885e+00 (3.4188e+00)	Loss_inst 1.0640e+00 (1.6589e+00)	Loss_obj 1.1245e+00 (1.7599e+00)	Loss_clu 4.1589e+00 (4.1591e+00)
Epoch: [0/1]	[   7/2756]	LR 1.8000000	MOM 0.9960001	Time  0.296 ( 0.786)	Data  0.000 ( 0.137)	Loss 3.9763e+00 (5.3081e+00)	Loss_base 1.8969e+00 (3.2286e+00)	Loss_inst 9.1523e-01 (1.5660e+00)	Loss_obj 9.8165e-01 (1.6626e+00)	Loss_clu 4.1589e+00 (4.1591e+00)
Epoch: [0/1]	[   8/2756]	LR 1.8000000	MOM 0.9960001	Time  0.291 ( 0.731)	Data  0.000 ( 0.122)	Loss 3.8736e+00 (5.1487e+00)	Loss_base 1.7942e+00 (3.0692e+00)	Loss_inst 8.5876e-01 (1.4874e+00)	Loss_obj 9.3541e-01 (1.5818e+00)	Loss_clu 4.1589e+00 (4.1591e+00)
Epoch: [0/1]	[   9/2756]	LR 1.8000000	MOM 0.9960001	Time  0.289 ( 0.687)	Data  0.000 ( 0.110)	Loss 3.6820e+00 (5.0020e+00)	Loss_base 1.6025e+00 (2.9225e+00)	Loss_inst 7.6817e-01 (1.4155e+00)	Loss_obj 8.3435e-01 (1.5070e+00)	Loss_clu 4.1589e+00 (4.1591e+00)
Epoch: [0/1]	[  10/2756]	LR 1.8000000	MOM 0.9960001	Time  0.294 ( 0.651)	Data  0.000 ( 0.100)	Loss 3.6329e+00 (4.8776e+00)	Loss_base 1.5535e+00 (2.7981e+00)	Loss_inst 7.4721e-01 (1.3547e+00)	Loss_obj 8.0629e-01 (1.4433e+00)	Loss_clu 4.1589e+00 (4.1590e+00)
Epoch: [0/1]	[  11/2756]	LR 1.8000000	MOM 0.9960002	Time  0.293 ( 0.621)	Data  0.000 ( 0.092)	Loss 3.5315e+00 (4.7654e+00)	Loss_base 1.4521e+00 (2.6859e+00)	Loss_inst 7.0006e-01 (1.3002e+00)	Loss_obj 7.5201e-01 (1.3857e+00)	Loss_clu 4.1589e+00 (4.1590e+00)
Epoch: [0/1]	[  12/2756]	LR 1.8000000	MOM 0.9960002	Time  0.294 ( 0.596)	Data  0.000 ( 0.084)	Loss 3.6527e+00 (4.6798e+00)	Loss_base 1.5733e+00 (2.6003e+00)	Loss_inst 7.5159e-01 (1.2580e+00)	Loss_obj 8.2171e-01 (1.3423e+00)	Loss_clu 4.1589e+00 (4.1590e+00)
Epoch: [0/1]	[  13/2756]	LR 1.8000000	MOM 0.9960002	Time  0.296 ( 0.574)	Data  0.000 ( 0.078)	Loss 3.6272e+00 (4.6046e+00)	Loss_base 1.5478e+00 (2.5251e+00)	Loss_inst 7.3973e-01 (1.2209e+00)	Loss_obj 8.0803e-01 (1.3042e+00)	Loss_clu 4.1589e+00 (4.1590e+00)
Epoch: [0/1]	[  14/2756]	LR 1.8000000	MOM 0.9960003	Time  0.295 ( 0.556)	Data  0.000 ( 0.073)	Loss 3.6260e+00 (4.5394e+00)	Loss_base 1.5466e+00 (2.4599e+00)	Loss_inst 7.4076e-01 (1.1889e+00)	Loss_obj 8.0583e-01 (1.2710e+00)	Loss_clu 4.1589e+00 (4.1590e+00)
Epoch: [0/1]	[  15/2756]	LR 1.8000000	MOM 0.9960003	Time  0.291 ( 0.539)	Data  0.000 ( 0.069)	Loss 3.6617e+00 (4.4845e+00)	Loss_base 1.5822e+00 (2.4050e+00)	Loss_inst 7.6468e-01 (1.1624e+00)	Loss_obj 8.1756e-01 (1.2426e+00)	Loss_clu 4.1589e+00 (4.1590e+00)
Epoch: [0/1]	[  16/2756]	LR 1.8000000	MOM 0.9960003	Time  0.288 ( 0.524)	Data  0.000 ( 0.065)	Loss 3.6033e+00 (4.4327e+00)	Loss_base 1.5239e+00 (2.3532e+00)	Loss_inst 7.3669e-01 (1.1374e+00)	Loss_obj 7.8717e-01 (1.2158e+00)	Loss_clu 4.1589e+00 (4.1590e+00)
Epoch: [0/1]	[  17/2756]	LR 1.8000000	MOM 0.9960004	Time  0.291 ( 0.511)	Data  0.000 ( 0.061)	Loss 3.6600e+00 (4.3898e+00)	Loss_base 1.5805e+00 (2.3103e+00)	Loss_inst 7.5998e-01 (1.1164e+00)	Loss_obj 8.2056e-01 (1.1939e+00)	Loss_clu 4.1589e+00 (4.1590e+00)
Epoch: [0/1]	[  18/2756]	LR 1.8000000	MOM 0.9960004	Time  0.296 ( 0.500)	Data  0.000 ( 0.058)	Loss 3.6268e+00 (4.3496e+00)	Loss_base 1.5473e+00 (2.2701e+00)	Loss_inst 7.5838e-01 (1.0976e+00)	Loss_obj 7.8894e-01 (1.1726e+00)	Loss_clu 4.1589e+00 (4.1590e+00)
Epoch: [0/1]	[  19/2756]	LR 1.8000000	MOM 0.9960005	Time  0.295 ( 0.490)	Data  0.000 ( 0.055)	Loss 3.6348e+00 (4.3139e+00)	Loss_base 1.5553e+00 (2.2344e+00)	Loss_inst 7.5242e-01 (1.0803e+00)	Loss_obj 8.0289e-01 (1.1541e+00)	Loss_clu 4.1589e+00 (4.1590e+00)
Epoch: [0/1]	[  20/2756]	LR 1.8000000	MOM 0.9960005	Time  0.297 ( 0.481)	Data  0.000 ( 0.052)	Loss 3.7032e+00 (4.2848e+00)	Loss_base 1.6238e+00 (2.2053e+00)	Loss_inst 7.8040e-01 (1.0660e+00)	Loss_obj 8.4339e-01 (1.1393e+00)	Loss_clu 4.1589e+00 (4.1590e+00)
Epoch: [0/1]	[  21/2756]	LR 1.8000000	MOM 0.9960006	Time  0.294 ( 0.472)	Data  0.000 ( 0.050)	Loss 3.6611e+00 (4.2564e+00)	Loss_base 1.5817e+00 (2.1770e+00)	Loss_inst 7.5674e-01 (1.0520e+00)	Loss_obj 8.2495e-01 (1.1250e+00)	Loss_clu 4.1589e+00 (4.1590e+00)
Epoch: [0/1]	[  22/2756]	LR 1.8000000	MOM 0.9960006	Time  0.301 ( 0.465)	Data  0.000 ( 0.048)	Loss 3.6209e+00 (4.2288e+00)	Loss_base 1.5415e+00 (2.1493e+00)	Loss_inst 7.4424e-01 (1.0386e+00)	Loss_obj 7.9722e-01 (1.1107e+00)	Loss_clu 4.1589e+00 (4.1590e+00)
Epoch: [0/1]	[  23/2756]	LR 1.8000000	MOM 0.9960007	Time  0.291 ( 0.457)	Data  0.000 ( 0.046)	Loss 3.6372e+00 (4.2042e+00)	Loss_base 1.5578e+00 (2.1247e+00)	Loss_inst 7.4288e-01 (1.0263e+00)	Loss_obj 8.1489e-01 (1.0984e+00)	Loss_clu 4.1589e+00 (4.1590e+00)
Epoch: [0/1]	[  24/2756]	LR 1.8000000	MOM 0.9960007	Time  0.296 ( 0.451)	Data  0.000 ( 0.044)	Loss 3.6754e+00 (4.1830e+00)	Loss_base 1.5960e+00 (2.1035e+00)	Loss_inst 7.6955e-01 (1.0160e+00)	Loss_obj 8.2644e-01 (1.0875e+00)	Loss_clu 4.1589e+00 (4.1590e+00)
Epoch: [0/1]	[  25/2756]	LR 1.8000000	MOM 0.9960008	Time  0.302 ( 0.445)	Data  0.000 ( 0.042)	Loss 3.6912e+00 (4.1641e+00)	Loss_base 1.6117e+00 (2.0846e+00)	Loss_inst 7.7262e-01 (1.0066e+00)	Loss_obj 8.3913e-01 (1.0780e+00)	Loss_clu 4.1589e+00 (4.1590e+00)
Epoch: [0/1]	[  26/2756]	LR 1.8000000	MOM 0.9960009	Time  0.311 ( 0.440)	Data  0.000 ( 0.041)	Loss 3.6639e+00 (4.1456e+00)	Loss_base 1.5845e+00 (2.0661e+00)	Loss_inst 7.6527e-01 (9.9770e-01)	Loss_obj 8.1918e-01 (1.0684e+00)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  27/2756]	LR 1.8000000	MOM 0.9960009	Time  0.320 ( 0.436)	Data  0.000 ( 0.039)	Loss 3.6613e+00 (4.1283e+00)	Loss_base 1.5818e+00 (2.0488e+00)	Loss_inst 7.6296e-01 (9.8932e-01)	Loss_obj 8.1885e-01 (1.0595e+00)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  28/2756]	LR 1.8000000	MOM 0.9960010	Time  0.314 ( 0.432)	Data  0.000 ( 0.038)	Loss 3.6668e+00 (4.1124e+00)	Loss_base 1.5874e+00 (2.0329e+00)	Loss_inst 7.6615e-01 (9.8162e-01)	Loss_obj 8.2121e-01 (1.0513e+00)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  29/2756]	LR 1.8000000	MOM 0.9960011	Time  0.303 ( 0.428)	Data  0.000 ( 0.037)	Loss 3.6778e+00 (4.0979e+00)	Loss_base 1.5984e+00 (2.0184e+00)	Loss_inst 7.7553e-01 (9.7475e-01)	Loss_obj 8.2284e-01 (1.0436e+00)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  30/2756]	LR 1.8000000	MOM 0.9960012	Time  0.301 ( 0.423)	Data  0.000 ( 0.036)	Loss 3.6564e+00 (4.0836e+00)	Loss_base 1.5769e+00 (2.0042e+00)	Loss_inst 7.6123e-01 (9.6786e-01)	Loss_obj 8.1569e-01 (1.0363e+00)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  31/2756]	LR 1.8000000	MOM 0.9960012	Time  0.300 ( 0.420)	Data  0.000 ( 0.035)	Loss 3.7373e+00 (4.0728e+00)	Loss_base 1.6579e+00 (1.9933e+00)	Loss_inst 7.9703e-01 (9.6253e-01)	Loss_obj 8.6084e-01 (1.0308e+00)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  32/2756]	LR 1.8000000	MOM 0.9960013	Time  0.302 ( 0.416)	Data  0.000 ( 0.033)	Loss 3.7505e+00 (4.0630e+00)	Loss_base 1.6710e+00 (1.9836e+00)	Loss_inst 7.9682e-01 (9.5750e-01)	Loss_obj 8.7422e-01 (1.0261e+00)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  33/2756]	LR 1.8000000	MOM 0.9960014	Time  0.300 ( 0.413)	Data  0.000 ( 0.032)	Loss 3.6771e+00 (4.0517e+00)	Loss_base 1.5976e+00 (1.9722e+00)	Loss_inst 7.6870e-01 (9.5195e-01)	Loss_obj 8.2894e-01 (1.0203e+00)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  34/2756]	LR 1.8000000	MOM 0.9960015	Time  0.319 ( 0.410)	Data  0.000 ( 0.032)	Loss 3.7071e+00 (4.0418e+00)	Loss_base 1.6277e+00 (1.9624e+00)	Loss_inst 7.9300e-01 (9.4741e-01)	Loss_obj 8.3469e-01 (1.0150e+00)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  35/2756]	LR 1.8000000	MOM 0.9960016	Time  0.317 ( 0.407)	Data  0.000 ( 0.031)	Loss 3.8215e+00 (4.0357e+00)	Loss_base 1.7421e+00 (1.9563e+00)	Loss_inst 8.3598e-01 (9.4431e-01)	Loss_obj 9.0612e-01 (1.0119e+00)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  36/2756]	LR 1.8000000	MOM 0.9960017	Time  0.303 ( 0.405)	Data  0.000 ( 0.030)	Loss 3.6640e+00 (4.0257e+00)	Loss_base 1.5846e+00 (1.9462e+00)	Loss_inst 7.6847e-01 (9.3956e-01)	Loss_obj 8.1611e-01 (1.0067e+00)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  37/2756]	LR 1.8000000	MOM 0.9960018	Time  0.298 ( 0.402)	Data  0.001 ( 0.029)	Loss 3.7923e+00 (4.0195e+00)	Loss_base 1.7128e+00 (1.9401e+00)	Loss_inst 8.2244e-01 (9.3648e-01)	Loss_obj 8.9039e-01 (1.0036e+00)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  38/2756]	LR 1.8000000	MOM 0.9960019	Time  0.300 ( 0.399)	Data  0.000 ( 0.028)	Loss 3.7192e+00 (4.0118e+00)	Loss_base 1.6397e+00 (1.9324e+00)	Loss_inst 7.9693e-01 (9.3290e-01)	Loss_obj 8.4281e-01 (9.9947e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  39/2756]	LR 1.8000000	MOM 0.9960020	Time  0.289 ( 0.396)	Data  0.000 ( 0.028)	Loss 3.7287e+00 (4.0048e+00)	Loss_base 1.6493e+00 (1.9253e+00)	Loss_inst 7.9410e-01 (9.2943e-01)	Loss_obj 8.5515e-01 (9.9586e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  40/2756]	LR 1.8000000	MOM 0.9960021	Time  0.299 ( 0.394)	Data  0.000 ( 0.027)	Loss 3.6518e+00 (3.9961e+00)	Loss_base 1.5724e+00 (1.9167e+00)	Loss_inst 7.6078e-01 (9.2532e-01)	Loss_obj 8.1161e-01 (9.9137e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  41/2756]	LR 1.8000000	MOM 0.9960022	Time  0.297 ( 0.392)	Data  0.000 ( 0.026)	Loss 3.7319e+00 (3.9899e+00)	Loss_base 1.6524e+00 (1.9104e+00)	Loss_inst 7.9896e-01 (9.2231e-01)	Loss_obj 8.5349e-01 (9.8808e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  42/2756]	LR 1.8000000	MOM 0.9960023	Time  0.301 ( 0.390)	Data  0.000 ( 0.026)	Loss 3.7018e+00 (3.9832e+00)	Loss_base 1.6224e+00 (1.9037e+00)	Loss_inst 7.8154e-01 (9.1904e-01)	Loss_obj 8.4085e-01 (9.8466e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  43/2756]	LR 1.8000000	MOM 0.9960024	Time  0.296 ( 0.387)	Data  0.000 ( 0.025)	Loss 3.7067e+00 (3.9769e+00)	Loss_base 1.6273e+00 (1.8974e+00)	Loss_inst 7.8258e-01 (9.1593e-01)	Loss_obj 8.4470e-01 (9.8148e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  44/2756]	LR 1.8000000	MOM 0.9960025	Time  0.301 ( 0.385)	Data  0.000 ( 0.025)	Loss 3.8146e+00 (3.9733e+00)	Loss_base 1.7352e+00 (1.8938e+00)	Loss_inst 8.2465e-01 (9.1391e-01)	Loss_obj 9.1056e-01 (9.7990e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  45/2756]	LR 1.8000000	MOM 0.9960026	Time  0.299 ( 0.384)	Data  0.000 ( 0.024)	Loss 3.7856e+00 (3.9692e+00)	Loss_base 1.7062e+00 (1.8897e+00)	Loss_inst 8.2372e-01 (9.1195e-01)	Loss_obj 8.8243e-01 (9.7778e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  46/2756]	LR 1.8000000	MOM 0.9960027	Time  0.298 ( 0.382)	Data  0.000 ( 0.024)	Loss 3.6184e+00 (3.9617e+00)	Loss_base 1.5390e+00 (1.8823e+00)	Loss_inst 7.3991e-01 (9.0829e-01)	Loss_obj 7.9908e-01 (9.7398e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  47/2756]	LR 1.8000000	MOM 0.9960029	Time  0.299 ( 0.380)	Data  0.000 ( 0.023)	Loss 3.6150e+00 (3.9545e+00)	Loss_base 1.5356e+00 (1.8750e+00)	Loss_inst 7.5356e-01 (9.0506e-01)	Loss_obj 7.8200e-01 (9.6998e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  48/2756]	LR 1.8000000	MOM 0.9960030	Time  0.299 ( 0.378)	Data  0.000 ( 0.023)	Loss 3.7061e+00 (3.9494e+00)	Loss_base 1.6266e+00 (1.8700e+00)	Loss_inst 7.8425e-01 (9.0260e-01)	Loss_obj 8.4240e-01 (9.6738e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  49/2756]	LR 1.8000000	MOM 0.9960031	Time  0.298 ( 0.377)	Data  0.000 ( 0.022)	Loss 3.7250e+00 (3.9449e+00)	Loss_base 1.6456e+00 (1.8655e+00)	Loss_inst 8.0133e-01 (9.0057e-01)	Loss_obj 8.4427e-01 (9.6492e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  50/2756]	LR 1.8000000	MOM 0.9960032	Time  0.295 ( 0.375)	Data  0.000 ( 0.022)	Loss 3.7193e+00 (3.9405e+00)	Loss_base 1.6398e+00 (1.8611e+00)	Loss_inst 7.9901e-01 (8.9858e-01)	Loss_obj 8.4083e-01 (9.6248e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  51/2756]	LR 1.8000000	MOM 0.9960034	Time  0.297 ( 0.374)	Data  0.000 ( 0.021)	Loss 3.6951e+00 (3.9358e+00)	Loss_base 1.6157e+00 (1.8563e+00)	Loss_inst 7.8446e-01 (8.9638e-01)	Loss_obj 8.3124e-01 (9.5996e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  52/2756]	LR 1.8000000	MOM 0.9960035	Time  0.300 ( 0.372)	Data  0.000 ( 0.021)	Loss 3.7274e+00 (3.9319e+00)	Loss_base 1.6480e+00 (1.8524e+00)	Loss_inst 8.0307e-01 (8.9462e-01)	Loss_obj 8.4493e-01 (9.5779e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  53/2756]	LR 1.8000000	MOM 0.9960036	Time  0.301 ( 0.371)	Data  0.000 ( 0.021)	Loss 3.7083e+00 (3.9277e+00)	Loss_base 1.6288e+00 (1.8483e+00)	Loss_inst 7.9556e-01 (8.9279e-01)	Loss_obj 8.3326e-01 (9.5548e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  54/2756]	LR 1.8000000	MOM 0.9960038	Time  0.296 ( 0.370)	Data  0.000 ( 0.020)	Loss 3.7112e+00 (3.9238e+00)	Loss_base 1.6317e+00 (1.8443e+00)	Loss_inst 8.0165e-01 (8.9113e-01)	Loss_obj 8.3007e-01 (9.5320e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  55/2756]	LR 1.8000000	MOM 0.9960039	Time  0.290 ( 0.368)	Data  0.000 ( 0.020)	Loss 3.6794e+00 (3.9194e+00)	Loss_base 1.5999e+00 (1.8400e+00)	Loss_inst 7.7889e-01 (8.8913e-01)	Loss_obj 8.2102e-01 (9.5084e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  56/2756]	LR 1.8000000	MOM 0.9960041	Time  0.301 ( 0.367)	Data  0.000 ( 0.019)	Loss 3.7460e+00 (3.9164e+00)	Loss_base 1.6665e+00 (1.8369e+00)	Loss_inst 8.0447e-01 (8.8764e-01)	Loss_obj 8.6204e-01 (9.4928e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  57/2756]	LR 1.8000000	MOM 0.9960042	Time  0.295 ( 0.366)	Data  0.000 ( 0.019)	Loss 3.7750e+00 (3.9139e+00)	Loss_base 1.6955e+00 (1.8345e+00)	Loss_inst 8.1698e-01 (8.8642e-01)	Loss_obj 8.7853e-01 (9.4806e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  58/2756]	LR 1.8000000	MOM 0.9960044	Time  0.302 ( 0.365)	Data  0.000 ( 0.019)	Loss 3.6818e+00 (3.9100e+00)	Loss_base 1.6023e+00 (1.8306e+00)	Loss_inst 7.8550e-01 (8.8471e-01)	Loss_obj 8.1684e-01 (9.4584e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  59/2756]	LR 1.8000000	MOM 0.9960045	Time  0.294 ( 0.364)	Data  0.000 ( 0.019)	Loss 3.7765e+00 (3.9078e+00)	Loss_base 1.6970e+00 (1.8283e+00)	Loss_inst 8.2679e-01 (8.8375e-01)	Loss_obj 8.7025e-01 (9.4458e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  60/2756]	LR 1.8000000	MOM 0.9960047	Time  0.293 ( 0.362)	Data  0.000 ( 0.018)	Loss 3.7586e+00 (3.9053e+00)	Loss_base 1.6791e+00 (1.8259e+00)	Loss_inst 8.2580e-01 (8.8280e-01)	Loss_obj 8.5334e-01 (9.4308e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  61/2756]	LR 1.8000000	MOM 0.9960048	Time  0.299 ( 0.361)	Data  0.000 ( 0.018)	Loss 3.6870e+00 (3.9018e+00)	Loss_base 1.6075e+00 (1.8224e+00)	Loss_inst 7.8148e-01 (8.8116e-01)	Loss_obj 8.2607e-01 (9.4120e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  62/2756]	LR 1.8000000	MOM 0.9960050	Time  0.300 ( 0.360)	Data  0.000 ( 0.018)	Loss 3.6842e+00 (3.8984e+00)	Loss_base 1.6048e+00 (1.8189e+00)	Loss_inst 7.7916e-01 (8.7955e-01)	Loss_obj 8.2563e-01 (9.3936e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  63/2756]	LR 1.8000000	MOM 0.9960052	Time  0.291 ( 0.359)	Data  0.000 ( 0.017)	Loss 3.6037e+00 (3.8938e+00)	Loss_base 1.5242e+00 (1.8143e+00)	Loss_inst 7.4276e-01 (8.7741e-01)	Loss_obj 7.8148e-01 (9.3690e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  64/2756]	LR 1.8000000	MOM 0.9960053	Time  0.298 ( 0.358)	Data  0.000 ( 0.017)	Loss 3.7221e+00 (3.8911e+00)	Loss_base 1.6427e+00 (1.8117e+00)	Loss_inst 8.0346e-01 (8.7627e-01)	Loss_obj 8.3924e-01 (9.3539e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  65/2756]	LR 1.8000000	MOM 0.9960055	Time  0.298 ( 0.357)	Data  0.000 ( 0.017)	Loss 3.6781e+00 (3.8879e+00)	Loss_base 1.5987e+00 (1.8084e+00)	Loss_inst 7.8349e-01 (8.7486e-01)	Loss_obj 8.1518e-01 (9.3357e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  66/2756]	LR 1.8000000	MOM 0.9960057	Time  0.298 ( 0.357)	Data  0.000 ( 0.017)	Loss 3.7365e+00 (3.8856e+00)	Loss_base 1.6570e+00 (1.8062e+00)	Loss_inst 8.1760e-01 (8.7401e-01)	Loss_obj 8.3943e-01 (9.3217e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  67/2756]	LR 1.8000000	MOM 0.9960058	Time  0.299 ( 0.356)	Data  0.000 ( 0.016)	Loss 3.7154e+00 (3.8831e+00)	Loss_base 1.6359e+00 (1.8037e+00)	Loss_inst 8.0436e-01 (8.7299e-01)	Loss_obj 8.3158e-01 (9.3069e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  68/2756]	LR 1.8000000	MOM 0.9960060	Time  0.295 ( 0.355)	Data  0.000 ( 0.016)	Loss 3.6847e+00 (3.8803e+00)	Loss_base 1.6052e+00 (1.8008e+00)	Loss_inst 7.9357e-01 (8.7183e-01)	Loss_obj 8.1164e-01 (9.2896e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  69/2756]	LR 1.8000000	MOM 0.9960062	Time  0.302 ( 0.354)	Data  0.000 ( 0.016)	Loss 3.6699e+00 (3.8772e+00)	Loss_base 1.5904e+00 (1.7978e+00)	Loss_inst 7.7935e-01 (8.7051e-01)	Loss_obj 8.1107e-01 (9.2728e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  70/2756]	LR 1.8000000	MOM 0.9960064	Time  0.295 ( 0.353)	Data  0.000 ( 0.016)	Loss 3.6396e+00 (3.8739e+00)	Loss_base 1.5601e+00 (1.7944e+00)	Loss_inst 7.7874e-01 (8.6922e-01)	Loss_obj 7.8140e-01 (9.2522e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  71/2756]	LR 1.8000000	MOM 0.9960065	Time  0.293 ( 0.352)	Data  0.000 ( 0.015)	Loss 3.6557e+00 (3.8709e+00)	Loss_base 1.5762e+00 (1.7914e+00)	Loss_inst 7.7901e-01 (8.6797e-01)	Loss_obj 7.9723e-01 (9.2345e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  72/2756]	LR 1.8000000	MOM 0.9960067	Time  0.302 ( 0.352)	Data  0.000 ( 0.015)	Loss 3.6470e+00 (3.8678e+00)	Loss_base 1.5675e+00 (1.7883e+00)	Loss_inst 7.7654e-01 (8.6672e-01)	Loss_obj 7.9098e-01 (9.2163e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  73/2756]	LR 1.8000000	MOM 0.9960069	Time  0.298 ( 0.351)	Data  0.000 ( 0.015)	Loss 3.7901e+00 (3.8667e+00)	Loss_base 1.7106e+00 (1.7873e+00)	Loss_inst 8.4138e-01 (8.6637e-01)	Loss_obj 8.6925e-01 (9.2092e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  74/2756]	LR 1.8000000	MOM 0.9960071	Time  0.297 ( 0.350)	Data  0.000 ( 0.015)	Loss 3.7936e+00 (3.8658e+00)	Loss_base 1.7142e+00 (1.7863e+00)	Loss_inst 8.4210e-01 (8.6605e-01)	Loss_obj 8.7206e-01 (9.2027e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  75/2756]	LR 1.8000000	MOM 0.9960073	Time  0.299 ( 0.350)	Data  0.000 ( 0.015)	Loss 3.7657e+00 (3.8645e+00)	Loss_base 1.6862e+00 (1.7850e+00)	Loss_inst 8.2977e-01 (8.6557e-01)	Loss_obj 8.5645e-01 (9.1943e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  76/2756]	LR 1.8000000	MOM 0.9960075	Time  0.299 ( 0.349)	Data  0.000 ( 0.015)	Loss 3.6918e+00 (3.8622e+00)	Loss_base 1.6124e+00 (1.7828e+00)	Loss_inst 7.9976e-01 (8.6472e-01)	Loss_obj 8.1261e-01 (9.1805e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  77/2756]	LR 1.8000000	MOM 0.9960077	Time  0.297 ( 0.348)	Data  0.000 ( 0.014)	Loss 3.8058e+00 (3.8615e+00)	Loss_base 1.7264e+00 (1.7820e+00)	Loss_inst 8.5878e-01 (8.6464e-01)	Loss_obj 8.6758e-01 (9.1740e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  78/2756]	LR 1.8000000	MOM 0.9960079	Time  0.294 ( 0.348)	Data  0.000 ( 0.014)	Loss 3.6512e+00 (3.8588e+00)	Loss_base 1.5717e+00 (1.7794e+00)	Loss_inst 7.8467e-01 (8.6363e-01)	Loss_obj 7.8708e-01 (9.1575e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  79/2756]	LR 1.8000000	MOM 0.9960081	Time  0.294 ( 0.347)	Data  0.000 ( 0.014)	Loss 3.5989e+00 (3.8556e+00)	Loss_base 1.5194e+00 (1.7761e+00)	Loss_inst 7.6157e-01 (8.6235e-01)	Loss_obj 7.5785e-01 (9.1377e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  80/2756]	LR 1.8000000	MOM 0.9960083	Time  0.299 ( 0.346)	Data  0.000 ( 0.014)	Loss 3.8088e+00 (3.8550e+00)	Loss_base 1.7293e+00 (1.7756e+00)	Loss_inst 8.5392e-01 (8.6225e-01)	Loss_obj 8.7539e-01 (9.1330e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  81/2756]	LR 1.8000000	MOM 0.9960085	Time  0.295 ( 0.346)	Data  0.000 ( 0.014)	Loss 3.7277e+00 (3.8534e+00)	Loss_base 1.6482e+00 (1.7740e+00)	Loss_inst 8.1828e-01 (8.6171e-01)	Loss_obj 8.2995e-01 (9.1228e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  82/2756]	LR 1.8000000	MOM 0.9960087	Time  0.296 ( 0.345)	Data  0.000 ( 0.013)	Loss 3.6555e+00 (3.8511e+00)	Loss_base 1.5761e+00 (1.7716e+00)	Loss_inst 7.8442e-01 (8.6078e-01)	Loss_obj 7.9163e-01 (9.1083e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  83/2756]	LR 1.8000000	MOM 0.9960089	Time  0.298 ( 0.344)	Data  0.000 ( 0.013)	Loss 3.8017e+00 (3.8505e+00)	Loss_base 1.7223e+00 (1.7710e+00)	Loss_inst 8.5309e-01 (8.6069e-01)	Loss_obj 8.6920e-01 (9.1034e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  84/2756]	LR 1.8000000	MOM 0.9960092	Time  0.298 ( 0.344)	Data  0.000 ( 0.013)	Loss 3.9259e+00 (3.8514e+00)	Loss_base 1.8464e+00 (1.7719e+00)	Loss_inst 9.0580e-01 (8.6122e-01)	Loss_obj 9.4063e-01 (9.1069e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  85/2756]	LR 1.8000000	MOM 0.9960094	Time  0.301 ( 0.343)	Data  0.000 ( 0.013)	Loss 3.8084e+00 (3.8509e+00)	Loss_base 1.7290e+00 (1.7714e+00)	Loss_inst 8.4802e-01 (8.6107e-01)	Loss_obj 8.8097e-01 (9.1035e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  86/2756]	LR 1.8000000	MOM 0.9960096	Time  0.293 ( 0.343)	Data  0.000 ( 0.013)	Loss 3.8134e+00 (3.8504e+00)	Loss_base 1.7340e+00 (1.7710e+00)	Loss_inst 8.6185e-01 (8.6108e-01)	Loss_obj 8.7213e-01 (9.0991e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  87/2756]	LR 1.8000000	MOM 0.9960098	Time  0.291 ( 0.342)	Data  0.000 ( 0.013)	Loss 3.7474e+00 (3.8493e+00)	Loss_base 1.6680e+00 (1.7698e+00)	Loss_inst 8.2857e-01 (8.6071e-01)	Loss_obj 8.3940e-01 (9.0911e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  88/2756]	LR 1.8000000	MOM 0.9960101	Time  0.299 ( 0.342)	Data  0.000 ( 0.013)	Loss 3.8434e+00 (3.8492e+00)	Loss_base 1.7639e+00 (1.7697e+00)	Loss_inst 8.7789e-01 (8.6090e-01)	Loss_obj 8.8602e-01 (9.0885e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  89/2756]	LR 1.8000000	MOM 0.9960103	Time  0.297 ( 0.341)	Data  0.000 ( 0.012)	Loss 3.7982e+00 (3.8486e+00)	Loss_base 1.7188e+00 (1.7692e+00)	Loss_inst 8.4470e-01 (8.6072e-01)	Loss_obj 8.7407e-01 (9.0846e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  90/2756]	LR 1.8000000	MOM 0.9960105	Time  0.300 ( 0.341)	Data  0.000 ( 0.012)	Loss 3.9729e+00 (3.8500e+00)	Loss_base 1.8935e+00 (1.7705e+00)	Loss_inst 9.3813e-01 (8.6157e-01)	Loss_obj 9.5534e-01 (9.0898e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  91/2756]	LR 1.8000000	MOM 0.9960108	Time  0.296 ( 0.340)	Data  0.000 ( 0.012)	Loss 3.8212e+00 (3.8497e+00)	Loss_base 1.7417e+00 (1.7702e+00)	Loss_inst 8.6353e-01 (8.6159e-01)	Loss_obj 8.7819e-01 (9.0864e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  92/2756]	LR 1.8000000	MOM 0.9960110	Time  0.297 ( 0.340)	Data  0.000 ( 0.012)	Loss 3.8492e+00 (3.8497e+00)	Loss_base 1.7697e+00 (1.7702e+00)	Loss_inst 8.7975e-01 (8.6179e-01)	Loss_obj 8.8997e-01 (9.0844e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  93/2756]	LR 1.8000000	MOM 0.9960112	Time  0.299 ( 0.339)	Data  0.000 ( 0.012)	Loss 3.8374e+00 (3.8495e+00)	Loss_base 1.7580e+00 (1.7701e+00)	Loss_inst 8.6935e-01 (8.6187e-01)	Loss_obj 8.8864e-01 (9.0823e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  94/2756]	LR 1.8000000	MOM 0.9960115	Time  0.296 ( 0.339)	Data  0.000 ( 0.012)	Loss 3.8223e+00 (3.8493e+00)	Loss_base 1.7428e+00 (1.7698e+00)	Loss_inst 8.5924e-01 (8.6184e-01)	Loss_obj 8.8360e-01 (9.0797e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  95/2756]	LR 1.8000000	MOM 0.9960117	Time  0.299 ( 0.339)	Data  0.000 ( 0.012)	Loss 3.7930e+00 (3.8487e+00)	Loss_base 1.7136e+00 (1.7692e+00)	Loss_inst 8.5060e-01 (8.6172e-01)	Loss_obj 8.6295e-01 (9.0750e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  96/2756]	LR 1.8000000	MOM 0.9960120	Time  0.298 ( 0.338)	Data  0.000 ( 0.012)	Loss 3.8528e+00 (3.8487e+00)	Loss_base 1.7733e+00 (1.7693e+00)	Loss_inst 8.7197e-01 (8.6183e-01)	Loss_obj 9.0137e-01 (9.0744e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  97/2756]	LR 1.8000000	MOM 0.9960122	Time  0.298 ( 0.338)	Data  0.000 ( 0.011)	Loss 3.8583e+00 (3.8488e+00)	Loss_base 1.7788e+00 (1.7694e+00)	Loss_inst 8.8402e-01 (8.6205e-01)	Loss_obj 8.9480e-01 (9.0731e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  98/2756]	LR 1.8000000	MOM 0.9960125	Time  0.303 ( 0.337)	Data  0.000 ( 0.011)	Loss 3.7994e+00 (3.8483e+00)	Loss_base 1.7200e+00 (1.7689e+00)	Loss_inst 8.5164e-01 (8.6195e-01)	Loss_obj 8.6834e-01 (9.0692e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[  99/2756]	LR 1.8000000	MOM 0.9960127	Time  0.301 ( 0.337)	Data  0.000 ( 0.011)	Loss 3.8223e+00 (3.8481e+00)	Loss_base 1.7428e+00 (1.7686e+00)	Loss_inst 8.6413e-01 (8.6197e-01)	Loss_obj 8.7870e-01 (9.0663e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 100/2756]	LR 1.8000000	MOM 0.9960130	Time  0.299 ( 0.337)	Data  0.000 ( 0.011)	Loss 3.8299e+00 (3.8479e+00)	Loss_base 1.7504e+00 (1.7684e+00)	Loss_inst 8.6794e-01 (8.6203e-01)	Loss_obj 8.8250e-01 (9.0639e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 101/2756]	LR 1.8000000	MOM 0.9960132	Time  0.297 ( 0.336)	Data  0.000 ( 0.011)	Loss 3.8847e+00 (3.8482e+00)	Loss_base 1.8053e+00 (1.7688e+00)	Loss_inst 8.8708e-01 (8.6228e-01)	Loss_obj 9.1819e-01 (9.0651e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 102/2756]	LR 1.8000000	MOM 0.9960135	Time  0.299 ( 0.336)	Data  0.000 ( 0.011)	Loss 3.9810e+00 (3.8495e+00)	Loss_base 1.9015e+00 (1.7701e+00)	Loss_inst 9.4321e-01 (8.6306e-01)	Loss_obj 9.5831e-01 (9.0701e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 103/2756]	LR 1.8000000	MOM 0.9960138	Time  0.290 ( 0.335)	Data  0.000 ( 0.011)	Loss 3.8866e+00 (3.8499e+00)	Loss_base 1.8072e+00 (1.7704e+00)	Loss_inst 8.9569e-01 (8.6338e-01)	Loss_obj 9.1152e-01 (9.0706e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 104/2756]	LR 1.8000000	MOM 0.9960140	Time  0.292 ( 0.335)	Data  0.000 ( 0.011)	Loss 3.9034e+00 (3.8504e+00)	Loss_base 1.8240e+00 (1.7709e+00)	Loss_inst 8.9755e-01 (8.6370e-01)	Loss_obj 9.2645e-01 (9.0724e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 105/2756]	LR 1.8000000	MOM 0.9960143	Time  0.290 ( 0.335)	Data  0.000 ( 0.011)	Loss 4.1393e+00 (3.8531e+00)	Loss_base 2.0599e+00 (1.7737e+00)	Loss_inst 1.0032e+00 (8.6502e-01)	Loss_obj 1.0567e+00 (9.0865e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 106/2756]	LR 1.8000000	MOM 0.9960146	Time  0.291 ( 0.334)	Data  0.000 ( 0.011)	Loss 3.9106e+00 (3.8537e+00)	Loss_base 1.8312e+00 (1.7742e+00)	Loss_inst 9.1664e-01 (8.6550e-01)	Loss_obj 9.1452e-01 (9.0871e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 107/2756]	LR 1.8000000	MOM 0.9960149	Time  0.295 ( 0.334)	Data  0.000 ( 0.010)	Loss 3.9817e+00 (3.8548e+00)	Loss_base 1.9023e+00 (1.7754e+00)	Loss_inst 9.3950e-01 (8.6618e-01)	Loss_obj 9.6280e-01 (9.0921e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 108/2756]	LR 1.8000000	MOM 0.9960151	Time  0.293 ( 0.333)	Data  0.000 ( 0.010)	Loss 3.9730e+00 (3.8559e+00)	Loss_base 1.8936e+00 (1.7765e+00)	Loss_inst 9.2917e-01 (8.6676e-01)	Loss_obj 9.6444e-01 (9.0971e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 109/2756]	LR 1.8000000	MOM 0.9960154	Time  0.292 ( 0.333)	Data  0.000 ( 0.010)	Loss 3.9856e+00 (3.8571e+00)	Loss_base 1.9061e+00 (1.7777e+00)	Loss_inst 9.4190e-01 (8.6745e-01)	Loss_obj 9.6424e-01 (9.1021e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 110/2756]	LR 1.8000000	MOM 0.9960157	Time  0.293 ( 0.333)	Data  0.000 ( 0.010)	Loss 3.9444e+00 (3.8579e+00)	Loss_base 1.8650e+00 (1.7784e+00)	Loss_inst 9.1666e-01 (8.6789e-01)	Loss_obj 9.4830e-01 (9.1055e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 111/2756]	LR 1.8000000	MOM 0.9960160	Time  0.290 ( 0.332)	Data  0.000 ( 0.010)	Loss 3.9388e+00 (3.8586e+00)	Loss_base 1.8594e+00 (1.7792e+00)	Loss_inst 9.0913e-01 (8.6826e-01)	Loss_obj 9.5028e-01 (9.1091e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 112/2756]	LR 1.8000000	MOM 0.9960163	Time  0.302 ( 0.332)	Data  0.000 ( 0.010)	Loss 4.0236e+00 (3.8601e+00)	Loss_base 1.9442e+00 (1.7806e+00)	Loss_inst 9.4851e-01 (8.6897e-01)	Loss_obj 9.9568e-01 (9.1166e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 113/2756]	LR 1.8000000	MOM 0.9960166	Time  0.294 ( 0.332)	Data  0.000 ( 0.010)	Loss 3.9885e+00 (3.8612e+00)	Loss_base 1.9091e+00 (1.7818e+00)	Loss_inst 9.3175e-01 (8.6952e-01)	Loss_obj 9.7735e-01 (9.1223e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 114/2756]	LR 1.8000000	MOM 0.9960169	Time  0.293 ( 0.331)	Data  0.000 ( 0.010)	Loss 4.0850e+00 (3.8631e+00)	Loss_base 2.0055e+00 (1.7837e+00)	Loss_inst 9.8607e-01 (8.7053e-01)	Loss_obj 1.0195e+00 (9.1317e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 115/2756]	LR 1.8000000	MOM 0.9960172	Time  0.293 ( 0.331)	Data  0.000 ( 0.010)	Loss 4.1020e+00 (3.8652e+00)	Loss_base 2.0225e+00 (1.7858e+00)	Loss_inst 9.9142e-01 (8.7157e-01)	Loss_obj 1.0311e+00 (9.1418e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 116/2756]	LR 1.8000000	MOM 0.9960175	Time  0.292 ( 0.331)	Data  0.000 ( 0.010)	Loss 3.9328e+00 (3.8658e+00)	Loss_base 1.8533e+00 (1.7863e+00)	Loss_inst 9.0570e-01 (8.7187e-01)	Loss_obj 9.4764e-01 (9.1447e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 117/2756]	LR 1.8000000	MOM 0.9960178	Time  0.292 ( 0.330)	Data  0.000 ( 0.010)	Loss 4.0081e+00 (3.8670e+00)	Loss_base 1.9286e+00 (1.7875e+00)	Loss_inst 9.4321e-01 (8.7247e-01)	Loss_obj 9.8541e-01 (9.1507e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 118/2756]	LR 1.8000000	MOM 0.9960181	Time  0.295 ( 0.330)	Data  0.000 ( 0.009)	Loss 4.0079e+00 (3.8682e+00)	Loss_base 1.9285e+00 (1.7887e+00)	Loss_inst 9.4113e-01 (8.7305e-01)	Loss_obj 9.8735e-01 (9.1568e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 119/2756]	LR 1.8000000	MOM 0.9960184	Time  0.289 ( 0.330)	Data  0.000 ( 0.009)	Loss 3.9137e+00 (3.8686e+00)	Loss_base 1.8343e+00 (1.7891e+00)	Loss_inst 8.9789e-01 (8.7325e-01)	Loss_obj 9.3639e-01 (9.1585e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 120/2756]	LR 1.8000000	MOM 0.9960187	Time  0.300 ( 0.330)	Data  0.000 ( 0.009)	Loss 3.9180e+00 (3.8690e+00)	Loss_base 1.8385e+00 (1.7895e+00)	Loss_inst 9.0175e-01 (8.7349e-01)	Loss_obj 9.3679e-01 (9.1602e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 121/2756]	LR 1.8000000	MOM 0.9960190	Time  0.300 ( 0.329)	Data  0.000 ( 0.009)	Loss 4.1529e+00 (3.8713e+00)	Loss_base 2.0734e+00 (1.7918e+00)	Loss_inst 1.0077e+00 (8.7459e-01)	Loss_obj 1.0657e+00 (9.1725e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 122/2756]	LR 1.8000000	MOM 0.9960193	Time  0.301 ( 0.329)	Data  0.000 ( 0.009)	Loss 4.1791e+00 (3.8738e+00)	Loss_base 2.0997e+00 (1.7943e+00)	Loss_inst 1.0246e+00 (8.7581e-01)	Loss_obj 1.0751e+00 (9.1853e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 123/2756]	LR 1.8000000	MOM 0.9960196	Time  0.304 ( 0.329)	Data  0.000 ( 0.009)	Loss 4.1637e+00 (3.8761e+00)	Loss_base 2.0843e+00 (1.7967e+00)	Loss_inst 1.0203e+00 (8.7698e-01)	Loss_obj 1.0639e+00 (9.1971e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 124/2756]	LR 1.8000000	MOM 0.9960199	Time  0.294 ( 0.329)	Data  0.000 ( 0.009)	Loss 3.9997e+00 (3.8771e+00)	Loss_base 1.9202e+00 (1.7977e+00)	Loss_inst 9.3348e-01 (8.7743e-01)	Loss_obj 9.8675e-01 (9.2024e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 125/2756]	LR 1.8000000	MOM 0.9960203	Time  0.300 ( 0.328)	Data  0.000 ( 0.009)	Loss 3.9919e+00 (3.8780e+00)	Loss_base 1.9125e+00 (1.7986e+00)	Loss_inst 9.2630e-01 (8.7781e-01)	Loss_obj 9.8620e-01 (9.2077e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 126/2756]	LR 1.8000000	MOM 0.9960206	Time  0.299 ( 0.328)	Data  0.000 ( 0.009)	Loss 4.0475e+00 (3.8794e+00)	Loss_base 1.9681e+00 (1.7999e+00)	Loss_inst 9.5904e-01 (8.7845e-01)	Loss_obj 1.0091e+00 (9.2146e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 127/2756]	LR 1.8000000	MOM 0.9960209	Time  0.297 ( 0.328)	Data  0.000 ( 0.009)	Loss 4.0203e+00 (3.8805e+00)	Loss_base 1.9409e+00 (1.8010e+00)	Loss_inst 9.4533e-01 (8.7898e-01)	Loss_obj 9.9558e-01 (9.2204e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 128/2756]	LR 1.8000000	MOM 0.9960213	Time  0.299 ( 0.328)	Data  0.000 ( 0.009)	Loss 3.9937e+00 (3.8813e+00)	Loss_base 1.9143e+00 (1.8019e+00)	Loss_inst 9.3317e-01 (8.7940e-01)	Loss_obj 9.8115e-01 (9.2250e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 129/2756]	LR 1.8000000	MOM 0.9960216	Time  0.296 ( 0.327)	Data  0.000 ( 0.009)	Loss 4.0651e+00 (3.8828e+00)	Loss_base 1.9857e+00 (1.8033e+00)	Loss_inst 9.6807e-01 (8.8008e-01)	Loss_obj 1.0176e+00 (9.2323e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 130/2756]	LR 1.8000000	MOM 0.9960219	Time  0.298 ( 0.327)	Data  0.000 ( 0.009)	Loss 4.0159e+00 (3.8838e+00)	Loss_base 1.9365e+00 (1.8043e+00)	Loss_inst 9.3945e-01 (8.8053e-01)	Loss_obj 9.9702e-01 (9.2379e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 131/2756]	LR 1.8000000	MOM 0.9960223	Time  0.300 ( 0.327)	Data  0.000 ( 0.009)	Loss 3.8887e+00 (3.8838e+00)	Loss_base 1.8093e+00 (1.8044e+00)	Loss_inst 8.7593e-01 (8.8050e-01)	Loss_obj 9.3336e-01 (9.2387e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 132/2756]	LR 1.8000000	MOM 0.9960226	Time  0.297 ( 0.327)	Data  0.000 ( 0.009)	Loss 3.9536e+00 (3.8843e+00)	Loss_base 1.8742e+00 (1.8049e+00)	Loss_inst 9.0692e-01 (8.8070e-01)	Loss_obj 9.6729e-01 (9.2419e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 133/2756]	LR 1.8000000	MOM 0.9960229	Time  0.300 ( 0.327)	Data  0.000 ( 0.008)	Loss 4.1684e+00 (3.8865e+00)	Loss_base 2.0889e+00 (1.8070e+00)	Loss_inst 1.0097e+00 (8.8166e-01)	Loss_obj 1.0792e+00 (9.2535e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 134/2756]	LR 1.8000000	MOM 0.9960233	Time  0.293 ( 0.326)	Data  0.000 ( 0.008)	Loss 3.9972e+00 (3.8873e+00)	Loss_base 1.9178e+00 (1.8078e+00)	Loss_inst 9.3134e-01 (8.8203e-01)	Loss_obj 9.8644e-01 (9.2580e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 135/2756]	LR 1.8000000	MOM 0.9960236	Time  0.291 ( 0.326)	Data  0.000 ( 0.008)	Loss 3.9162e+00 (3.8875e+00)	Loss_base 1.8368e+00 (1.8080e+00)	Loss_inst 8.9208e-01 (8.8210e-01)	Loss_obj 9.4468e-01 (9.2594e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 136/2756]	LR 1.8000000	MOM 0.9960240	Time  0.300 ( 0.326)	Data  0.000 ( 0.008)	Loss 4.0432e+00 (3.8886e+00)	Loss_base 1.9638e+00 (1.8092e+00)	Loss_inst 9.4875e-01 (8.8259e-01)	Loss_obj 1.0150e+00 (9.2659e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 137/2756]	LR 1.8000000	MOM 0.9960243	Time  0.297 ( 0.326)	Data  0.000 ( 0.008)	Loss 3.9922e+00 (3.8894e+00)	Loss_base 1.9127e+00 (1.8099e+00)	Loss_inst 9.2262e-01 (8.8288e-01)	Loss_obj 9.9012e-01 (9.2705e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 138/2756]	LR 1.8000000	MOM 0.9960247	Time  0.302 ( 0.325)	Data  0.000 ( 0.008)	Loss 4.1554e+00 (3.8913e+00)	Loss_base 2.0760e+00 (1.8118e+00)	Loss_inst 1.0011e+00 (8.8373e-01)	Loss_obj 1.0749e+00 (9.2811e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 139/2756]	LR 1.8000000	MOM 0.9960251	Time  0.302 ( 0.325)	Data  0.000 ( 0.008)	Loss 4.1696e+00 (3.8933e+00)	Loss_base 2.0902e+00 (1.8138e+00)	Loss_inst 1.0132e+00 (8.8465e-01)	Loss_obj 1.0770e+00 (9.2918e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 140/2756]	LR 1.8000000	MOM 0.9960254	Time  0.300 ( 0.325)	Data  0.000 ( 0.008)	Loss 3.7980e+00 (3.8926e+00)	Loss_base 1.7186e+00 (1.8132e+00)	Loss_inst 8.2989e-01 (8.8426e-01)	Loss_obj 8.8868e-01 (9.2889e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 141/2756]	LR 1.8000000	MOM 0.9960258	Time  0.299 ( 0.325)	Data  0.000 ( 0.008)	Loss 3.9613e+00 (3.8931e+00)	Loss_base 1.8819e+00 (1.8136e+00)	Loss_inst 9.1148e-01 (8.8446e-01)	Loss_obj 9.7039e-01 (9.2918e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 142/2756]	LR 1.8000000	MOM 0.9960261	Time  0.300 ( 0.325)	Data  0.000 ( 0.008)	Loss 4.1160e+00 (3.8946e+00)	Loss_base 2.0365e+00 (1.8152e+00)	Loss_inst 9.8420e-01 (8.8515e-01)	Loss_obj 1.0523e+00 (9.3004e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 143/2756]	LR 1.8000000	MOM 0.9960265	Time  0.289 ( 0.325)	Data  0.000 ( 0.008)	Loss 4.0909e+00 (3.8960e+00)	Loss_base 2.0115e+00 (1.8166e+00)	Loss_inst 9.6599e-01 (8.8571e-01)	Loss_obj 1.0455e+00 (9.3085e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 144/2756]	LR 1.8000000	MOM 0.9960269	Time  0.302 ( 0.324)	Data  0.000 ( 0.008)	Loss 3.9933e+00 (3.8967e+00)	Loss_base 1.9139e+00 (1.8172e+00)	Loss_inst 9.2938e-01 (8.8602e-01)	Loss_obj 9.8454e-01 (9.3122e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 145/2756]	LR 1.8000000	MOM 0.9960273	Time  0.300 ( 0.324)	Data  0.000 ( 0.008)	Loss 3.7954e+00 (3.8960e+00)	Loss_base 1.7160e+00 (1.8165e+00)	Loss_inst 8.2772e-01 (8.8562e-01)	Loss_obj 8.8826e-01 (9.3092e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 146/2756]	LR 1.8000000	MOM 0.9960276	Time  0.298 ( 0.324)	Data  0.000 ( 0.008)	Loss 4.3984e+00 (3.8994e+00)	Loss_base 2.3190e+00 (1.8200e+00)	Loss_inst 1.1198e+00 (8.8721e-01)	Loss_obj 1.1992e+00 (9.3275e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 147/2756]	LR 1.8000000	MOM 0.9960280	Time  0.301 ( 0.324)	Data  0.000 ( 0.008)	Loss 4.2072e+00 (3.9015e+00)	Loss_base 2.1277e+00 (1.8220e+00)	Loss_inst 1.0254e+00 (8.8814e-01)	Loss_obj 1.1023e+00 (9.3389e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 148/2756]	LR 1.8000000	MOM 0.9960284	Time  0.303 ( 0.324)	Data  0.000 ( 0.008)	Loss 4.0193e+00 (3.9023e+00)	Loss_base 1.9399e+00 (1.8228e+00)	Loss_inst 9.3029e-01 (8.8843e-01)	Loss_obj 1.0096e+00 (9.3440e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 149/2756]	LR 1.8000000	MOM 0.9960288	Time  0.301 ( 0.324)	Data  0.000 ( 0.008)	Loss 3.9798e+00 (3.9028e+00)	Loss_base 1.9004e+00 (1.8233e+00)	Loss_inst 9.1383e-01 (8.8860e-01)	Loss_obj 9.8658e-01 (9.3475e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 150/2756]	LR 1.8000000	MOM 0.9960292	Time  0.298 ( 0.323)	Data  0.000 ( 0.008)	Loss 4.1459e+00 (3.9044e+00)	Loss_base 2.0665e+00 (1.8250e+00)	Loss_inst 9.9436e-01 (8.8930e-01)	Loss_obj 1.0721e+00 (9.3566e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 151/2756]	LR 1.8000000	MOM 0.9960296	Time  0.291 ( 0.323)	Data  0.000 ( 0.007)	Loss 4.1594e+00 (3.9061e+00)	Loss_base 2.0800e+00 (1.8266e+00)	Loss_inst 1.0034e+00 (8.9005e-01)	Loss_obj 1.0766e+00 (9.3659e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 152/2756]	LR 1.8000000	MOM 0.9960299	Time  0.300 ( 0.323)	Data  0.000 ( 0.007)	Loss 3.9388e+00 (3.9063e+00)	Loss_base 1.8594e+00 (1.8268e+00)	Loss_inst 8.9630e-01 (8.9009e-01)	Loss_obj 9.6309e-01 (9.3676e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 153/2756]	LR 1.8000000	MOM 0.9960303	Time  0.305 ( 0.323)	Data  0.000 ( 0.007)	Loss 3.9548e+00 (3.9066e+00)	Loss_base 1.8754e+00 (1.8272e+00)	Loss_inst 9.0252e-01 (8.9017e-01)	Loss_obj 9.7285e-01 (9.3699e-01)	Loss_clu 4.1589e+00 (4.1589e+00)
Epoch: [0/1]	[ 154/2756]	LR 1.8000000	MOM 0.9960307	Time  0.301 ( 0.323)	Data  0.000 ( 0.007)	Loss 4.1035e+00 (3.9079e+00)	Loss_base 2.0241e+00 (1.8284e+00)	Loss_inst 9.7064e-01 (8.9069e-01)	Loss_obj 1.0534e+00 (9.3774e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 155/2756]	LR 1.8000000	MOM 0.9960311	Time  0.298 ( 0.323)	Data  0.000 ( 0.007)	Loss 3.9552e+00 (3.9082e+00)	Loss_base 1.8758e+00 (1.8287e+00)	Loss_inst 9.0565e-01 (8.9078e-01)	Loss_obj 9.7012e-01 (9.3795e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 156/2756]	LR 1.8000000	MOM 0.9960315	Time  0.300 ( 0.322)	Data  0.000 ( 0.007)	Loss 3.9858e+00 (3.9087e+00)	Loss_base 1.9064e+00 (1.8292e+00)	Loss_inst 9.1582e-01 (8.9094e-01)	Loss_obj 9.9054e-01 (9.3829e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 157/2756]	LR 1.8000000	MOM 0.9960319	Time  0.297 ( 0.322)	Data  0.000 ( 0.007)	Loss 3.7878e+00 (3.9079e+00)	Loss_base 1.7084e+00 (1.8285e+00)	Loss_inst 8.2139e-01 (8.9050e-01)	Loss_obj 8.8701e-01 (9.3796e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 158/2756]	LR 1.8000000	MOM 0.9960324	Time  0.300 ( 0.322)	Data  0.000 ( 0.007)	Loss 4.1046e+00 (3.9091e+00)	Loss_base 2.0252e+00 (1.8297e+00)	Loss_inst 9.7540e-01 (8.9104e-01)	Loss_obj 1.0498e+00 (9.3867e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 159/2756]	LR 1.8000000	MOM 0.9960328	Time  0.295 ( 0.322)	Data  0.000 ( 0.007)	Loss 4.1262e+00 (3.9105e+00)	Loss_base 2.0468e+00 (1.8311e+00)	Loss_inst 9.8262e-01 (8.9161e-01)	Loss_obj 1.0642e+00 (9.3945e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 160/2756]	LR 1.8000000	MOM 0.9960332	Time  0.298 ( 0.322)	Data  0.000 ( 0.007)	Loss 3.9056e+00 (3.9105e+00)	Loss_base 1.8262e+00 (1.8310e+00)	Loss_inst 8.7385e-01 (8.9150e-01)	Loss_obj 9.5233e-01 (9.3953e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 161/2756]	LR 1.8000000	MOM 0.9960336	Time  0.301 ( 0.322)	Data  0.000 ( 0.007)	Loss 3.8491e+00 (3.9101e+00)	Loss_base 1.7697e+00 (1.8307e+00)	Loss_inst 8.4756e-01 (8.9123e-01)	Loss_obj 9.2215e-01 (9.3942e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 162/2756]	LR 1.8000000	MOM 0.9960340	Time  0.298 ( 0.322)	Data  0.001 ( 0.007)	Loss 4.1482e+00 (3.9116e+00)	Loss_base 2.0688e+00 (1.8321e+00)	Loss_inst 9.9801e-01 (8.9188e-01)	Loss_obj 1.0708e+00 (9.4023e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 163/2756]	LR 1.8000000	MOM 0.9960344	Time  0.300 ( 0.321)	Data  0.000 ( 0.007)	Loss 3.9749e+00 (3.9119e+00)	Loss_base 1.8955e+00 (1.8325e+00)	Loss_inst 9.1482e-01 (8.9202e-01)	Loss_obj 9.8070e-01 (9.4048e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 164/2756]	LR 1.8000000	MOM 0.9960348	Time  0.301 ( 0.321)	Data  0.001 ( 0.007)	Loss 4.0350e+00 (3.9127e+00)	Loss_base 1.9556e+00 (1.8332e+00)	Loss_inst 9.4406e-01 (8.9234e-01)	Loss_obj 1.0115e+00 (9.4091e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 165/2756]	LR 1.8000000	MOM 0.9960353	Time  0.299 ( 0.321)	Data  0.000 ( 0.007)	Loss 3.7511e+00 (3.9117e+00)	Loss_base 1.6717e+00 (1.8323e+00)	Loss_inst 8.0245e-01 (8.9180e-01)	Loss_obj 8.6925e-01 (9.4047e-01)	Loss_clu 4.1587e+00 (4.1589e+00)
Epoch: [0/1]	[ 166/2756]	LR 1.8000000	MOM 0.9960357	Time  0.302 ( 0.321)	Data  0.000 ( 0.007)	Loss 3.9621e+00 (3.9120e+00)	Loss_base 1.8827e+00 (1.8326e+00)	Loss_inst 9.0470e-01 (8.9187e-01)	Loss_obj 9.7803e-01 (9.4070e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 167/2756]	LR 1.8000000	MOM 0.9960361	Time  0.297 ( 0.321)	Data  0.001 ( 0.007)	Loss 3.5885e+00 (3.9101e+00)	Loss_base 1.5091e+00 (1.8306e+00)	Loss_inst 7.2273e-01 (8.9087e-01)	Loss_obj 7.8638e-01 (9.3978e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 168/2756]	LR 1.8000000	MOM 0.9960366	Time  0.301 ( 0.321)	Data  0.000 ( 0.007)	Loss 3.7488e+00 (3.9091e+00)	Loss_base 1.6694e+00 (1.8297e+00)	Loss_inst 8.0215e-01 (8.9034e-01)	Loss_obj 8.6721e-01 (9.3935e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 169/2756]	LR 1.8000000	MOM 0.9960370	Time  0.298 ( 0.321)	Data  0.000 ( 0.007)	Loss 3.7388e+00 (3.9081e+00)	Loss_base 1.6594e+00 (1.8287e+00)	Loss_inst 7.9690e-01 (8.8979e-01)	Loss_obj 8.6251e-01 (9.3890e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 170/2756]	LR 1.8000000	MOM 0.9960374	Time  0.301 ( 0.321)	Data  0.000 ( 0.007)	Loss 4.0853e+00 (3.9092e+00)	Loss_base 2.0059e+00 (1.8297e+00)	Loss_inst 9.6968e-01 (8.9026e-01)	Loss_obj 1.0362e+00 (9.3947e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 171/2756]	LR 1.8000000	MOM 0.9960379	Time  0.302 ( 0.320)	Data  0.000 ( 0.007)	Loss 3.8833e+00 (3.9090e+00)	Loss_base 1.8039e+00 (1.8296e+00)	Loss_inst 8.6754e-01 (8.9013e-01)	Loss_obj 9.3634e-01 (9.3945e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 172/2756]	LR 1.8000000	MOM 0.9960383	Time  0.302 ( 0.320)	Data  0.000 ( 0.007)	Loss 3.6528e+00 (3.9075e+00)	Loss_base 1.5734e+00 (1.8281e+00)	Loss_inst 7.4921e-01 (8.8931e-01)	Loss_obj 8.2416e-01 (9.3878e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 173/2756]	LR 1.8000000	MOM 0.9960388	Time  0.298 ( 0.320)	Data  0.000 ( 0.007)	Loss 3.7976e+00 (3.9069e+00)	Loss_base 1.7182e+00 (1.8275e+00)	Loss_inst 8.2649e-01 (8.8895e-01)	Loss_obj 8.9171e-01 (9.3851e-01)	Loss_clu 4.1588e+00 (4.1589e+00)
Epoch: [0/1]	[ 174/2756]	LR 1.8000000	MOM 0.9960392	Time  0.301 ( 0.320)	Data  0.000 ( 0.007)	Loss 3.5294e+00 (3.9047e+00)	Loss_base 1.4500e+00 (1.8253e+00)	Loss_inst 6.9489e-01 (8.8784e-01)	Loss_obj 7.5515e-01 (9.3747e-01)	Loss_clu 4.1587e+00 (4.1589e+00)
Epoch: [0/1]	[ 175/2756]	LR 1.8000000	MOM 0.9960397	Time  0.299 ( 0.320)	Data  0.000 ( 0.006)	Loss 4.1796e+00 (3.9063e+00)	Loss_base 2.1003e+00 (1.8269e+00)	Loss_inst 1.0139e+00 (8.8856e-01)	Loss_obj 1.0863e+00 (9.3831e-01)	Loss_clu 4.1587e+00 (4.1589e+00)
Epoch: [0/1]	[ 176/2756]	LR 1.8000000	MOM 0.9960401	Time  0.300 ( 0.320)	Data  0.000 ( 0.006)	Loss 3.8052e+00 (3.9057e+00)	Loss_base 1.7258e+00 (1.8263e+00)	Loss_inst 8.2581e-01 (8.8820e-01)	Loss_obj 9.0004e-01 (9.3810e-01)	Loss_clu 4.1587e+00 (4.1589e+00)
Epoch: [0/1]	[ 177/2756]	LR 1.8000000	MOM 0.9960406	Time  0.300 ( 0.320)	Data  0.000 ( 0.006)	Loss 4.1288e+00 (3.9070e+00)	Loss_base 2.0494e+00 (1.8276e+00)	Loss_inst 9.9218e-01 (8.8879e-01)	Loss_obj 1.0572e+00 (9.3876e-01)	Loss_clu 4.1587e+00 (4.1589e+00)
Epoch: [0/1]	[ 178/2756]	LR 1.8000000	MOM 0.9960410	Time  0.298 ( 0.320)	Data  0.000 ( 0.006)	Loss 3.7784e+00 (3.9063e+00)	Loss_base 1.6991e+00 (1.8268e+00)	Loss_inst 8.2138e-01 (8.8841e-01)	Loss_obj 8.7775e-01 (9.3842e-01)	Loss_clu 4.1586e+00 (4.1589e+00)
Epoch: [0/1]	[ 179/2756]	LR 1.8000000	MOM 0.9960415	Time  0.306 ( 0.320)	Data  0.000 ( 0.006)	Loss 3.4526e+00 (3.9038e+00)	Loss_base 1.3732e+00 (1.8243e+00)	Loss_inst 6.6012e-01 (8.8714e-01)	Loss_obj 7.1312e-01 (9.3717e-01)	Loss_clu 4.1587e+00 (4.1589e+00)
Epoch: [0/1]	[ 180/2756]	LR 1.8000000	MOM 0.9960420	Time  0.301 ( 0.319)	Data  0.000 ( 0.006)	Loss 3.7049e+00 (3.9027e+00)	Loss_base 1.6256e+00 (1.8232e+00)	Loss_inst 7.7932e-01 (8.8655e-01)	Loss_obj 8.4623e-01 (9.3667e-01)	Loss_clu 4.1587e+00 (4.1589e+00)
Epoch: [0/1]	[ 181/2756]	LR 1.8000000	MOM 0.9960424	Time  0.298 ( 0.319)	Data  0.000 ( 0.006)	Loss 3.8851e+00 (3.9026e+00)	Loss_base 1.8059e+00 (1.8231e+00)	Loss_inst 8.6862e-01 (8.8645e-01)	Loss_obj 9.3730e-01 (9.3667e-01)	Loss_clu 4.1585e+00 (4.1589e+00)
Epoch: [0/1]	[ 182/2756]	LR 1.8000000	MOM 0.9960429	Time  0.301 ( 0.319)	Data  0.000 ( 0.006)	Loss 3.8907e+00 (3.9025e+00)	Loss_base 1.8115e+00 (1.8231e+00)	Loss_inst 8.7209e-01 (8.8637e-01)	Loss_obj 9.3939e-01 (9.3669e-01)	Loss_clu 4.1585e+00 (4.1589e+00)
Epoch: [0/1]	[ 183/2756]	LR 1.8000000	MOM 0.9960434	Time  0.300 ( 0.319)	Data  0.000 ( 0.006)	Loss 3.7946e+00 (3.9019e+00)	Loss_base 1.7153e+00 (1.8225e+00)	Loss_inst 8.2296e-01 (8.8603e-01)	Loss_obj 8.9235e-01 (9.3645e-01)	Loss_clu 4.1586e+00 (4.1589e+00)
Epoch: [0/1]	[ 184/2756]	LR 1.8000000	MOM 0.9960438	Time  0.301 ( 0.319)	Data  0.000 ( 0.006)	Loss 3.6633e+00 (3.9006e+00)	Loss_base 1.5840e+00 (1.8212e+00)	Loss_inst 7.6076e-01 (8.8535e-01)	Loss_obj 8.2322e-01 (9.3583e-01)	Loss_clu 4.1585e+00 (4.1589e+00)
Epoch: [0/1]	[ 185/2756]	LR 1.8000000	MOM 0.9960443	Time  0.301 ( 0.319)	Data  0.000 ( 0.006)	Loss 3.8542e+00 (3.9004e+00)	Loss_base 1.7749e+00 (1.8209e+00)	Loss_inst 8.5766e-01 (8.8520e-01)	Loss_obj 9.1728e-01 (9.3573e-01)	Loss_clu 4.1586e+00 (4.1589e+00)
Epoch: [0/1]	[ 186/2756]	LR 1.8000000	MOM 0.9960448	Time  0.298 ( 0.319)	Data  0.000 ( 0.006)	Loss 3.7186e+00 (3.8994e+00)	Loss_base 1.6392e+00 (1.8200e+00)	Loss_inst 7.9145e-01 (8.8470e-01)	Loss_obj 8.4780e-01 (9.3526e-01)	Loss_clu 4.1586e+00 (4.1589e+00)
Epoch: [0/1]	[ 187/2756]	LR 1.8000000	MOM 0.9960453	Time  0.302 ( 0.319)	Data  0.000 ( 0.006)	Loss 3.8503e+00 (3.8991e+00)	Loss_base 1.7710e+00 (1.8197e+00)	Loss_inst 8.5543e-01 (8.8454e-01)	Loss_obj 9.1561e-01 (9.3516e-01)	Loss_clu 4.1586e+00 (4.1589e+00)
Epoch: [0/1]	[ 188/2756]	LR 1.8000000	MOM 0.9960458	Time  0.298 ( 0.319)	Data  0.000 ( 0.006)	Loss 3.7936e+00 (3.8986e+00)	Loss_base 1.7143e+00 (1.8191e+00)	Loss_inst 8.2307e-01 (8.8422e-01)	Loss_obj 8.9123e-01 (9.3493e-01)	Loss_clu 4.1586e+00 (4.1589e+00)
Epoch: [0/1]	[ 189/2756]	LR 1.8000000	MOM 0.9960462	Time  0.300 ( 0.319)	Data  0.000 ( 0.006)	Loss 3.6237e+00 (3.8971e+00)	Loss_base 1.5445e+00 (1.8177e+00)	Loss_inst 7.4021e-01 (8.8346e-01)	Loss_obj 8.0431e-01 (9.3424e-01)	Loss_clu 4.1584e+00 (4.1589e+00)
Epoch: [0/1]	[ 190/2756]	LR 1.8000000	MOM 0.9960467	Time  0.300 ( 0.318)	Data  0.000 ( 0.006)	Loss 3.5963e+00 (3.8956e+00)	Loss_base 1.5171e+00 (1.8161e+00)	Loss_inst 7.2659e-01 (8.8264e-01)	Loss_obj 7.9051e-01 (9.3349e-01)	Loss_clu 4.1584e+00 (4.1589e+00)
Epoch: [0/1]	[ 191/2756]	LR 1.8000000	MOM 0.9960472	Time  0.301 ( 0.318)	Data  0.000 ( 0.006)	Loss 3.6831e+00 (3.8944e+00)	Loss_base 1.6038e+00 (1.8150e+00)	Loss_inst 7.6942e-01 (8.8205e-01)	Loss_obj 8.3439e-01 (9.3297e-01)	Loss_clu 4.1585e+00 (4.1589e+00)
Epoch: [0/1]	[ 192/2756]	LR 1.8000000	MOM 0.9960477	Time  0.300 ( 0.318)	Data  0.000 ( 0.006)	Loss 3.6261e+00 (3.8931e+00)	Loss_base 1.5469e+00 (1.8136e+00)	Loss_inst 7.4486e-01 (8.8134e-01)	Loss_obj 8.0204e-01 (9.3229e-01)	Loss_clu 4.1584e+00 (4.1588e+00)
Epoch: [0/1]	[ 193/2756]	LR 1.8000000	MOM 0.9960482	Time  0.298 ( 0.318)	Data  0.000 ( 0.006)	Loss 3.8286e+00 (3.8927e+00)	Loss_base 1.7494e+00 (1.8133e+00)	Loss_inst 8.4587e-01 (8.8116e-01)	Loss_obj 9.0349e-01 (9.3214e-01)	Loss_clu 4.1584e+00 (4.1588e+00)
Epoch: [0/1]	[ 194/2756]	LR 1.8000000	MOM 0.9960487	Time  0.301 ( 0.318)	Data  0.000 ( 0.006)	Loss 3.6911e+00 (3.8917e+00)	Loss_base 1.6119e+00 (1.8123e+00)	Loss_inst 7.7574e-01 (8.8062e-01)	Loss_obj 8.3617e-01 (9.3165e-01)	Loss_clu 4.1584e+00 (4.1588e+00)
Epoch: [0/1]	[ 195/2756]	LR 1.8000000	MOM 0.9960492	Time  0.300 ( 0.318)	Data  0.000 ( 0.006)	Loss 3.5942e+00 (3.8902e+00)	Loss_base 1.5151e+00 (1.8108e+00)	Loss_inst 7.2742e-01 (8.7983e-01)	Loss_obj 7.8764e-01 (9.3092e-01)	Loss_clu 4.1582e+00 (4.1588e+00)
Epoch: [0/1]	[ 196/2756]	LR 1.8000000	MOM 0.9960497	Time  0.300 ( 0.318)	Data  0.000 ( 0.006)	Loss 3.6056e+00 (3.8887e+00)	Loss_base 1.5264e+00 (1.8093e+00)	Loss_inst 7.3793e-01 (8.7911e-01)	Loss_obj 7.8843e-01 (9.3019e-01)	Loss_clu 4.1584e+00 (4.1588e+00)
Epoch: [0/1]	[ 197/2756]	LR 1.8000000	MOM 0.9960502	Time  0.300 ( 0.318)	Data  0.000 ( 0.006)	Loss 3.8315e+00 (3.8884e+00)	Loss_base 1.7523e+00 (1.8090e+00)	Loss_inst 8.4252e-01 (8.7893e-01)	Loss_obj 9.0982e-01 (9.3009e-01)	Loss_clu 4.1583e+00 (4.1588e+00)
Epoch: [0/1]	[ 198/2756]	LR 1.8000000	MOM 0.9960507	Time  0.297 ( 0.318)	Data  0.000 ( 0.006)	Loss 3.6063e+00 (3.8870e+00)	Loss_base 1.5272e+00 (1.8076e+00)	Loss_inst 7.3509e-01 (8.7821e-01)	Loss_obj 7.9207e-01 (9.2940e-01)	Loss_clu 4.1583e+00 (4.1588e+00)
Epoch: [0/1]	[ 199/2756]	LR 1.8000000	MOM 0.9960512	Time  0.299 ( 0.318)	Data  0.000 ( 0.006)	Loss 3.6033e+00 (3.8856e+00)	Loss_base 1.5241e+00 (1.8062e+00)	Loss_inst 7.3189e-01 (8.7747e-01)	Loss_obj 7.9222e-01 (9.2871e-01)	Loss_clu 4.1584e+00 (4.1588e+00)
Epoch: [0/1]	[ 200/2756]	LR 1.8000000	MOM 0.9960518	Time  0.300 ( 0.318)	Data  0.000 ( 0.006)	Loss 3.4842e+00 (3.8836e+00)	Loss_base 1.4050e+00 (1.8042e+00)	Loss_inst 6.7772e-01 (8.7648e-01)	Loss_obj 7.2729e-01 (9.2771e-01)	Loss_clu 4.1583e+00 (4.1588e+00)
Epoch: [0/1]	[ 201/2756]	LR 1.8000000	MOM 0.9960523	Time  0.300 ( 0.317)	Data  0.000 ( 0.006)	Loss 3.5973e+00 (3.8822e+00)	Loss_base 1.5182e+00 (1.8028e+00)	Loss_inst 7.3108e-01 (8.7576e-01)	Loss_obj 7.8708e-01 (9.2701e-01)	Loss_clu 4.1583e+00 (4.1588e+00)
Epoch: [0/1]	[ 202/2756]	LR 1.8000000	MOM 0.9960528	Time  0.301 ( 0.317)	Data  0.000 ( 0.006)	Loss 3.4213e+00 (3.8799e+00)	Loss_base 1.3423e+00 (1.8005e+00)	Loss_inst 6.4471e-01 (8.7462e-01)	Loss_obj 6.9758e-01 (9.2588e-01)	Loss_clu 4.1580e+00 (4.1588e+00)
Epoch: [0/1]	[ 203/2756]	LR 1.8000000	MOM 0.9960533	Time  0.301 ( 0.317)	Data  0.000 ( 0.006)	Loss 4.0200e+00 (3.8806e+00)	Loss_base 1.9408e+00 (1.8012e+00)	Loss_inst 9.3382e-01 (8.7491e-01)	Loss_obj 1.0070e+00 (9.2628e-01)	Loss_clu 4.1584e+00 (4.1588e+00)
Epoch: [0/1]	[ 204/2756]	LR 1.8000000	MOM 0.9960538	Time  0.300 ( 0.317)	Data  0.000 ( 0.006)	Loss 3.7036e+00 (3.8797e+00)	Loss_base 1.6244e+00 (1.8003e+00)	Loss_inst 7.8251e-01 (8.7446e-01)	Loss_obj 8.4189e-01 (9.2587e-01)	Loss_clu 4.1585e+00 (4.1588e+00)
Epoch: [0/1]	[ 205/2756]	LR 1.8000000	MOM 0.9960544	Time  0.300 ( 0.317)	Data  0.000 ( 0.006)	Loss 3.5556e+00 (3.8782e+00)	Loss_base 1.4764e+00 (1.7988e+00)	Loss_inst 7.1087e-01 (8.7367e-01)	Loss_obj 7.6558e-01 (9.2509e-01)	Loss_clu 4.1582e+00 (4.1588e+00)
Epoch: [0/1]	[ 206/2756]	LR 1.8000000	MOM 0.9960549	Time  0.303 ( 0.317)	Data  0.000 ( 0.006)	Loss 3.6304e+00 (3.8770e+00)	Loss_base 1.5514e+00 (1.7976e+00)	Loss_inst 7.4532e-01 (8.7305e-01)	Loss_obj 8.0607e-01 (9.2452e-01)	Loss_clu 4.1581e+00 (4.1588e+00)
Epoch: [0/1]	[ 207/2756]	LR 1.8000000	MOM 0.9960554	Time  0.299 ( 0.317)	Data  0.000 ( 0.006)	Loss 3.7482e+00 (3.8764e+00)	Loss_base 1.6691e+00 (1.7969e+00)	Loss_inst 8.0694e-01 (8.7273e-01)	Loss_obj 8.6215e-01 (9.2422e-01)	Loss_clu 4.1582e+00 (4.1588e+00)
Epoch: [0/1]	[ 208/2756]	LR 1.8000000	MOM 0.9960560	Time  0.302 ( 0.317)	Data  0.000 ( 0.006)	Loss 3.5310e+00 (3.8747e+00)	Loss_base 1.4520e+00 (1.7953e+00)	Loss_inst 6.9307e-01 (8.7187e-01)	Loss_obj 7.5889e-01 (9.2343e-01)	Loss_clu 4.1581e+00 (4.1588e+00)
Epoch: [0/1]	[ 209/2756]	LR 1.8000000	MOM 0.9960565	Time  0.301 ( 0.317)	Data  0.000 ( 0.005)	Loss 3.4638e+00 (3.8727e+00)	Loss_base 1.3848e+00 (1.7933e+00)	Loss_inst 6.6801e-01 (8.7090e-01)	Loss_obj 7.1680e-01 (9.2244e-01)	Loss_clu 4.1580e+00 (4.1588e+00)
Epoch: [0/1]	[ 210/2756]	LR 1.8000000	MOM 0.9960570	Time  0.300 ( 0.317)	Data  0.000 ( 0.005)	Loss 3.6104e+00 (3.8715e+00)	Loss_base 1.5313e+00 (1.7921e+00)	Loss_inst 7.3835e-01 (8.7027e-01)	Loss_obj 7.9298e-01 (9.2183e-01)	Loss_clu 4.1581e+00 (4.1588e+00)
Epoch: [0/1]	[ 211/2756]	LR 1.8000000	MOM 0.9960576	Time  0.301 ( 0.317)	Data  0.000 ( 0.005)	Loss 3.7764e+00 (3.8711e+00)	Loss_base 1.6972e+00 (1.7917e+00)	Loss_inst 8.1806e-01 (8.7003e-01)	Loss_obj 8.7916e-01 (9.2163e-01)	Loss_clu 4.1583e+00 (4.1588e+00)
Epoch: [0/1]	[ 212/2756]	LR 1.8000000	MOM 0.9960581	Time  0.299 ( 0.317)	Data  0.000 ( 0.005)	Loss 3.6734e+00 (3.8701e+00)	Loss_base 1.5944e+00 (1.7907e+00)	Loss_inst 7.6601e-01 (8.6954e-01)	Loss_obj 8.2837e-01 (9.2119e-01)	Loss_clu 4.1580e+00 (4.1588e+00)
Epoch: [0/1]	[ 213/2756]	LR 1.8000000	MOM 0.9960587	Time  0.300 ( 0.316)	Data  0.000 ( 0.005)	Loss 3.7606e+00 (3.8696e+00)	Loss_base 1.6817e+00 (1.7902e+00)	Loss_inst 8.1032e-01 (8.6926e-01)	Loss_obj 8.7133e-01 (9.2096e-01)	Loss_clu 4.1579e+00 (4.1588e+00)
Epoch: [0/1]	[ 214/2756]	LR 1.8000000	MOM 0.9960592	Time  0.300 ( 0.316)	Data  0.000 ( 0.005)	Loss 3.5598e+00 (3.8682e+00)	Loss_base 1.4809e+00 (1.7888e+00)	Loss_inst 7.1587e-01 (8.6855e-01)	Loss_obj 7.6498e-01 (9.2023e-01)	Loss_clu 4.1580e+00 (4.1588e+00)
Epoch: [0/1]	[ 215/2756]	LR 1.8000000	MOM 0.9960598	Time  0.297 ( 0.316)	Data  0.000 ( 0.005)	Loss 3.5743e+00 (3.8668e+00)	Loss_base 1.4953e+00 (1.7874e+00)	Loss_inst 7.2044e-01 (8.6786e-01)	Loss_obj 7.7482e-01 (9.1956e-01)	Loss_clu 4.1581e+00 (4.1588e+00)
Epoch: [0/1]	[ 216/2756]	LR 1.8000000	MOM 0.9960603	Time  0.298 ( 0.316)	Data  0.000 ( 0.005)	Loss 3.5607e+00 (3.8654e+00)	Loss_base 1.4817e+00 (1.7860e+00)	Loss_inst 7.1317e-01 (8.6715e-01)	Loss_obj 7.6851e-01 (9.1886e-01)	Loss_clu 4.1580e+00 (4.1588e+00)
Epoch: [0/1]	[ 217/2756]	LR 1.8000000	MOM 0.9960609	Time  0.301 ( 0.316)	Data  0.000 ( 0.005)	Loss 3.4906e+00 (3.8637e+00)	Loss_base 1.4115e+00 (1.7843e+00)	Loss_inst 6.7737e-01 (8.6628e-01)	Loss_obj 7.3414e-01 (9.1801e-01)	Loss_clu 4.1581e+00 (4.1588e+00)
Epoch: [0/1]	[ 218/2756]	LR 1.8000000	MOM 0.9960614	Time  0.301 ( 0.316)	Data  0.000 ( 0.005)	Loss 3.5663e+00 (3.8623e+00)	Loss_base 1.4871e+00 (1.7829e+00)	Loss_inst 7.1732e-01 (8.6560e-01)	Loss_obj 7.6975e-01 (9.1734e-01)	Loss_clu 4.1584e+00 (4.1588e+00)
Epoch: [0/1]	[ 219/2756]	LR 1.8000000	MOM 0.9960620	Time  0.303 ( 0.316)	Data  0.000 ( 0.005)	Loss 3.6965e+00 (3.8616e+00)	Loss_base 1.6178e+00 (1.7822e+00)	Loss_inst 7.7815e-01 (8.6520e-01)	Loss_obj 8.3960e-01 (9.1698e-01)	Loss_clu 4.1575e+00 (4.1588e+00)
Epoch: [0/1]	[ 220/2756]	LR 1.8000000	MOM 0.9960626	Time  0.295 ( 0.316)	Data  0.000 ( 0.005)	Loss 3.7509e+00 (3.8611e+00)	Loss_base 1.6720e+00 (1.7817e+00)	Loss_inst 8.1223e-01 (8.6496e-01)	Loss_obj 8.5976e-01 (9.1672e-01)	Loss_clu 4.1578e+00 (4.1588e+00)
Epoch: [0/1]	[ 221/2756]	LR 1.8000000	MOM 0.9960631	Time  0.302 ( 0.316)	Data  0.000 ( 0.005)	Loss 3.7856e+00 (3.8607e+00)	Loss_base 1.7065e+00 (1.7813e+00)	Loss_inst 8.2723e-01 (8.6479e-01)	Loss_obj 8.7925e-01 (9.1656e-01)	Loss_clu 4.1583e+00 (4.1588e+00)
Epoch: [0/1]	[ 222/2756]	LR 1.8000000	MOM 0.9960637	Time  0.302 ( 0.316)	Data  0.000 ( 0.005)	Loss 3.3925e+00 (3.8586e+00)	Loss_base 1.3136e+00 (1.7792e+00)	Loss_inst 6.3421e-01 (8.6376e-01)	Loss_obj 6.7935e-01 (9.1549e-01)	Loss_clu 4.1579e+00 (4.1588e+00)
Epoch: [0/1]	[ 223/2756]	LR 1.8000000	MOM 0.9960643	Time  0.302 ( 0.316)	Data  0.000 ( 0.005)	Loss 3.5227e+00 (3.8571e+00)	Loss_base 1.4439e+00 (1.7778e+00)	Loss_inst 6.9913e-01 (8.6302e-01)	Loss_obj 7.4473e-01 (9.1473e-01)	Loss_clu 4.1577e+00 (4.1588e+00)
Epoch: [0/1]	[ 224/2756]	LR 1.8000000	MOM 0.9960648	Time  0.299 ( 0.316)	Data  0.000 ( 0.005)	Loss 3.4814e+00 (3.8555e+00)	Loss_base 1.4025e+00 (1.7761e+00)	Loss_inst 6.7751e-01 (8.6220e-01)	Loss_obj 7.2500e-01 (9.1389e-01)	Loss_clu 4.1578e+00 (4.1587e+00)
Epoch: [0/1]	[ 225/2756]	LR 1.8000000	MOM 0.9960654	Time  0.301 ( 0.316)	Data  0.000 ( 0.005)	Loss 3.4828e+00 (3.8538e+00)	Loss_base 1.4039e+00 (1.7744e+00)	Loss_inst 6.7626e-01 (8.6137e-01)	Loss_obj 7.2759e-01 (9.1306e-01)	Loss_clu 4.1578e+00 (4.1587e+00)
Epoch: [0/1]	[ 226/2756]	LR 1.8000000	MOM 0.9960660	Time  0.302 ( 0.316)	Data  0.000 ( 0.005)	Loss 3.4597e+00 (3.8521e+00)	Loss_base 1.3811e+00 (1.7727e+00)	Loss_inst 6.6762e-01 (8.6052e-01)	Loss_obj 7.1348e-01 (9.1218e-01)	Loss_clu 4.1572e+00 (4.1587e+00)
Epoch: [0/1]	[ 227/2756]	LR 1.8000000	MOM 0.9960666	Time  0.299 ( 0.315)	Data  0.000 ( 0.005)	Loss 3.4715e+00 (3.8504e+00)	Loss_base 1.3929e+00 (1.7710e+00)	Loss_inst 6.7247e-01 (8.5970e-01)	Loss_obj 7.2041e-01 (9.1134e-01)	Loss_clu 4.1573e+00 (4.1587e+00)
Epoch: [0/1]	[ 228/2756]	LR 1.8000000	MOM 0.9960672	Time  0.300 ( 0.315)	Data  0.000 ( 0.005)	Loss 3.5579e+00 (3.8491e+00)	Loss_base 1.4793e+00 (1.7698e+00)	Loss_inst 7.1617e-01 (8.5907e-01)	Loss_obj 7.6315e-01 (9.1069e-01)	Loss_clu 4.1571e+00 (4.1587e+00)
Epoch: [0/1]	[ 229/2756]	LR 1.8000000	MOM 0.9960678	Time  0.300 ( 0.315)	Data  0.000 ( 0.005)	Loss 3.3772e+00 (3.8471e+00)	Loss_base 1.2989e+00 (1.7677e+00)	Loss_inst 6.2687e-01 (8.5806e-01)	Loss_obj 6.7202e-01 (9.0966e-01)	Loss_clu 4.1566e+00 (4.1587e+00)
Epoch: [0/1]	[ 230/2756]	LR 1.8000000	MOM 0.9960683	Time  0.298 ( 0.315)	Data  0.000 ( 0.005)	Loss 3.6889e+00 (3.8464e+00)	Loss_base 1.6102e+00 (1.7670e+00)	Loss_inst 7.8118e-01 (8.5773e-01)	Loss_obj 8.2907e-01 (9.0931e-01)	Loss_clu 4.1572e+00 (4.1587e+00)
Epoch: [0/1]	[ 231/2756]	LR 1.8000000	MOM 0.9960689	Time  0.300 ( 0.315)	Data  0.000 ( 0.005)	Loss 3.6178e+00 (3.8454e+00)	Loss_base 1.5392e+00 (1.7661e+00)	Loss_inst 7.5225e-01 (8.5727e-01)	Loss_obj 7.8696e-01 (9.0878e-01)	Loss_clu 4.1571e+00 (4.1587e+00)
Epoch: [0/1]	[ 232/2756]	LR 1.8000000	MOM 0.9960695	Time  0.301 ( 0.315)	Data  0.000 ( 0.005)	Loss 3.3239e+00 (3.8432e+00)	Loss_base 1.2457e+00 (1.7638e+00)	Loss_inst 6.0244e-01 (8.5618e-01)	Loss_obj 6.4322e-01 (9.0764e-01)	Loss_clu 4.1565e+00 (4.1587e+00)
Epoch: [0/1]	[ 233/2756]	LR 1.8000000	MOM 0.9960701	Time  0.304 ( 0.315)	Data  0.000 ( 0.005)	Loss 3.6142e+00 (3.8422e+00)	Loss_base 1.5355e+00 (1.7628e+00)	Loss_inst 7.4256e-01 (8.5569e-01)	Loss_obj 7.9291e-01 (9.0715e-01)	Loss_clu 4.1574e+00 (4.1587e+00)
Epoch: [0/1]	[ 234/2756]	LR 1.8000000	MOM 0.9960707	Time  0.301 ( 0.315)	Data  0.000 ( 0.005)	Loss 3.5146e+00 (3.8408e+00)	Loss_base 1.4361e+00 (1.7615e+00)	Loss_inst 6.9540e-01 (8.5501e-01)	Loss_obj 7.4066e-01 (9.0644e-01)	Loss_clu 4.1570e+00 (4.1587e+00)
Epoch: [0/1]	[ 235/2756]	LR 1.8000000	MOM 0.9960713	Time  0.302 ( 0.315)	Data  0.000 ( 0.005)	Loss 3.3762e+00 (3.8388e+00)	Loss_base 1.2974e+00 (1.7595e+00)	Loss_inst 6.3168e-01 (8.5406e-01)	Loss_obj 6.6575e-01 (9.0542e-01)	Loss_clu 4.1576e+00 (4.1587e+00)
Epoch: [0/1]	[ 236/2756]	LR 1.8000000	MOM 0.9960719	Time  0.298 ( 0.315)	Data  0.000 ( 0.005)	Loss 3.4906e+00 (3.8374e+00)	Loss_base 1.4122e+00 (1.7580e+00)	Loss_inst 6.8239e-01 (8.5334e-01)	Loss_obj 7.2980e-01 (9.0468e-01)	Loss_clu 4.1567e+00 (4.1587e+00)
Epoch: [0/1]	[ 237/2756]	LR 1.8000000	MOM 0.9960725	Time  0.301 ( 0.315)	Data  0.000 ( 0.005)	Loss 3.5121e+00 (3.8360e+00)	Loss_base 1.4339e+00 (1.7567e+00)	Loss_inst 6.8988e-01 (8.5265e-01)	Loss_obj 7.4399e-01 (9.0401e-01)	Loss_clu 4.1565e+00 (4.1587e+00)
Epoch: [0/1]	[ 238/2756]	LR 1.8000000	MOM 0.9960732	Time  0.298 ( 0.315)	Data  0.000 ( 0.005)	Loss 3.3907e+00 (3.8341e+00)	Loss_base 1.3124e+00 (1.7548e+00)	Loss_inst 6.3522e-01 (8.5174e-01)	Loss_obj 6.7720e-01 (9.0306e-01)	Loss_clu 4.1565e+00 (4.1586e+00)
Epoch: [0/1]	[ 239/2756]	LR 1.8000000	MOM 0.9960738	Time  0.303 ( 0.315)	Data  0.000 ( 0.005)	Loss 3.3295e+00 (3.8320e+00)	Loss_base 1.2509e+00 (1.7527e+00)	Loss_inst 6.0337e-01 (8.5071e-01)	Loss_obj 6.4758e-01 (9.0199e-01)	Loss_clu 4.1570e+00 (4.1586e+00)
Epoch: [0/1]	[ 240/2756]	LR 1.8000000	MOM 0.9960744	Time  0.299 ( 0.315)	Data  0.000 ( 0.005)	Loss 3.4145e+00 (3.8303e+00)	Loss_base 1.3362e+00 (1.7510e+00)	Loss_inst 6.5113e-01 (8.4988e-01)	Loss_obj 6.8512e-01 (9.0109e-01)	Loss_clu 4.1565e+00 (4.1586e+00)
Epoch: [0/1]	[ 241/2756]	LR 1.8000000	MOM 0.9960750	Time  0.301 ( 0.315)	Data  0.000 ( 0.005)	Loss 3.2999e+00 (3.8281e+00)	Loss_base 1.2214e+00 (1.7488e+00)	Loss_inst 5.9363e-01 (8.4882e-01)	Loss_obj 6.2780e-01 (8.9996e-01)	Loss_clu 4.1570e+00 (4.1586e+00)
Epoch: [0/1]	[ 242/2756]	LR 1.8000000	MOM 0.9960756	Time  0.302 ( 0.315)	Data  0.000 ( 0.005)	Loss 3.4106e+00 (3.8264e+00)	Loss_base 1.3321e+00 (1.7471e+00)	Loss_inst 6.4612e-01 (8.4799e-01)	Loss_obj 6.8601e-01 (8.9908e-01)	Loss_clu 4.1570e+00 (4.1586e+00)
Epoch: [0/1]	[ 243/2756]	LR 1.8000000	MOM 0.9960762	Time  0.300 ( 0.314)	Data  0.000 ( 0.005)	Loss 3.4088e+00 (3.8247e+00)	Loss_base 1.3304e+00 (1.7454e+00)	Loss_inst 6.4397e-01 (8.4715e-01)	Loss_obj 6.8639e-01 (8.9821e-01)	Loss_clu 4.1568e+00 (4.1586e+00)
Epoch: [0/1]	[ 244/2756]	LR 1.8000000	MOM 0.9960769	Time  0.301 ( 0.314)	Data  0.000 ( 0.005)	Loss 3.3482e+00 (3.8227e+00)	Loss_base 1.2700e+00 (1.7434e+00)	Loss_inst 6.1087e-01 (8.4619e-01)	Loss_obj 6.5916e-01 (8.9724e-01)	Loss_clu 4.1564e+00 (4.1586e+00)
Epoch: [0/1]	[ 245/2756]	LR 1.8000000	MOM 0.9960775	Time  0.303 ( 0.314)	Data  0.000 ( 0.005)	Loss 3.4063e+00 (3.8210e+00)	Loss_base 1.3280e+00 (1.7417e+00)	Loss_inst 6.4532e-01 (8.4537e-01)	Loss_obj 6.8264e-01 (8.9636e-01)	Loss_clu 4.1567e+00 (4.1586e+00)
Epoch: [0/1]	[ 246/2756]	LR 1.8000000	MOM 0.9960781	Time  0.304 ( 0.314)	Data  0.000 ( 0.005)	Loss 3.5696e+00 (3.8200e+00)	Loss_base 1.4916e+00 (1.7407e+00)	Loss_inst 7.2487e-01 (8.4488e-01)	Loss_obj 7.6669e-01 (8.9584e-01)	Loss_clu 4.1560e+00 (4.1586e+00)
Epoch: [0/1]	[ 247/2756]	LR 1.8000000	MOM 0.9960788	Time  0.300 ( 0.314)	Data  0.000 ( 0.005)	Loss 3.4442e+00 (3.8185e+00)	Loss_base 1.3665e+00 (1.7392e+00)	Loss_inst 6.6556e-01 (8.4416e-01)	Loss_obj 7.0091e-01 (8.9505e-01)	Loss_clu 4.1555e+00 (4.1586e+00)
Epoch: [0/1]	[ 248/2756]	LR 1.8000000	MOM 0.9960794	Time  0.399 ( 0.315)	Data  0.000 ( 0.005)	Loss 3.3417e+00 (3.8166e+00)	Loss_base 1.2636e+00 (1.7373e+00)	Loss_inst 6.1437e-01 (8.4324e-01)	Loss_obj 6.4925e-01 (8.9407e-01)	Loss_clu 4.1561e+00 (4.1586e+00)
Epoch: [0/1]	[ 249/2756]	LR 1.8000000	MOM 0.9960800	Time  0.408 ( 0.315)	Data  0.015 ( 0.005)	Loss 3.4732e+00 (3.8152e+00)	Loss_base 1.3953e+00 (1.7359e+00)	Loss_inst 6.7412e-01 (8.4256e-01)	Loss_obj 7.2122e-01 (8.9337e-01)	Loss_clu 4.1557e+00 (4.1586e+00)
Epoch: [0/1]	[ 250/2756]	LR 1.8000000	MOM 0.9960807	Time  0.330 ( 0.315)	Data  0.001 ( 0.005)	Loss 3.6391e+00 (3.8145e+00)	Loss_base 1.5615e+00 (1.7352e+00)	Loss_inst 7.5653e-01 (8.4222e-01)	Loss_obj 8.0500e-01 (8.9302e-01)	Loss_clu 4.1551e+00 (4.1585e+00)
Epoch: [0/1]	[ 251/2756]	LR 1.8000000	MOM 0.9960813	Time  0.325 ( 0.315)	Data  0.000 ( 0.005)	Loss 3.3534e+00 (3.8127e+00)	Loss_base 1.2751e+00 (1.7334e+00)	Loss_inst 6.1741e-01 (8.4133e-01)	Loss_obj 6.5771e-01 (8.9209e-01)	Loss_clu 4.1565e+00 (4.1585e+00)
Epoch: [0/1]	[ 252/2756]	LR 1.8000000	MOM 0.9960820	Time  0.354 ( 0.315)	Data  0.001 ( 0.005)	Loss 3.4489e+00 (3.8112e+00)	Loss_base 1.3712e+00 (1.7320e+00)	Loss_inst 6.6321e-01 (8.4062e-01)	Loss_obj 7.0802e-01 (8.9136e-01)	Loss_clu 4.1554e+00 (4.1585e+00)
Epoch: [0/1]	[ 253/2756]	LR 1.8000000	MOM 0.9960826	Time  0.892 ( 0.318)	Data  0.007 ( 0.005)	Loss 3.4959e+00 (3.8100e+00)	Loss_base 1.4181e+00 (1.7307e+00)	Loss_inst 6.8741e-01 (8.4002e-01)	Loss_obj 7.3067e-01 (8.9073e-01)	Loss_clu 4.1557e+00 (4.1585e+00)
Epoch: [0/1]	[ 254/2756]	LR 1.8000000	MOM 0.9960832	Time  0.987 ( 0.320)	Data  0.003 ( 0.005)	Loss 3.5580e+00 (3.8090e+00)	Loss_base 1.4805e+00 (1.7298e+00)	Loss_inst 7.1783e-01 (8.3954e-01)	Loss_obj 7.6268e-01 (8.9023e-01)	Loss_clu 4.1549e+00 (4.1585e+00)
Epoch: [0/1]	[ 255/2756]	LR 1.8000000	MOM 0.9960839	Time  0.344 ( 0.320)	Data  0.002 ( 0.005)	Loss 3.4886e+00 (3.8078e+00)	Loss_base 1.4111e+00 (1.7285e+00)	Loss_inst 6.8650e-01 (8.3894e-01)	Loss_obj 7.2456e-01 (8.8958e-01)	Loss_clu 4.1551e+00 (4.1585e+00)
Epoch: [0/1]	[ 256/2756]	LR 1.8000000	MOM 0.9960846	Time  0.381 ( 0.320)	Data  0.001 ( 0.005)	Loss 3.5921e+00 (3.8069e+00)	Loss_base 1.5149e+00 (1.7277e+00)	Loss_inst 7.3620e-01 (8.3854e-01)	Loss_obj 7.7872e-01 (8.8915e-01)	Loss_clu 4.1543e+00 (4.1585e+00)
Epoch: [0/1]	[ 257/2756]	LR 1.8000000	MOM 0.9960852	Time  1.166 ( 0.324)	Data  0.002 ( 0.005)	Loss 3.3881e+00 (3.8053e+00)	Loss_base 1.3109e+00 (1.7261e+00)	Loss_inst 6.3509e-01 (8.3775e-01)	Loss_obj 6.7580e-01 (8.8832e-01)	Loss_clu 4.1545e+00 (4.1584e+00)
Epoch: [0/1]	[ 258/2756]	LR 1.8000000	MOM 0.9960859	Time  0.801 ( 0.326)	Data  0.004 ( 0.005)	Loss 3.4731e+00 (3.8040e+00)	Loss_base 1.3958e+00 (1.7248e+00)	Loss_inst 6.7601e-01 (8.3713e-01)	Loss_obj 7.1978e-01 (8.8767e-01)	Loss_clu 4.1547e+00 (4.1584e+00)
Epoch: [0/1]	[ 259/2756]	LR 1.8000000	MOM 0.9960865	Time  0.360 ( 0.326)	Data  0.002 ( 0.005)	Loss 3.7451e+00 (3.8038e+00)	Loss_base 1.6680e+00 (1.7246e+00)	Loss_inst 8.1316e-01 (8.3704e-01)	Loss_obj 8.5486e-01 (8.8754e-01)	Loss_clu 4.1542e+00 (4.1584e+00)
Epoch: [0/1]	[ 260/2756]	LR 1.8000000	MOM 0.9960872	Time  0.295 ( 0.326)	Data  0.000 ( 0.005)	Loss 3.5476e+00 (3.8028e+00)	Loss_base 1.4706e+00 (1.7236e+00)	Loss_inst 7.1541e-01 (8.3657e-01)	Loss_obj 7.5520e-01 (8.8704e-01)	Loss_clu 4.1539e+00 (4.1584e+00)
Epoch: [0/1]	[ 261/2756]	LR 1.8000000	MOM 0.9960879	Time  0.304 ( 0.326)	Data  0.000 ( 0.005)	Loss 3.2557e+00 (3.8007e+00)	Loss_base 1.1786e+00 (1.7215e+00)	Loss_inst 5.7231e-01 (8.3556e-01)	Loss_obj 6.0633e-01 (8.8596e-01)	Loss_clu 4.1541e+00 (4.1584e+00)
Epoch: [0/1]	[ 262/2756]	LR 1.8000000	MOM 0.9960885	Time  0.295 ( 0.325)	Data  0.001 ( 0.005)	Loss 3.4508e+00 (3.7994e+00)	Loss_base 1.3738e+00 (1.7202e+00)	Loss_inst 6.6642e-01 (8.3492e-01)	Loss_obj 7.0734e-01 (8.8529e-01)	Loss_clu 4.1541e+00 (4.1584e+00)
Epoch: [0/1]	[ 263/2756]	LR 1.8000000	MOM 0.9960892	Time  0.293 ( 0.325)	Data  0.000 ( 0.005)	Loss 3.3669e+00 (3.7977e+00)	Loss_base 1.2899e+00 (1.7186e+00)	Loss_inst 6.2833e-01 (8.3414e-01)	Loss_obj 6.6159e-01 (8.8444e-01)	Loss_clu 4.1539e+00 (4.1583e+00)
Epoch: [0/1]	[ 264/2756]	LR 1.8000000	MOM 0.9960899	Time  0.293 ( 0.325)	Data  0.000 ( 0.005)	Loss 3.4772e+00 (3.7965e+00)	Loss_base 1.4009e+00 (1.7174e+00)	Loss_inst 6.8156e-01 (8.3356e-01)	Loss_obj 7.1937e-01 (8.8382e-01)	Loss_clu 4.1525e+00 (4.1583e+00)
Epoch: [0/1]	[ 265/2756]	LR 1.8000000	MOM 0.9960906	Time  0.307 ( 0.325)	Data  0.000 ( 0.005)	Loss 3.7801e+00 (3.7965e+00)	Loss_base 1.7033e+00 (1.7173e+00)	Loss_inst 8.2620e-01 (8.3353e-01)	Loss_obj 8.7711e-01 (8.8379e-01)	Loss_clu 4.1535e+00 (4.1583e+00)
Epoch: [0/1]	[ 266/2756]	LR 1.8000000	MOM 0.9960912	Time  0.304 ( 0.325)	Data  0.000 ( 0.005)	Loss 3.5622e+00 (3.7956e+00)	Loss_base 1.4855e+00 (1.7165e+00)	Loss_inst 7.2104e-01 (8.3311e-01)	Loss_obj 7.6451e-01 (8.8334e-01)	Loss_clu 4.1534e+00 (4.1583e+00)
Epoch: [0/1]	[ 267/2756]	LR 1.8000000	MOM 0.9960919	Time  0.304 ( 0.325)	Data  0.000 ( 0.004)	Loss 3.3677e+00 (3.7940e+00)	Loss_base 1.2907e+00 (1.7149e+00)	Loss_inst 6.2671e-01 (8.3234e-01)	Loss_obj 6.6399e-01 (8.8252e-01)	Loss_clu 4.1540e+00 (4.1583e+00)
Epoch: [0/1]	[ 268/2756]	LR 1.8000000	MOM 0.9960926	Time  0.303 ( 0.325)	Data  0.000 ( 0.004)	Loss 3.4460e+00 (3.7927e+00)	Loss_base 1.3702e+00 (1.7136e+00)	Loss_inst 6.6606e-01 (8.3172e-01)	Loss_obj 7.0414e-01 (8.8186e-01)	Loss_clu 4.1516e+00 (4.1583e+00)
Epoch: [0/1]	[ 269/2756]	LR 1.8000000	MOM 0.9960933	Time  0.303 ( 0.325)	Data  0.000 ( 0.004)	Loss 3.5865e+00 (3.7919e+00)	Loss_base 1.5101e+00 (1.7128e+00)	Loss_inst 7.3522e-01 (8.3137e-01)	Loss_obj 7.7489e-01 (8.8147e-01)	Loss_clu 4.1528e+00 (4.1582e+00)
Epoch: [0/1]	[ 270/2756]	LR 1.8000000	MOM 0.9960940	Time  0.300 ( 0.325)	Data  0.000 ( 0.004)	Loss 3.4506e+00 (3.7907e+00)	Loss_base 1.3740e+00 (1.7116e+00)	Loss_inst 6.6553e-01 (8.3075e-01)	Loss_obj 7.0849e-01 (8.8083e-01)	Loss_clu 4.1532e+00 (4.1582e+00)
Epoch: [0/1]	[ 271/2756]	LR 1.8000000	MOM 0.9960947	Time  0.301 ( 0.325)	Data  0.000 ( 0.004)	Loss 3.4792e+00 (3.7895e+00)	Loss_base 1.4027e+00 (1.7104e+00)	Loss_inst 6.8058e-01 (8.3020e-01)	Loss_obj 7.2215e-01 (8.8024e-01)	Loss_clu 4.1529e+00 (4.1582e+00)
Epoch: [0/1]	[ 272/2756]	LR 1.8000000	MOM 0.9960954	Time  0.302 ( 0.325)	Data  0.000 ( 0.004)	Loss 3.5211e+00 (3.7886e+00)	Loss_base 1.4447e+00 (1.7095e+00)	Loss_inst 7.0038e-01 (8.2973e-01)	Loss_obj 7.4428e-01 (8.7975e-01)	Loss_clu 4.1528e+00 (4.1582e+00)
Epoch: [0/1]	[ 273/2756]	LR 1.8000000	MOM 0.9960961	Time  0.300 ( 0.324)	Data  0.000 ( 0.004)	Loss 3.4436e+00 (3.7873e+00)	Loss_base 1.3671e+00 (1.7082e+00)	Loss_inst 6.6253e-01 (8.2912e-01)	Loss_obj 7.0461e-01 (8.7911e-01)	Loss_clu 4.1530e+00 (4.1582e+00)
Epoch: [0/1]	[ 274/2756]	LR 1.8000000	MOM 0.9960968	Time  0.303 ( 0.324)	Data  0.000 ( 0.004)	Loss 3.4163e+00 (3.7859e+00)	Loss_base 1.3405e+00 (1.7069e+00)	Loss_inst 6.4795e-01 (8.2846e-01)	Loss_obj 6.9250e-01 (8.7843e-01)	Loss_clu 4.1518e+00 (4.1581e+00)
Epoch: [0/1]	[ 275/2756]	LR 1.8000000	MOM 0.9960975	Time  0.302 ( 0.324)	Data  0.000 ( 0.004)	Loss 3.5243e+00 (3.7850e+00)	Loss_base 1.4485e+00 (1.7059e+00)	Loss_inst 7.0506e-01 (8.2801e-01)	Loss_obj 7.4340e-01 (8.7794e-01)	Loss_clu 4.1517e+00 (4.1581e+00)
Epoch: [0/1]	[ 276/2756]	LR 1.8000000	MOM 0.9960982	Time  0.303 ( 0.324)	Data  0.000 ( 0.004)	Loss 3.5054e+00 (3.7840e+00)	Loss_base 1.4301e+00 (1.7050e+00)	Loss_inst 6.9637e-01 (8.2753e-01)	Loss_obj 7.3375e-01 (8.7742e-01)	Loss_clu 4.1506e+00 (4.1581e+00)
Epoch: [0/1]	[ 277/2756]	LR 1.8000000	MOM 0.9960989	Time  0.304 ( 0.324)	Data  0.000 ( 0.004)	Loss 3.2706e+00 (3.7821e+00)	Loss_base 1.1949e+00 (1.7031e+00)	Loss_inst 5.7938e-01 (8.2664e-01)	Loss_obj 6.1557e-01 (8.7648e-01)	Loss_clu 4.1512e+00 (4.1581e+00)
Epoch: [0/1]	[ 278/2756]	LR 1.8000000	MOM 0.9960996	Time  0.299 ( 0.324)	Data  0.000 ( 0.004)	Loss 3.2906e+00 (3.7804e+00)	Loss_base 1.2148e+00 (1.7014e+00)	Loss_inst 5.9297e-01 (8.2580e-01)	Loss_obj 6.2187e-01 (8.7556e-01)	Loss_clu 4.1515e+00 (4.1580e+00)
Epoch: [0/1]	[ 279/2756]	LR 1.8000000	MOM 0.9961003	Time  0.302 ( 0.324)	Data  0.000 ( 0.004)	Loss 3.3557e+00 (3.7789e+00)	Loss_base 1.2804e+00 (1.6999e+00)	Loss_inst 6.2088e-01 (8.2507e-01)	Loss_obj 6.5949e-01 (8.7479e-01)	Loss_clu 4.1506e+00 (4.1580e+00)
Epoch: [0/1]	[ 280/2756]	LR 1.8000000	MOM 0.9961010	Time  0.300 ( 0.324)	Data  0.000 ( 0.004)	Loss 3.4474e+00 (3.7777e+00)	Loss_base 1.3712e+00 (1.6987e+00)	Loss_inst 6.6626e-01 (8.2451e-01)	Loss_obj 7.0497e-01 (8.7419e-01)	Loss_clu 4.1523e+00 (4.1580e+00)
Epoch: [0/1]	[ 281/2756]	LR 1.8000000	MOM 0.9961017	Time  0.299 ( 0.324)	Data  0.000 ( 0.004)	Loss 3.5746e+00 (3.7770e+00)	Loss_base 1.4996e+00 (1.6980e+00)	Loss_inst 7.3213e-01 (8.2418e-01)	Loss_obj 7.6745e-01 (8.7381e-01)	Loss_clu 4.1501e+00 (4.1580e+00)
Epoch: [0/1]	[ 282/2756]	LR 1.8000000	MOM 0.9961024	Time  0.302 ( 0.324)	Data  0.000 ( 0.004)	Loss 3.1183e+00 (3.7746e+00)	Loss_base 1.0417e+00 (1.6957e+00)	Loss_inst 5.0351e-01 (8.2305e-01)	Loss_obj 5.3822e-01 (8.7262e-01)	Loss_clu 4.1532e+00 (4.1579e+00)
Epoch: [0/1]	[ 283/2756]	LR 1.8000000	MOM 0.9961032	Time  0.304 ( 0.324)	Data  0.000 ( 0.004)	Loss 3.5793e+00 (3.7740e+00)	Loss_base 1.5041e+00 (1.6950e+00)	Loss_inst 7.3100e-01 (8.2272e-01)	Loss_obj 7.7312e-01 (8.7227e-01)	Loss_clu 4.1503e+00 (4.1579e+00)
Epoch: [0/1]	[ 284/2756]	LR 1.8000000	MOM 0.9961039	Time  0.301 ( 0.324)	Data  0.000 ( 0.004)	Loss 3.3015e+00 (3.7723e+00)	Loss_base 1.2261e+00 (1.6934e+00)	Loss_inst 5.9586e-01 (8.2193e-01)	Loss_obj 6.3022e-01 (8.7142e-01)	Loss_clu 4.1509e+00 (4.1579e+00)
Epoch: [0/1]	[ 285/2756]	LR 1.8000000	MOM 0.9961046	Time  0.299 ( 0.323)	Data  0.000 ( 0.004)	Loss 3.4609e+00 (3.7712e+00)	Loss_base 1.3854e+00 (1.6923e+00)	Loss_inst 6.7188e-01 (8.2140e-01)	Loss_obj 7.1353e-01 (8.7087e-01)	Loss_clu 4.1510e+00 (4.1579e+00)
Epoch: [0/1]	[ 286/2756]	LR 1.8000000	MOM 0.9961053	Time  0.302 ( 0.323)	Data  0.000 ( 0.004)	Loss 3.4602e+00 (3.7701e+00)	Loss_base 1.3854e+00 (1.6912e+00)	Loss_inst 6.7321e-01 (8.2089e-01)	Loss_obj 7.1216e-01 (8.7032e-01)	Loss_clu 4.1496e+00 (4.1578e+00)
Epoch: [0/1]	[ 287/2756]	LR 1.8000000	MOM 0.9961061	Time  0.304 ( 0.323)	Data  0.001 ( 0.004)	Loss 3.3940e+00 (3.7688e+00)	Loss_base 1.3191e+00 (1.6899e+00)	Loss_inst 6.3989e-01 (8.2026e-01)	Loss_obj 6.7924e-01 (8.6966e-01)	Loss_clu 4.1498e+00 (4.1578e+00)
Epoch: [0/1]	[ 288/2756]	LR 1.8000000	MOM 0.9961068	Time  0.303 ( 0.323)	Data  0.000 ( 0.004)	Loss 3.3723e+00 (3.7674e+00)	Loss_base 1.2977e+00 (1.6886e+00)	Loss_inst 6.3101e-01 (8.1960e-01)	Loss_obj 6.6674e-01 (8.6895e-01)	Loss_clu 4.1491e+00 (4.1578e+00)
Epoch: [0/1]	[ 289/2756]	LR 1.8000000	MOM 0.9961075	Time  0.300 ( 0.323)	Data  0.000 ( 0.004)	Loss 3.2447e+00 (3.7656e+00)	Loss_base 1.1699e+00 (1.6868e+00)	Loss_inst 5.6655e-01 (8.1873e-01)	Loss_obj 6.0332e-01 (8.6804e-01)	Loss_clu 4.1497e+00 (4.1577e+00)
Epoch: [0/1]	[ 290/2756]	LR 1.8000000	MOM 0.9961083	Time  0.300 ( 0.323)	Data  0.000 ( 0.004)	Loss 3.2291e+00 (3.7638e+00)	Loss_base 1.1527e+00 (1.6849e+00)	Loss_inst 5.5794e-01 (8.1783e-01)	Loss_obj 5.9473e-01 (8.6710e-01)	Loss_clu 4.1529e+00 (4.1577e+00)
Epoch: [0/1]	[ 291/2756]	LR 1.8000000	MOM 0.9961090	Time  0.303 ( 0.323)	Data  0.000 ( 0.004)	Loss 3.5370e+00 (3.7630e+00)	Loss_base 1.4628e+00 (1.6842e+00)	Loss_inst 7.1152e-01 (8.1747e-01)	Loss_obj 7.5129e-01 (8.6670e-01)	Loss_clu 4.1483e+00 (4.1577e+00)
Epoch: [0/1]	[ 292/2756]	LR 1.8000000	MOM 0.9961098	Time  0.305 ( 0.323)	Data  0.000 ( 0.004)	Loss 3.3960e+00 (3.7618e+00)	Loss_base 1.3203e+00 (1.6829e+00)	Loss_inst 6.3958e-01 (8.1686e-01)	Loss_obj 6.8076e-01 (8.6607e-01)	Loss_clu 4.1514e+00 (4.1577e+00)
Epoch: [0/1]	[ 293/2756]	LR 1.8000000	MOM 0.9961105	Time  0.305 ( 0.323)	Data  0.000 ( 0.004)	Loss 3.2752e+00 (3.7601e+00)	Loss_base 1.2008e+00 (1.6813e+00)	Loss_inst 5.7839e-01 (8.1605e-01)	Loss_obj 6.2241e-01 (8.6524e-01)	Loss_clu 4.1489e+00 (4.1576e+00)
Epoch: [0/1]	[ 294/2756]	LR 1.8000000	MOM 0.9961113	Time  0.302 ( 0.323)	Data  0.000 ( 0.004)	Loss 3.3446e+00 (3.7587e+00)	Loss_base 1.2695e+00 (1.6799e+00)	Loss_inst 6.1723e-01 (8.1538e-01)	Loss_obj 6.5226e-01 (8.6452e-01)	Loss_clu 4.1502e+00 (4.1576e+00)
Epoch: [0/1]	[ 295/2756]	LR 1.8000000	MOM 0.9961120	Time  0.305 ( 0.323)	Data  0.000 ( 0.004)	Loss 3.5141e+00 (3.7579e+00)	Loss_base 1.4407e+00 (1.6791e+00)	Loss_inst 7.0328e-01 (8.1500e-01)	Loss_obj 7.3740e-01 (8.6409e-01)	Loss_clu 4.1469e+00 (4.1576e+00)
Epoch: [0/1]	[ 296/2756]	LR 1.8000000	MOM 0.9961128	Time  0.299 ( 0.323)	Data  0.000 ( 0.004)	Loss 3.2406e+00 (3.7561e+00)	Loss_base 1.1667e+00 (1.6774e+00)	Loss_inst 5.6550e-01 (8.1416e-01)	Loss_obj 6.0119e-01 (8.6320e-01)	Loss_clu 4.1479e+00 (4.1576e+00)
Epoch: [0/1]	[ 297/2756]	LR 1.8000000	MOM 0.9961135	Time  0.301 ( 0.323)	Data  0.000 ( 0.004)	Loss 3.5610e+00 (3.7555e+00)	Loss_base 1.4872e+00 (1.6767e+00)	Loss_inst 7.2425e-01 (8.1386e-01)	Loss_obj 7.6295e-01 (8.6287e-01)	Loss_clu 4.1475e+00 (4.1575e+00)
Epoch: [0/1]	[ 298/2756]	LR 1.8000000	MOM 0.9961143	Time  0.304 ( 0.323)	Data  0.000 ( 0.004)	Loss 3.4887e+00 (3.7546e+00)	Loss_base 1.4138e+00 (1.6758e+00)	Loss_inst 6.8742e-01 (8.1343e-01)	Loss_obj 7.2637e-01 (8.6241e-01)	Loss_clu 4.1497e+00 (4.1575e+00)
Epoch: [0/1]	[ 299/2756]	LR 1.8000000	MOM 0.9961150	Time  0.302 ( 0.322)	Data  0.000 ( 0.004)	Loss 3.5581e+00 (3.7539e+00)	Loss_base 1.4838e+00 (1.6752e+00)	Loss_inst 7.2257e-01 (8.1313e-01)	Loss_obj 7.6128e-01 (8.6207e-01)	Loss_clu 4.1484e+00 (4.1575e+00)
Epoch: [0/1]	[ 300/2756]	LR 1.8000000	MOM 0.9961158	Time  0.303 ( 0.322)	Data  0.000 ( 0.004)	Loss 3.5289e+00 (3.7532e+00)	Loss_base 1.4559e+00 (1.6745e+00)	Loss_inst 7.0802e-01 (8.1278e-01)	Loss_obj 7.4791e-01 (8.6169e-01)	Loss_clu 4.1460e+00 (4.1574e+00)
Epoch: [0/1]	[ 301/2756]	LR 1.8000000	MOM 0.9961166	Time  0.303 ( 0.322)	Data  0.000 ( 0.004)	Loss 3.5718e+00 (3.7526e+00)	Loss_base 1.4983e+00 (1.6739e+00)	Loss_inst 7.3044e-01 (8.1251e-01)	Loss_obj 7.6787e-01 (8.6138e-01)	Loss_clu 4.1469e+00 (4.1574e+00)
Epoch: [0/1]	[ 302/2756]	LR 1.8000000	MOM 0.9961173	Time  0.304 ( 0.322)	Data  0.000 ( 0.004)	Loss 3.3796e+00 (3.7514e+00)	Loss_base 1.3061e+00 (1.6727e+00)	Loss_inst 6.3448e-01 (8.1192e-01)	Loss_obj 6.7159e-01 (8.6076e-01)	Loss_clu 4.1471e+00 (4.1574e+00)
Epoch: [0/1]	[ 303/2756]	LR 1.8000000	MOM 0.9961181	Time  0.304 ( 0.322)	Data  0.000 ( 0.004)	Loss 3.3813e+00 (3.7501e+00)	Loss_base 1.3088e+00 (1.6715e+00)	Loss_inst 6.3634e-01 (8.1134e-01)	Loss_obj 6.7247e-01 (8.6014e-01)	Loss_clu 4.1451e+00 (4.1573e+00)
Epoch: [0/1]	[ 304/2756]	LR 1.8000000	MOM 0.9961189	Time  0.299 ( 0.322)	Data  0.000 ( 0.004)	Loss 3.5153e+00 (3.7494e+00)	Loss_base 1.4421e+00 (1.6707e+00)	Loss_inst 7.0202e-01 (8.1099e-01)	Loss_obj 7.4006e-01 (8.5974e-01)	Loss_clu 4.1465e+00 (4.1573e+00)
Epoch: [0/1]	[ 305/2756]	LR 1.8000000	MOM 0.9961197	Time  0.303 ( 0.322)	Data  0.000 ( 0.004)	Loss 3.4017e+00 (3.7482e+00)	Loss_base 1.3276e+00 (1.6696e+00)	Loss_inst 6.4622e-01 (8.1045e-01)	Loss_obj 6.8141e-01 (8.5916e-01)	Loss_clu 4.1482e+00 (4.1573e+00)
Epoch: [0/1]	[ 306/2756]	LR 1.8000000	MOM 0.9961204	Time  0.306 ( 0.322)	Data  0.000 ( 0.004)	Loss 3.5346e+00 (3.7475e+00)	Loss_base 1.4613e+00 (1.6689e+00)	Loss_inst 7.1162e-01 (8.1012e-01)	Loss_obj 7.4966e-01 (8.5880e-01)	Loss_clu 4.1467e+00 (4.1572e+00)
Epoch: [0/1]	[ 307/2756]	LR 1.8000000	MOM 0.9961212	Time  0.304 ( 0.322)	Data  0.000 ( 0.004)	Loss 3.4255e+00 (3.7465e+00)	Loss_base 1.3535e+00 (1.6679e+00)	Loss_inst 6.5702e-01 (8.0963e-01)	Loss_obj 6.9647e-01 (8.5828e-01)	Loss_clu 4.1440e+00 (4.1572e+00)
Epoch: [0/1]	[ 308/2756]	LR 1.8000000	MOM 0.9961220	Time  0.301 ( 0.322)	Data  0.000 ( 0.004)	Loss 3.4530e+00 (3.7455e+00)	Loss_base 1.3815e+00 (1.6670e+00)	Loss_inst 6.6890e-01 (8.0917e-01)	Loss_obj 7.1257e-01 (8.5780e-01)	Loss_clu 4.1431e+00 (4.1571e+00)
Epoch: [0/1]	[ 309/2756]	LR 1.8000000	MOM 0.9961228	Time  0.302 ( 0.322)	Data  0.000 ( 0.004)	Loss 3.4196e+00 (3.7445e+00)	Loss_base 1.3474e+00 (1.6659e+00)	Loss_inst 6.5284e-01 (8.0867e-01)	Loss_obj 6.9452e-01 (8.5728e-01)	Loss_clu 4.1444e+00 (4.1571e+00)
Epoch: [0/1]	[ 310/2756]	LR 1.8000000	MOM 0.9961236	Time  0.299 ( 0.322)	Data  0.000 ( 0.004)	Loss 3.4226e+00 (3.7435e+00)	Loss_base 1.3506e+00 (1.6649e+00)	Loss_inst 6.5982e-01 (8.0819e-01)	Loss_obj 6.9081e-01 (8.5674e-01)	Loss_clu 4.1440e+00 (4.1570e+00)
Epoch: [0/1]	[ 311/2756]	LR 1.8000000	MOM 0.9961244	Time  0.301 ( 0.322)	Data  0.000 ( 0.004)	Loss 3.5767e+00 (3.7429e+00)	Loss_base 1.5047e+00 (1.6644e+00)	Loss_inst 7.3634e-01 (8.0796e-01)	Loss_obj 7.6837e-01 (8.5646e-01)	Loss_clu 4.1440e+00 (4.1570e+00)
Epoch: [0/1]	[ 312/2756]	LR 1.8000000	MOM 0.9961252	Time  0.301 ( 0.322)	Data  0.000 ( 0.004)	Loss 3.3555e+00 (3.7417e+00)	Loss_base 1.2838e+00 (1.6632e+00)	Loss_inst 6.2678e-01 (8.0738e-01)	Loss_obj 6.5706e-01 (8.5582e-01)	Loss_clu 4.1434e+00 (4.1570e+00)
Epoch: [0/1]	[ 313/2756]	LR 1.8000000	MOM 0.9961260	Time  0.304 ( 0.322)	Data  0.000 ( 0.004)	Loss 3.4457e+00 (3.7407e+00)	Loss_base 1.3735e+00 (1.6623e+00)	Loss_inst 6.6828e-01 (8.0694e-01)	Loss_obj 7.0519e-01 (8.5534e-01)	Loss_clu 4.1444e+00 (4.1569e+00)
Epoch: [0/1]	[ 314/2756]	LR 1.8000000	MOM 0.9961268	Time  0.304 ( 0.322)	Data  0.000 ( 0.004)	Loss 3.4780e+00 (3.7399e+00)	Loss_base 1.4068e+00 (1.6615e+00)	Loss_inst 6.8441e-01 (8.0655e-01)	Loss_obj 7.2237e-01 (8.5492e-01)	Loss_clu 4.1425e+00 (4.1569e+00)
Epoch: [0/1]	[ 315/2756]	LR 1.8000000	MOM 0.9961276	Time  0.304 ( 0.321)	Data  0.000 ( 0.004)	Loss 3.6567e+00 (3.7396e+00)	Loss_base 1.5860e+00 (1.6612e+00)	Loss_inst 7.7177e-01 (8.0644e-01)	Loss_obj 8.1421e-01 (8.5479e-01)	Loss_clu 4.1415e+00 (4.1568e+00)
Epoch: [0/1]	[ 316/2756]	LR 1.8000000	MOM 0.9961284	Time  0.301 ( 0.321)	Data  0.000 ( 0.004)	Loss 3.5041e+00 (3.7389e+00)	Loss_base 1.4333e+00 (1.6605e+00)	Loss_inst 6.9887e-01 (8.0610e-01)	Loss_obj 7.3443e-01 (8.5441e-01)	Loss_clu 4.1415e+00 (4.1568e+00)
Epoch: [0/1]	[ 317/2756]	LR 1.8000000	MOM 0.9961292	Time  0.303 ( 0.321)	Data  0.000 ( 0.004)	Loss 3.2135e+00 (3.7372e+00)	Loss_base 1.1410e+00 (1.6589e+00)	Loss_inst 5.5560e-01 (8.0531e-01)	Loss_obj 5.8545e-01 (8.5357e-01)	Loss_clu 4.1448e+00 (4.1567e+00)
Epoch: [0/1]	[ 318/2756]	LR 1.8000000	MOM 0.9961300	Time  0.304 ( 0.321)	Data  0.000 ( 0.004)	Loss 3.3683e+00 (3.7361e+00)	Loss_base 1.2960e+00 (1.6577e+00)	Loss_inst 6.3284e-01 (8.0477e-01)	Loss_obj 6.6316e-01 (8.5297e-01)	Loss_clu 4.1445e+00 (4.1567e+00)
Epoch: [0/1]	[ 319/2756]	LR 1.8000000	MOM 0.9961308	Time  0.303 ( 0.321)	Data  0.000 ( 0.004)	Loss 3.3222e+00 (3.7348e+00)	Loss_base 1.2495e+00 (1.6565e+00)	Loss_inst 6.0942e-01 (8.0416e-01)	Loss_obj 6.4011e-01 (8.5230e-01)	Loss_clu 4.1454e+00 (4.1567e+00)
Epoch: [0/1]	[ 320/2756]	LR 1.8000000	MOM 0.9961316	Time  0.302 ( 0.321)	Data  0.000 ( 0.004)	Loss 3.2492e+00 (3.7333e+00)	Loss_base 1.1760e+00 (1.6550e+00)	Loss_inst 5.7216e-01 (8.0344e-01)	Loss_obj 6.0383e-01 (8.5153e-01)	Loss_clu 4.1465e+00 (4.1566e+00)
Epoch: [0/1]	[ 321/2756]	LR 1.8000000	MOM 0.9961324	Time  0.300 ( 0.321)	Data  0.000 ( 0.004)	Loss 3.4498e+00 (3.7324e+00)	Loss_base 1.3774e+00 (1.6541e+00)	Loss_inst 6.6898e-01 (8.0302e-01)	Loss_obj 7.0845e-01 (8.5109e-01)	Loss_clu 4.1447e+00 (4.1566e+00)
Epoch: [0/1]	[ 322/2756]	LR 1.8000000	MOM 0.9961332	Time  0.304 ( 0.321)	Data  0.001 ( 0.004)	Loss 3.5403e+00 (3.7318e+00)	Loss_base 1.4685e+00 (1.6535e+00)	Loss_inst 7.1324e-01 (8.0274e-01)	Loss_obj 7.5524e-01 (8.5079e-01)	Loss_clu 4.1437e+00 (4.1566e+00)
Epoch: [0/1]	[ 323/2756]	LR 1.8000000	MOM 0.9961340	Time  0.302 ( 0.321)	Data  0.000 ( 0.004)	Loss 3.2946e+00 (3.7305e+00)	Loss_base 1.2220e+00 (1.6522e+00)	Loss_inst 5.9541e-01 (8.0210e-01)	Loss_obj 6.2661e-01 (8.5010e-01)	Loss_clu 4.1451e+00 (4.1565e+00)
Epoch: [0/1]	[ 324/2756]	LR 1.8000000	MOM 0.9961349	Time  0.303 ( 0.321)	Data  0.000 ( 0.004)	Loss 3.4821e+00 (3.7297e+00)	Loss_base 1.4095e+00 (1.6515e+00)	Loss_inst 6.8989e-01 (8.0176e-01)	Loss_obj 7.1964e-01 (8.4970e-01)	Loss_clu 4.1451e+00 (4.1565e+00)
Epoch: [0/1]	[ 325/2756]	LR 1.8000000	MOM 0.9961357	Time  0.304 ( 0.321)	Data  0.000 ( 0.004)	Loss 3.4633e+00 (3.7289e+00)	Loss_base 1.3923e+00 (1.6507e+00)	Loss_inst 6.8060e-01 (8.0138e-01)	Loss_obj 7.1174e-01 (8.4927e-01)	Loss_clu 4.1420e+00 (4.1564e+00)
Epoch: [0/1]	[ 326/2756]	LR 1.8000000	MOM 0.9961365	Time  0.306 ( 0.321)	Data  0.000 ( 0.004)	Loss 3.4347e+00 (3.7280e+00)	Loss_base 1.3624e+00 (1.6498e+00)	Loss_inst 6.6329e-01 (8.0096e-01)	Loss_obj 6.9913e-01 (8.4881e-01)	Loss_clu 4.1445e+00 (4.1564e+00)
Epoch: [0/1]	[ 327/2756]	LR 1.8000000	MOM 0.9961373	Time  0.302 ( 0.321)	Data  0.000 ( 0.004)	Loss 3.6127e+00 (3.7276e+00)	Loss_base 1.5425e+00 (1.6494e+00)	Loss_inst 7.5390e-01 (8.0082e-01)	Loss_obj 7.8864e-01 (8.4863e-01)	Loss_clu 4.1403e+00 (4.1564e+00)
Epoch: [0/1]	[ 328/2756]	LR 1.8000000	MOM 0.9961382	Time  0.305 ( 0.321)	Data  0.000 ( 0.004)	Loss 3.3172e+00 (3.7264e+00)	Loss_base 1.2477e+00 (1.6482e+00)	Loss_inst 6.0565e-01 (8.0023e-01)	Loss_obj 6.4207e-01 (8.4800e-01)	Loss_clu 4.1390e+00 (4.1563e+00)
Epoch: [0/1]	[ 329/2756]	LR 1.8000000	MOM 0.9961390	Time  0.301 ( 0.321)	Data  0.000 ( 0.004)	Loss 3.2653e+00 (3.7250e+00)	Loss_base 1.1949e+00 (1.6469e+00)	Loss_inst 5.8243e-01 (7.9957e-01)	Loss_obj 6.1246e-01 (8.4729e-01)	Loss_clu 4.1409e+00 (4.1563e+00)
Epoch: [0/1]	[ 330/2756]	LR 1.8000000	MOM 0.9961398	Time  0.303 ( 0.321)	Data  0.000 ( 0.004)	Loss 3.2780e+00 (3.7236e+00)	Loss_base 1.2063e+00 (1.6455e+00)	Loss_inst 5.8821e-01 (7.9893e-01)	Loss_obj 6.1811e-01 (8.4660e-01)	Loss_clu 4.1434e+00 (4.1562e+00)
Epoch: [0/1]	[ 331/2756]	LR 1.8000000	MOM 0.9961407	Time  0.302 ( 0.321)	Data  0.000 ( 0.004)	Loss 3.4129e+00 (3.7227e+00)	Loss_base 1.3439e+00 (1.6446e+00)	Loss_inst 6.5219e-01 (7.9849e-01)	Loss_obj 6.9171e-01 (8.4613e-01)	Loss_clu 4.1379e+00 (4.1562e+00)
Epoch: [0/1]	[ 332/2756]	LR 1.8000000	MOM 0.9961415	Time  0.303 ( 0.321)	Data  0.000 ( 0.004)	Loss 3.4652e+00 (3.7219e+00)	Loss_base 1.3945e+00 (1.6439e+00)	Loss_inst 6.7894e-01 (7.9813e-01)	Loss_obj 7.1556e-01 (8.4574e-01)	Loss_clu 4.1414e+00 (4.1561e+00)
Epoch: [0/1]	[ 333/2756]	LR 1.8000000	MOM 0.9961424	Time  0.303 ( 0.320)	Data  0.000 ( 0.004)	Loss 3.3786e+00 (3.7209e+00)	Loss_base 1.3084e+00 (1.6429e+00)	Loss_inst 6.4124e-01 (7.9766e-01)	Loss_obj 6.6716e-01 (8.4520e-01)	Loss_clu 4.1404e+00 (4.1561e+00)
Epoch: [0/1]	[ 334/2756]	LR 1.8000000	MOM 0.9961432	Time  0.302 ( 0.320)	Data  0.000 ( 0.004)	Loss 3.1452e+00 (3.7192e+00)	Loss_base 1.0771e+00 (1.6412e+00)	Loss_inst 5.2479e-01 (7.9684e-01)	Loss_obj 5.5228e-01 (8.4433e-01)	Loss_clu 4.1363e+00 (4.1560e+00)
Epoch: [0/1]	[ 335/2756]	LR 1.8000000	MOM 0.9961441	Time  0.305 ( 0.320)	Data  0.000 ( 0.004)	Loss 3.3092e+00 (3.7180e+00)	Loss_base 1.2396e+00 (1.6400e+00)	Loss_inst 6.0115e-01 (7.9626e-01)	Loss_obj 6.3841e-01 (8.4371e-01)	Loss_clu 4.1393e+00 (4.1560e+00)
Epoch: [0/1]	[ 336/2756]	LR 1.8000000	MOM 0.9961449	Time  0.302 ( 0.320)	Data  0.000 ( 0.004)	Loss 3.5888e+00 (3.7176e+00)	Loss_base 1.5211e+00 (1.6396e+00)	Loss_inst 7.3905e-01 (7.9609e-01)	Loss_obj 7.8202e-01 (8.4353e-01)	Loss_clu 4.1354e+00 (4.1559e+00)
Epoch: [0/1]	[ 337/2756]	LR 1.8000000	MOM 0.9961458	Time  0.303 ( 0.320)	Data  0.000 ( 0.004)	Loss 3.6219e+00 (3.7173e+00)	Loss_base 1.5526e+00 (1.6394e+00)	Loss_inst 7.5488e-01 (7.9597e-01)	Loss_obj 7.9769e-01 (8.4340e-01)	Loss_clu 4.1388e+00 (4.1559e+00)
Epoch: [0/1]	[ 338/2756]	LR 1.8000000	MOM 0.9961466	Time  0.303 ( 0.320)	Data  0.000 ( 0.004)	Loss 3.3578e+00 (3.7162e+00)	Loss_base 1.2900e+00 (1.6383e+00)	Loss_inst 6.2871e-01 (7.9547e-01)	Loss_obj 6.6132e-01 (8.4286e-01)	Loss_clu 4.1355e+00 (4.1558e+00)
Epoch: [0/1]	[ 339/2756]	LR 1.8000000	MOM 0.9961475	Time  0.303 ( 0.320)	Data  0.000 ( 0.004)	Loss 3.4572e+00 (3.7155e+00)	Loss_base 1.3872e+00 (1.6376e+00)	Loss_inst 6.7616e-01 (7.9512e-01)	Loss_obj 7.1101e-01 (8.4247e-01)	Loss_clu 4.1400e+00 (4.1557e+00)
Epoch: [0/1]	[ 340/2756]	LR 1.8000000	MOM 0.9961483	Time  0.302 ( 0.320)	Data  0.000 ( 0.004)	Loss 3.3520e+00 (3.7144e+00)	Loss_base 1.2856e+00 (1.6366e+00)	Loss_inst 6.2455e-01 (7.9462e-01)	Loss_obj 6.6109e-01 (8.4194e-01)	Loss_clu 4.1326e+00 (4.1557e+00)
Epoch: [0/1]	[ 341/2756]	LR 1.8000000	MOM 0.9961492	Time  0.301 ( 0.320)	Data  0.000 ( 0.004)	Loss 3.3421e+00 (3.7133e+00)	Loss_base 1.2752e+00 (1.6355e+00)	Loss_inst 6.1939e-01 (7.9411e-01)	Loss_obj 6.5581e-01 (8.4139e-01)	Loss_clu 4.1339e+00 (4.1556e+00)
Epoch: [0/1]	[ 342/2756]	LR 1.8000000	MOM 0.9961501	Time  0.299 ( 0.320)	Data  0.000 ( 0.004)	Loss 3.2751e+00 (3.7120e+00)	Loss_base 1.2096e+00 (1.6343e+00)	Loss_inst 5.8564e-01 (7.9350e-01)	Loss_obj 6.2395e-01 (8.4076e-01)	Loss_clu 4.1310e+00 (4.1555e+00)
Epoch: [0/1]	[ 343/2756]	LR 1.8000000	MOM 0.9961509	Time  0.303 ( 0.320)	Data  0.000 ( 0.004)	Loss 3.3932e+00 (3.7111e+00)	Loss_base 1.3279e+00 (1.6334e+00)	Loss_inst 6.4557e-01 (7.9307e-01)	Loss_obj 6.8236e-01 (8.4030e-01)	Loss_clu 4.1305e+00 (4.1555e+00)
Epoch: [0/1]	[ 344/2756]	LR 1.8000000	MOM 0.9961518	Time  0.301 ( 0.320)	Data  0.000 ( 0.004)	Loss 3.3422e+00 (3.7100e+00)	Loss_base 1.2756e+00 (1.6323e+00)	Loss_inst 6.1869e-01 (7.9257e-01)	Loss_obj 6.5688e-01 (8.3977e-01)	Loss_clu 4.1332e+00 (4.1554e+00)
Epoch: [0/1]	[ 345/2756]	LR 1.8000000	MOM 0.9961527	Time  0.301 ( 0.320)	Data  0.000 ( 0.004)	Loss 3.4804e+00 (3.7094e+00)	Loss_base 1.4157e+00 (1.6317e+00)	Loss_inst 6.9050e-01 (7.9227e-01)	Loss_obj 7.2521e-01 (8.3944e-01)	Loss_clu 4.1293e+00 (4.1553e+00)
Epoch: [0/1]	[ 346/2756]	LR 1.8000000	MOM 0.9961536	Time  0.303 ( 0.320)	Data  0.000 ( 0.004)	Loss 3.2999e+00 (3.7082e+00)	Loss_base 1.2342e+00 (1.6306e+00)	Loss_inst 5.9705e-01 (7.9171e-01)	Loss_obj 6.3720e-01 (8.3885e-01)	Loss_clu 4.1314e+00 (4.1553e+00)
Epoch: [0/1]	[ 347/2756]	LR 1.8000000	MOM 0.9961544	Time  0.299 ( 0.320)	Data  0.000 ( 0.004)	Loss 3.3991e+00 (3.7073e+00)	Loss_base 1.3334e+00 (1.6297e+00)	Loss_inst 6.4842e-01 (7.9130e-01)	Loss_obj 6.8500e-01 (8.3841e-01)	Loss_clu 4.1314e+00 (4.1552e+00)
Epoch: [0/1]	[ 348/2756]	LR 1.8000000	MOM 0.9961553	Time  0.295 ( 0.320)	Data  0.000 ( 0.004)	Loss 3.5245e+00 (3.7068e+00)	Loss_base 1.4598e+00 (1.6292e+00)	Loss_inst 7.1356e-01 (7.9108e-01)	Loss_obj 7.4624e-01 (8.3815e-01)	Loss_clu 4.1294e+00 (4.1551e+00)
Epoch: [0/1]	[ 349/2756]	LR 1.8000000	MOM 0.9961562	Time  0.293 ( 0.320)	Data  0.000 ( 0.004)	Loss 3.4043e+00 (3.7059e+00)	Loss_base 1.3388e+00 (1.6284e+00)	Loss_inst 6.5042e-01 (7.9067e-01)	Loss_obj 6.8834e-01 (8.3772e-01)	Loss_clu 4.1310e+00 (4.1550e+00)
Epoch: [0/1]	[ 350/2756]	LR 1.8000000	MOM 0.9961571	Time  0.294 ( 0.320)	Data  0.000 ( 0.003)	Loss 3.3160e+00 (3.7048e+00)	Loss_base 1.2523e+00 (1.6273e+00)	Loss_inst 6.0680e-01 (7.9015e-01)	Loss_obj 6.4554e-01 (8.3717e-01)	Loss_clu 4.1273e+00 (4.1550e+00)
Epoch: [0/1]	[ 351/2756]	LR 1.8000000	MOM 0.9961580	Time  0.294 ( 0.319)	Data  0.000 ( 0.003)	Loss 3.3341e+00 (3.7038e+00)	Loss_base 1.2719e+00 (1.6263e+00)	Loss_inst 6.2138e-01 (7.8967e-01)	Loss_obj 6.5052e-01 (8.3664e-01)	Loss_clu 4.1244e+00 (4.1549e+00)
Epoch: [0/1]	[ 352/2756]	LR 1.8000000	MOM 0.9961589	Time  0.294 ( 0.319)	Data  0.000 ( 0.003)	Loss 3.5477e+00 (3.7033e+00)	Loss_base 1.4833e+00 (1.6259e+00)	Loss_inst 7.2091e-01 (7.8948e-01)	Loss_obj 7.6240e-01 (8.3643e-01)	Loss_clu 4.1288e+00 (4.1548e+00)
Epoch: [0/1]	[ 353/2756]	LR 1.8000000	MOM 0.9961597	Time  0.295 ( 0.319)	Data  0.000 ( 0.003)	Loss 3.6398e+00 (3.7031e+00)	Loss_base 1.5751e+00 (1.6258e+00)	Loss_inst 7.6755e-01 (7.8941e-01)	Loss_obj 8.0757e-01 (8.3635e-01)	Loss_clu 4.1293e+00 (4.1547e+00)
Epoch: [0/1]	[ 354/2756]	LR 1.8000000	MOM 0.9961606	Time  0.299 ( 0.319)	Data  0.000 ( 0.003)	Loss 3.3389e+00 (3.7021e+00)	Loss_base 1.2744e+00 (1.6248e+00)	Loss_inst 6.1935e-01 (7.8893e-01)	Loss_obj 6.5508e-01 (8.3584e-01)	Loss_clu 4.1290e+00 (4.1547e+00)
Epoch: [0/1]	[ 355/2756]	LR 1.8000000	MOM 0.9961615	Time  0.300 ( 0.319)	Data  0.000 ( 0.003)	Loss 3.4391e+00 (3.7014e+00)	Loss_base 1.3775e+00 (1.6241e+00)	Loss_inst 6.7011e-01 (7.8860e-01)	Loss_obj 7.0741e-01 (8.3548e-01)	Loss_clu 4.1231e+00 (4.1546e+00)
Epoch: [0/1]	[ 356/2756]	LR 1.8000000	MOM 0.9961624	Time  0.314 ( 0.319)	Data  0.000 ( 0.003)	Loss 3.2679e+00 (3.7002e+00)	Loss_base 1.2046e+00 (1.6229e+00)	Loss_inst 5.8734e-01 (7.8804e-01)	Loss_obj 6.1727e-01 (8.3487e-01)	Loss_clu 4.1266e+00 (4.1545e+00)
Epoch: [0/1]	[ 357/2756]	LR 1.8000000	MOM 0.9961633	Time  0.298 ( 0.319)	Data  0.000 ( 0.003)	Loss 3.3410e+00 (3.6992e+00)	Loss_base 1.2784e+00 (1.6219e+00)	Loss_inst 6.2176e-01 (7.8757e-01)	Loss_obj 6.5664e-01 (8.3437e-01)	Loss_clu 4.1252e+00 (4.1544e+00)
Epoch: [0/1]	[ 358/2756]	LR 1.8000000	MOM 0.9961642	Time  0.303 ( 0.319)	Data  0.000 ( 0.003)	Loss 3.1160e+00 (3.6975e+00)	Loss_base 1.0535e+00 (1.6204e+00)	Loss_inst 5.1142e-01 (7.8680e-01)	Loss_obj 5.4206e-01 (8.3356e-01)	Loss_clu 4.1251e+00 (4.1543e+00)
Epoch: [0/1]	[ 359/2756]	LR 1.8000000	MOM 0.9961651	Time  0.304 ( 0.319)	Data  0.000 ( 0.003)	Loss 3.3237e+00 (3.6965e+00)	Loss_base 1.2629e+00 (1.6194e+00)	Loss_inst 6.1291e-01 (7.8632e-01)	Loss_obj 6.4998e-01 (8.3305e-01)	Loss_clu 4.1215e+00 (4.1542e+00)
Epoch: [0/1]	[ 360/2756]	LR 1.8000000	MOM 0.9961661	Time  0.302 ( 0.319)	Data  0.000 ( 0.003)	Loss 3.3362e+00 (3.6955e+00)	Loss_base 1.2723e+00 (1.6184e+00)	Loss_inst 6.1882e-01 (7.8586e-01)	Loss_obj 6.5344e-01 (8.3255e-01)	Loss_clu 4.1279e+00 (4.1542e+00)
Epoch: [0/1]	[ 361/2756]	LR 1.8000000	MOM 0.9961670	Time  0.304 ( 0.319)	Data  0.000 ( 0.003)	Loss 3.4370e+00 (3.6948e+00)	Loss_base 1.3793e+00 (1.6177e+00)	Loss_inst 6.7206e-01 (7.8554e-01)	Loss_obj 7.0728e-01 (8.3220e-01)	Loss_clu 4.1152e+00 (4.1541e+00)
Epoch: [0/1]	[ 362/2756]	LR 1.8000000	MOM 0.9961679	Time  0.304 ( 0.319)	Data  0.000 ( 0.003)	Loss 3.3128e+00 (3.6937e+00)	Loss_base 1.2517e+00 (1.6167e+00)	Loss_inst 6.0683e-01 (7.8505e-01)	Loss_obj 6.4491e-01 (8.3169e-01)	Loss_clu 4.1221e+00 (4.1540e+00)
Epoch: [0/1]	[ 363/2756]	LR 1.8000000	MOM 0.9961688	Time  0.306 ( 0.319)	Data  0.000 ( 0.003)	Loss 3.3418e+00 (3.6928e+00)	Loss_base 1.2810e+00 (1.6158e+00)	Loss_inst 6.2388e-01 (7.8461e-01)	Loss_obj 6.5707e-01 (8.3121e-01)	Loss_clu 4.1217e+00 (4.1539e+00)
Epoch: [0/1]	[ 364/2756]	LR 1.8000000	MOM 0.9961697	Time  0.304 ( 0.319)	Data  0.000 ( 0.003)	Loss 3.2358e+00 (3.6915e+00)	Loss_base 1.1790e+00 (1.6146e+00)	Loss_inst 5.7453e-01 (7.8403e-01)	Loss_obj 6.0445e-01 (8.3059e-01)	Loss_clu 4.1137e+00 (4.1538e+00)
Epoch: [0/1]	[ 365/2756]	LR 1.8000000	MOM 0.9961706	Time  0.298 ( 0.319)	Data  0.000 ( 0.003)	Loss 3.3790e+00 (3.6907e+00)	Loss_base 1.3162e+00 (1.6138e+00)	Loss_inst 6.3979e-01 (7.8364e-01)	Loss_obj 6.7641e-01 (8.3016e-01)	Loss_clu 4.1256e+00 (4.1537e+00)
Epoch: [0/1]	[ 366/2756]	LR 1.8000000	MOM 0.9961716	Time  0.305 ( 0.319)	Data  0.000 ( 0.003)	Loss 3.3352e+00 (3.6897e+00)	Loss_base 1.2728e+00 (1.6129e+00)	Loss_inst 6.2145e-01 (7.8320e-01)	Loss_obj 6.5137e-01 (8.2968e-01)	Loss_clu 4.1248e+00 (4.1536e+00)
Epoch: [0/1]	[ 367/2756]	LR 1.8000000	MOM 0.9961725	Time  0.307 ( 0.319)	Data  0.000 ( 0.003)	Loss 3.3643e+00 (3.6888e+00)	Loss_base 1.3024e+00 (1.6120e+00)	Loss_inst 6.3563e-01 (7.8279e-01)	Loss_obj 6.6672e-01 (8.2923e-01)	Loss_clu 4.1239e+00 (4.1535e+00)
Epoch: [0/1]	[ 368/2756]	LR 1.8000000	MOM 0.9961734	Time  0.304 ( 0.319)	Data  0.000 ( 0.003)	Loss 3.2505e+00 (3.6876e+00)	Loss_base 1.1911e+00 (1.6109e+00)	Loss_inst 5.8014e-01 (7.8225e-01)	Loss_obj 6.1094e-01 (8.2864e-01)	Loss_clu 4.1189e+00 (4.1534e+00)
Epoch: [0/1]	[ 369/2756]	LR 1.8000000	MOM 0.9961743	Time  0.295 ( 0.319)	Data  0.000 ( 0.003)	Loss 3.4405e+00 (3.6869e+00)	Loss_base 1.3808e+00 (1.6103e+00)	Loss_inst 6.7463e-01 (7.8195e-01)	Loss_obj 7.0621e-01 (8.2831e-01)	Loss_clu 4.1192e+00 (4.1534e+00)
Epoch: [0/1]	[ 370/2756]	LR 1.8000000	MOM 0.9961753	Time  0.295 ( 0.319)	Data  0.000 ( 0.003)	Loss 3.1765e+00 (3.6856e+00)	Loss_base 1.1181e+00 (1.6089e+00)	Loss_inst 5.4417e-01 (7.8131e-01)	Loss_obj 5.7391e-01 (8.2763e-01)	Loss_clu 4.1168e+00 (4.1533e+00)
Epoch: [0/1]	[ 371/2756]	LR 1.8000000	MOM 0.9961762	Time  0.295 ( 0.318)	Data  0.000 ( 0.003)	Loss 3.1571e+00 (3.6841e+00)	Loss_base 1.0961e+00 (1.6076e+00)	Loss_inst 5.3234e-01 (7.8064e-01)	Loss_obj 5.6374e-01 (8.2692e-01)	Loss_clu 4.1221e+00 (4.1532e+00)
Epoch: [0/1]	[ 372/2756]	LR 1.8000000	MOM 0.9961771	Time  0.295 ( 0.318)	Data  0.000 ( 0.003)	Loss 3.0926e+00 (3.6826e+00)	Loss_base 1.0322e+00 (1.6060e+00)	Loss_inst 5.0101e-01 (7.7989e-01)	Loss_obj 5.3116e-01 (8.2612e-01)	Loss_clu 4.1208e+00 (4.1531e+00)
Epoch: [0/1]	[ 373/2756]	LR 1.8000000	MOM 0.9961781	Time  0.295 ( 0.318)	Data  0.000 ( 0.003)	Loss 3.3681e+00 (3.6817e+00)	Loss_base 1.3051e+00 (1.6052e+00)	Loss_inst 6.3761e-01 (7.7951e-01)	Loss_obj 6.6753e-01 (8.2570e-01)	Loss_clu 4.1259e+00 (4.1530e+00)
Epoch: [0/1]	[ 374/2756]	LR 1.8000000	MOM 0.9961790	Time  0.292 ( 0.318)	Data  0.000 ( 0.003)	Loss 3.3210e+00 (3.6808e+00)	Loss_base 1.2589e+00 (1.6043e+00)	Loss_inst 6.1302e-01 (7.7907e-01)	Loss_obj 6.4584e-01 (8.2522e-01)	Loss_clu 4.1244e+00 (4.1529e+00)
Epoch: [0/1]	[ 375/2756]	LR 1.8000000	MOM 0.9961800	Time  0.298 ( 0.318)	Data  0.000 ( 0.003)	Loss 3.2563e+00 (3.6796e+00)	Loss_base 1.1957e+00 (1.6032e+00)	Loss_inst 5.8286e-01 (7.7855e-01)	Loss_obj 6.1283e-01 (8.2466e-01)	Loss_clu 4.1211e+00 (4.1529e+00)
Epoch: [0/1]	[ 376/2756]	LR 1.8000000	MOM 0.9961809	Time  0.293 ( 0.318)	Data  0.000 ( 0.003)	Loss 3.3071e+00 (3.6786e+00)	Loss_base 1.2464e+00 (1.6023e+00)	Loss_inst 6.0554e-01 (7.7809e-01)	Loss_obj 6.4090e-01 (8.2417e-01)	Loss_clu 4.1213e+00 (4.1528e+00)
Epoch: [0/1]	[ 377/2756]	LR 1.8000000	MOM 0.9961819	Time  0.303 ( 0.318)	Data  0.000 ( 0.003)	Loss 3.4096e+00 (3.6779e+00)	Loss_base 1.3506e+00 (1.6016e+00)	Loss_inst 6.5739e-01 (7.7777e-01)	Loss_obj 6.9324e-01 (8.2382e-01)	Loss_clu 4.1179e+00 (4.1527e+00)
Epoch: [0/1]	[ 378/2756]	LR 1.8000000	MOM 0.9961828	Time  0.296 ( 0.318)	Data  0.000 ( 0.003)	Loss 3.2089e+00 (3.6767e+00)	Loss_base 1.1480e+00 (1.6004e+00)	Loss_inst 5.5738e-01 (7.7719e-01)	Loss_obj 5.9063e-01 (8.2321e-01)	Loss_clu 4.1218e+00 (4.1526e+00)
Epoch: [0/1]	[ 379/2756]	LR 1.8000000	MOM 0.9961838	Time  0.293 ( 0.318)	Data  0.000 ( 0.003)	Loss 3.5843e+00 (3.6764e+00)	Loss_base 1.5232e+00 (1.6002e+00)	Loss_inst 7.4330e-01 (7.7710e-01)	Loss_obj 7.7995e-01 (8.2309e-01)	Loss_clu 4.1220e+00 (4.1525e+00)
Epoch: [0/1]	[ 380/2756]	LR 1.8000000	MOM 0.9961847	Time  0.310 ( 0.318)	Data  0.000 ( 0.003)	Loss 3.1860e+00 (3.6752e+00)	Loss_base 1.1262e+00 (1.5989e+00)	Loss_inst 5.4682e-01 (7.7650e-01)	Loss_obj 5.7940e-01 (8.2245e-01)	Loss_clu 4.1196e+00 (4.1524e+00)
Epoch: [0/1]	[ 381/2756]	LR 1.8000000	MOM 0.9961857	Time  0.307 ( 0.318)	Data  0.000 ( 0.003)	Loss 3.2566e+00 (3.6741e+00)	Loss_base 1.2006e+00 (1.5979e+00)	Loss_inst 5.8675e-01 (7.7600e-01)	Loss_obj 6.1381e-01 (8.2191e-01)	Loss_clu 4.1120e+00 (4.1523e+00)
Epoch: [0/1]	[ 382/2756]	LR 1.8000000	MOM 0.9961866	Time  0.304 ( 0.318)	Data  0.000 ( 0.003)	Loss 3.2297e+00 (3.6729e+00)	Loss_base 1.1741e+00 (1.5968e+00)	Loss_inst 5.6944e-01 (7.7546e-01)	Loss_obj 6.0466e-01 (8.2134e-01)	Loss_clu 4.1112e+00 (4.1522e+00)
Epoch: [0/1]	[ 383/2756]	LR 1.8000000	MOM 0.9961876	Time  0.303 ( 0.318)	Data  0.000 ( 0.003)	Loss 3.4033e+00 (3.6722e+00)	Loss_base 1.3481e+00 (1.5962e+00)	Loss_inst 6.5938e-01 (7.7516e-01)	Loss_obj 6.8872e-01 (8.2099e-01)	Loss_clu 4.1104e+00 (4.1521e+00)
Epoch: [0/1]	[ 384/2756]	LR 1.8000000	MOM 0.9961886	Time  0.294 ( 0.318)	Data  0.000 ( 0.003)	Loss 3.1537e+00 (3.6709e+00)	Loss_base 1.0996e+00 (1.5949e+00)	Loss_inst 5.3558e-01 (7.7453e-01)	Loss_obj 5.6404e-01 (8.2033e-01)	Loss_clu 4.1082e+00 (4.1520e+00)
Epoch: [0/1]	[ 385/2756]	LR 1.8000000	MOM 0.9961895	Time  0.294 ( 0.318)	Data  0.000 ( 0.003)	Loss 3.4163e+00 (3.6702e+00)	Loss_base 1.3625e+00 (1.5943e+00)	Loss_inst 6.6581e-01 (7.7425e-01)	Loss_obj 6.9669e-01 (8.2001e-01)	Loss_clu 4.1077e+00 (4.1519e+00)
Epoch: [0/1]	[ 386/2756]	LR 1.8000000	MOM 0.9961905	Time  0.301 ( 0.318)	Data  0.000 ( 0.003)	Loss 3.1166e+00 (3.6688e+00)	Loss_base 1.0628e+00 (1.5929e+00)	Loss_inst 5.1650e-01 (7.7359e-01)	Loss_obj 5.4633e-01 (8.1930e-01)	Loss_clu 4.1076e+00 (4.1518e+00)
Epoch: [0/1]	[ 387/2756]	LR 1.8000000	MOM 0.9961915	Time  0.306 ( 0.318)	Data  0.000 ( 0.003)	Loss 3.1277e+00 (3.6674e+00)	Loss_base 1.0745e+00 (1.5916e+00)	Loss_inst 5.2132e-01 (7.7294e-01)	Loss_obj 5.5315e-01 (8.1861e-01)	Loss_clu 4.1065e+00 (4.1516e+00)
Epoch: [0/1]	[ 388/2756]	LR 1.8000000	MOM 0.9961924	Time  0.303 ( 0.318)	Data  0.000 ( 0.003)	Loss 3.3421e+00 (3.6665e+00)	Loss_base 1.2941e+00 (1.5908e+00)	Loss_inst 6.3121e-01 (7.7257e-01)	Loss_obj 6.6285e-01 (8.1821e-01)	Loss_clu 4.0960e+00 (4.1515e+00)
Epoch: [0/1]	[ 389/2756]	LR 1.8000000	MOM 0.9961934	Time  0.304 ( 0.318)	Data  0.000 ( 0.003)	Loss 3.3480e+00 (3.6657e+00)	Loss_base 1.2957e+00 (1.5900e+00)	Loss_inst 6.3071e-01 (7.7221e-01)	Loss_obj 6.6504e-01 (8.1782e-01)	Loss_clu 4.1046e+00 (4.1514e+00)
Epoch: [0/1]	[ 390/2756]	LR 1.8000000	MOM 0.9961944	Time  0.307 ( 0.318)	Data  0.000 ( 0.003)	Loss 3.4315e+00 (3.6651e+00)	Loss_base 1.3798e+00 (1.5895e+00)	Loss_inst 6.7294e-01 (7.7195e-01)	Loss_obj 7.0681e-01 (8.1754e-01)	Loss_clu 4.1035e+00 (4.1513e+00)
Epoch: [0/1]	[ 391/2756]	LR 1.8000000	MOM 0.9961954	Time  0.297 ( 0.318)	Data  0.000 ( 0.003)	Loss 3.5743e+00 (3.6649e+00)	Loss_base 1.5228e+00 (1.5893e+00)	Loss_inst 7.4351e-01 (7.7188e-01)	Loss_obj 7.7925e-01 (8.1744e-01)	Loss_clu 4.1030e+00 (4.1511e+00)
Epoch: [0/1]	[ 392/2756]	LR 1.8000000	MOM 0.9961964	Time  0.294 ( 0.317)	Data  0.000 ( 0.003)	Loss 3.3494e+00 (3.6641e+00)	Loss_base 1.3004e+00 (1.5886e+00)	Loss_inst 6.3844e-01 (7.7154e-01)	Loss_obj 6.6194e-01 (8.1704e-01)	Loss_clu 4.0981e+00 (4.1510e+00)
Epoch: [0/1]	[ 393/2756]	LR 1.8000000	MOM 0.9961974	Time  0.292 ( 0.317)	Data  0.000 ( 0.003)	Loss 3.3385e+00 (3.6633e+00)	Loss_base 1.2905e+00 (1.5878e+00)	Loss_inst 6.2927e-01 (7.7118e-01)	Loss_obj 6.6121e-01 (8.1665e-01)	Loss_clu 4.0961e+00 (4.1509e+00)
Epoch: [0/1]	[ 394/2756]	LR 1.8000000	MOM 0.9961983	Time  0.295 ( 0.317)	Data  0.000 ( 0.003)	Loss 3.7048e+00 (3.6634e+00)	Loss_base 1.6585e+00 (1.5880e+00)	Loss_inst 8.1376e-01 (7.7129e-01)	Loss_obj 8.4478e-01 (8.1672e-01)	Loss_clu 4.0925e+00 (4.1507e+00)
Epoch: [0/1]	[ 395/2756]	LR 1.8000000	MOM 0.9961993	Time  0.298 ( 0.317)	Data  0.000 ( 0.003)	Loss 3.7205e+00 (3.6635e+00)	Loss_base 1.6720e+00 (1.5882e+00)	Loss_inst 8.1722e-01 (7.7141e-01)	Loss_obj 8.5481e-01 (8.1681e-01)	Loss_clu 4.0970e+00 (4.1506e+00)
Epoch: [0/1]	[ 396/2756]	LR 1.8000000	MOM 0.9962003	Time  0.295 ( 0.317)	Data  0.000 ( 0.003)	Loss 3.1103e+00 (3.6621e+00)	Loss_base 1.0654e+00 (1.5869e+00)	Loss_inst 5.1936e-01 (7.7077e-01)	Loss_obj 5.4608e-01 (8.1613e-01)	Loss_clu 4.0898e+00 (4.1504e+00)
Epoch: [0/1]	[ 397/2756]	LR 1.8000000	MOM 0.9962013	Time  0.306 ( 0.317)	Data  0.000 ( 0.003)	Loss 3.1906e+00 (3.6609e+00)	Loss_base 1.1357e+00 (1.5858e+00)	Loss_inst 5.5785e-01 (7.7024e-01)	Loss_obj 5.7782e-01 (8.1553e-01)	Loss_clu 4.1098e+00 (4.1503e+00)
Epoch: [0/1]	[ 398/2756]	LR 1.8000000	MOM 0.9962023	Time  0.294 ( 0.317)	Data  0.000 ( 0.003)	Loss 3.3479e+00 (3.6601e+00)	Loss_base 1.3027e+00 (1.5851e+00)	Loss_inst 6.3826e-01 (7.6990e-01)	Loss_obj 6.6444e-01 (8.1516e-01)	Loss_clu 4.0905e+00 (4.1502e+00)
Epoch: [0/1]	[ 399/2756]	LR 1.8000000	MOM 0.9962033	Time  0.296 ( 0.317)	Data  0.000 ( 0.003)	Loss 3.1772e+00 (3.6589e+00)	Loss_base 1.1345e+00 (1.5839e+00)	Loss_inst 5.5374e-01 (7.6936e-01)	Loss_obj 5.8078e-01 (8.1457e-01)	Loss_clu 4.0853e+00 (4.1500e+00)
Epoch: [0/1]	[ 400/2756]	LR 1.8000000	MOM 0.9962043	Time  0.294 ( 0.317)	Data  0.000 ( 0.003)	Loss 3.2765e+00 (3.6580e+00)	Loss_base 1.2256e+00 (1.5830e+00)	Loss_inst 6.0120e-01 (7.6894e-01)	Loss_obj 6.2442e-01 (8.1410e-01)	Loss_clu 4.1018e+00 (4.1499e+00)
Epoch: [0/1]	[ 401/2756]	LR 1.8000000	MOM 0.9962053	Time  0.297 ( 0.317)	Data  0.000 ( 0.003)	Loss 3.3904e+00 (3.6573e+00)	Loss_base 1.3484e+00 (1.5825e+00)	Loss_inst 6.6267e-01 (7.6868e-01)	Loss_obj 6.8572e-01 (8.1378e-01)	Loss_clu 4.0841e+00 (4.1497e+00)
Epoch: [0/1]	[ 402/2756]	LR 1.8000000	MOM 0.9962063	Time  0.299 ( 0.317)	Data  0.000 ( 0.003)	Loss 3.4588e+00 (3.6568e+00)	Loss_base 1.4187e+00 (1.5821e+00)	Loss_inst 6.9663e-01 (7.6850e-01)	Loss_obj 7.2211e-01 (8.1355e-01)	Loss_clu 4.0801e+00 (4.1496e+00)
Epoch: [0/1]	[ 403/2756]	LR 1.8000000	MOM 0.9962073	Time  0.293 ( 0.317)	Data  0.000 ( 0.003)	Loss 3.4607e+00 (3.6563e+00)	Loss_base 1.4211e+00 (1.5817e+00)	Loss_inst 6.9361e-01 (7.6832e-01)	Loss_obj 7.2747e-01 (8.1334e-01)	Loss_clu 4.0793e+00 (4.1494e+00)
Epoch: [0/1]	[ 404/2756]	LR 1.8000000	MOM 0.9962084	Time  0.292 ( 0.317)	Data  0.000 ( 0.003)	Loss 3.2995e+00 (3.6555e+00)	Loss_base 1.2567e+00 (1.5808e+00)	Loss_inst 6.1415e-01 (7.6794e-01)	Loss_obj 6.4250e-01 (8.1291e-01)	Loss_clu 4.0857e+00 (4.1492e+00)
Epoch: [0/1]	[ 405/2756]	LR 1.8000000	MOM 0.9962094	Time  0.302 ( 0.317)	Data  0.000 ( 0.003)	Loss 3.3808e+00 (3.6548e+00)	Loss_base 1.3356e+00 (1.5802e+00)	Loss_inst 6.5374e-01 (7.6765e-01)	Loss_obj 6.8186e-01 (8.1259e-01)	Loss_clu 4.0903e+00 (4.1491e+00)
Epoch: [0/1]	[ 406/2756]	LR 1.8000000	MOM 0.9962104	Time  0.295 ( 0.317)	Data  0.000 ( 0.003)	Loss 3.2995e+00 (3.6539e+00)	Loss_base 1.2628e+00 (1.5795e+00)	Loss_inst 6.1856e-01 (7.6729e-01)	Loss_obj 6.4424e-01 (8.1218e-01)	Loss_clu 4.0734e+00 (4.1489e+00)
Epoch: [0/1]	[ 407/2756]	LR 1.8000000	MOM 0.9962114	Time  0.302 ( 0.317)	Data  0.000 ( 0.003)	Loss 3.3969e+00 (3.6533e+00)	Loss_base 1.3542e+00 (1.5789e+00)	Loss_inst 6.6192e-01 (7.6703e-01)	Loss_obj 6.9224e-01 (8.1188e-01)	Loss_clu 4.0855e+00 (4.1487e+00)
Epoch: [0/1]	[ 408/2756]	LR 1.8000000	MOM 0.9962124	Time  0.298 ( 0.317)	Data  0.000 ( 0.003)	Loss 3.4377e+00 (3.6528e+00)	Loss_base 1.4008e+00 (1.5785e+00)	Loss_inst 6.8577e-01 (7.6683e-01)	Loss_obj 7.1503e-01 (8.1165e-01)	Loss_clu 4.0738e+00 (4.1486e+00)
Epoch: [0/1]	[ 409/2756]	LR 1.8000000	MOM 0.9962135	Time  0.301 ( 0.317)	Data  0.000 ( 0.003)	Loss 3.4114e+00 (3.6522e+00)	Loss_base 1.3732e+00 (1.5780e+00)	Loss_inst 6.7448e-01 (7.6661e-01)	Loss_obj 6.9871e-01 (8.1137e-01)	Loss_clu 4.0765e+00 (4.1484e+00)
Epoch: [0/1]	[ 410/2756]	LR 1.8000000	MOM 0.9962145	Time  0.297 ( 0.317)	Data  0.000 ( 0.003)	Loss 3.3822e+00 (3.6515e+00)	Loss_base 1.3387e+00 (1.5774e+00)	Loss_inst 6.5730e-01 (7.6634e-01)	Loss_obj 6.8141e-01 (8.1105e-01)	Loss_clu 4.0870e+00 (4.1482e+00)
Epoch: [0/1]	[ 411/2756]	LR 1.8000000	MOM 0.9962155	Time  0.293 ( 0.317)	Data  0.000 ( 0.003)	Loss 3.2212e+00 (3.6505e+00)	Loss_base 1.1823e+00 (1.5764e+00)	Loss_inst 5.7706e-01 (7.6588e-01)	Loss_obj 6.0523e-01 (8.1056e-01)	Loss_clu 4.0779e+00 (4.1481e+00)
Epoch: [0/1]	[ 412/2756]	LR 1.8000000	MOM 0.9962165	Time  0.296 ( 0.316)	Data  0.000 ( 0.003)	Loss 3.2428e+00 (3.6495e+00)	Loss_base 1.2047e+00 (1.5755e+00)	Loss_inst 5.9003e-01 (7.6545e-01)	Loss_obj 6.1467e-01 (8.1008e-01)	Loss_clu 4.0761e+00 (4.1479e+00)
Epoch: [0/1]	[ 413/2756]	LR 1.8000000	MOM 0.9962176	Time  0.305 ( 0.316)	Data  0.000 ( 0.003)	Loss 3.2025e+00 (3.6484e+00)	Loss_base 1.1588e+00 (1.5745e+00)	Loss_inst 5.6789e-01 (7.6498e-01)	Loss_obj 5.9095e-01 (8.0955e-01)	Loss_clu 4.0873e+00 (4.1477e+00)
Epoch: [0/1]	[ 414/2756]	LR 1.8000000	MOM 0.9962186	Time  0.297 ( 0.316)	Data  0.000 ( 0.003)	Loss 3.2937e+00 (3.6475e+00)	Loss_base 1.2382e+00 (1.5737e+00)	Loss_inst 6.0593e-01 (7.6459e-01)	Loss_obj 6.3226e-01 (8.0912e-01)	Loss_clu 4.1111e+00 (4.1476e+00)
Epoch: [0/1]	[ 415/2756]	LR 1.8000000	MOM 0.9962196	Time  0.304 ( 0.316)	Data  0.000 ( 0.003)	Loss 3.6013e+00 (3.6474e+00)	Loss_base 1.5639e+00 (1.5737e+00)	Loss_inst 7.6872e-01 (7.6460e-01)	Loss_obj 7.9523e-01 (8.0909e-01)	Loss_clu 4.0748e+00 (4.1475e+00)
Epoch: [0/1]	[ 416/2756]	LR 1.8000000	MOM 0.9962207	Time  0.294 ( 0.316)	Data  0.000 ( 0.003)	Loss 3.2525e+00 (3.6465e+00)	Loss_base 1.1983e+00 (1.5728e+00)	Loss_inst 5.8530e-01 (7.6417e-01)	Loss_obj 6.1304e-01 (8.0862e-01)	Loss_clu 4.1084e+00 (4.1474e+00)
Epoch: [0/1]	[ 417/2756]	LR 1.8000000	MOM 0.9962217	Time  0.295 ( 0.316)	Data  0.000 ( 0.003)	Loss 3.2543e+00 (3.6455e+00)	Loss_base 1.2123e+00 (1.5719e+00)	Loss_inst 5.9286e-01 (7.6376e-01)	Loss_obj 6.1942e-01 (8.0817e-01)	Loss_clu 4.0841e+00 (4.1472e+00)
Epoch: [0/1]	[ 418/2756]	LR 1.8000000	MOM 0.9962228	Time  0.299 ( 0.316)	Data  0.000 ( 0.003)	Loss 3.3178e+00 (3.6448e+00)	Loss_base 1.2717e+00 (1.5712e+00)	Loss_inst 6.2616e-01 (7.6344e-01)	Loss_obj 6.4557e-01 (8.0778e-01)	Loss_clu 4.0921e+00 (4.1471e+00)
Epoch: [0/1]	[ 419/2756]	LR 1.8000000	MOM 0.9962238	Time  0.296 ( 0.316)	Data  0.000 ( 0.003)	Loss 3.1439e+00 (3.6436e+00)	Loss_base 1.1004e+00 (1.5701e+00)	Loss_inst 5.3766e-01 (7.6290e-01)	Loss_obj 5.6269e-01 (8.0720e-01)	Loss_clu 4.0870e+00 (4.1470e+00)
Epoch: [0/1]	[ 420/2756]	LR 1.8000000	MOM 0.9962249	Time  0.297 ( 0.316)	Data  0.000 ( 0.003)	Loss 3.3508e+00 (3.6429e+00)	Loss_base 1.3062e+00 (1.5695e+00)	Loss_inst 6.4161e-01 (7.6261e-01)	Loss_obj 6.6464e-01 (8.0686e-01)	Loss_clu 4.0891e+00 (4.1468e+00)
Epoch: [0/1]	[ 421/2756]	LR 1.8000000	MOM 0.9962259	Time  0.304 ( 0.316)	Data  0.000 ( 0.003)	Loss 3.2289e+00 (3.6419e+00)	Loss_base 1.1873e+00 (1.5686e+00)	Loss_inst 5.8124e-01 (7.6218e-01)	Loss_obj 6.0607e-01 (8.0638e-01)	Loss_clu 4.0832e+00 (4.1467e+00)
Epoch: [0/1]	[ 422/2756]	LR 1.8000000	MOM 0.9962270	Time  0.294 ( 0.316)	Data  0.000 ( 0.003)	Loss 3.2286e+00 (3.6409e+00)	Loss_base 1.1916e+00 (1.5677e+00)	Loss_inst 5.8428e-01 (7.6176e-01)	Loss_obj 6.0732e-01 (8.0591e-01)	Loss_clu 4.0740e+00 (4.1465e+00)
Epoch: [0/1]	[ 423/2756]	LR 1.8000000	MOM 0.9962280	Time  0.302 ( 0.316)	Data  0.000 ( 0.003)	Loss 3.0849e+00 (3.6396e+00)	Loss_base 1.0469e+00 (1.5664e+00)	Loss_inst 5.1610e-01 (7.6118e-01)	Loss_obj 5.3080e-01 (8.0526e-01)	Loss_clu 4.0761e+00 (4.1463e+00)
Epoch: [0/1]	[ 424/2756]	LR 1.8000000	MOM 0.9962291	Time  0.294 ( 0.316)	Data  0.000 ( 0.003)	Loss 3.4343e+00 (3.6391e+00)	Loss_base 1.4021e+00 (1.5661e+00)	Loss_inst 6.8797e-01 (7.6101e-01)	Loss_obj 7.1416e-01 (8.0505e-01)	Loss_clu 4.0643e+00 (4.1461e+00)
Epoch: [0/1]	[ 425/2756]	LR 1.8000000	MOM 0.9962301	Time  0.302 ( 0.316)	Data  0.000 ( 0.003)	Loss 3.1401e+00 (3.6380e+00)	Loss_base 1.1010e+00 (1.5650e+00)	Loss_inst 5.3693e-01 (7.6048e-01)	Loss_obj 5.6402e-01 (8.0448e-01)	Loss_clu 4.0782e+00 (4.1460e+00)
Epoch: [0/1]	[ 426/2756]	LR 1.8000000	MOM 0.9962312	Time  0.293 ( 0.316)	Data  0.000 ( 0.003)	Loss 3.2647e+00 (3.6371e+00)	Loss_base 1.2234e+00 (1.5642e+00)	Loss_inst 6.0426e-01 (7.6012e-01)	Loss_obj 6.1910e-01 (8.0405e-01)	Loss_clu 4.0827e+00 (4.1458e+00)
Epoch: [0/1]	[ 427/2756]	LR 1.8000000	MOM 0.9962323	Time  0.296 ( 0.316)	Data  0.000 ( 0.003)	Loss 3.2737e+00 (3.6362e+00)	Loss_base 1.2431e+00 (1.5634e+00)	Loss_inst 6.0772e-01 (7.5976e-01)	Loss_obj 6.3540e-01 (8.0365e-01)	Loss_clu 4.0611e+00 (4.1456e+00)
Epoch: [0/1]	[ 428/2756]	LR 1.8000000	MOM 0.9962333	Time  0.297 ( 0.316)	Data  0.000 ( 0.003)	Loss 3.5395e+00 (3.6360e+00)	Loss_base 1.5077e+00 (1.5633e+00)	Loss_inst 7.3511e-01 (7.5970e-01)	Loss_obj 7.7255e-01 (8.0358e-01)	Loss_clu 4.0636e+00 (4.1454e+00)
Epoch: [0/1]	[ 429/2756]	LR 1.8000000	MOM 0.9962344	Time  0.297 ( 0.316)	Data  0.000 ( 0.003)	Loss 3.2873e+00 (3.6352e+00)	Loss_base 1.2586e+00 (1.5626e+00)	Loss_inst 6.1650e-01 (7.5937e-01)	Loss_obj 6.4209e-01 (8.0321e-01)	Loss_clu 4.0575e+00 (4.1452e+00)
Epoch: [0/1]	[ 430/2756]	LR 1.8000000	MOM 0.9962355	Time  0.293 ( 0.316)	Data  0.000 ( 0.003)	Loss 3.1834e+00 (3.6341e+00)	Loss_base 1.1504e+00 (1.5616e+00)	Loss_inst 5.6530e-01 (7.5892e-01)	Loss_obj 5.8514e-01 (8.0270e-01)	Loss_clu 4.0660e+00 (4.1450e+00)
Epoch: [0/1]	[ 431/2756]	LR 1.8000000	MOM 0.9962366	Time  0.298 ( 0.316)	Data  0.000 ( 0.003)	Loss 3.2688e+00 (3.6333e+00)	Loss_base 1.2445e+00 (1.5609e+00)	Loss_inst 6.1019e-01 (7.5858e-01)	Loss_obj 6.3430e-01 (8.0231e-01)	Loss_clu 4.0487e+00 (4.1448e+00)
Epoch: [0/1]	[ 432/2756]	LR 1.8000000	MOM 0.9962376	Time  0.292 ( 0.316)	Data  0.000 ( 0.003)	Loss 3.1243e+00 (3.6321e+00)	Loss_base 1.0961e+00 (1.5598e+00)	Loss_inst 5.3643e-01 (7.5806e-01)	Loss_obj 5.5968e-01 (8.0175e-01)	Loss_clu 4.0563e+00 (4.1446e+00)
Epoch: [0/1]	[ 433/2756]	LR 1.8000000	MOM 0.9962387	Time  0.304 ( 0.316)	Data  0.001 ( 0.003)	Loss 3.2326e+00 (3.6312e+00)	Loss_base 1.2006e+00 (1.5590e+00)	Loss_inst 5.9297e-01 (7.5768e-01)	Loss_obj 6.0767e-01 (8.0130e-01)	Loss_clu 4.0639e+00 (4.1444e+00)
Epoch: [0/1]	[ 434/2756]	LR 1.8000000	MOM 0.9962398	Time  0.298 ( 0.316)	Data  0.000 ( 0.003)	Loss 3.5533e+00 (3.6310e+00)	Loss_base 1.5320e+00 (1.5589e+00)	Loss_inst 7.5329e-01 (7.5767e-01)	Loss_obj 7.7875e-01 (8.0125e-01)	Loss_clu 4.0425e+00 (4.1442e+00)
Epoch: [0/1]	[ 435/2756]	LR 1.8000000	MOM 0.9962409	Time  0.301 ( 0.315)	Data  0.000 ( 0.003)	Loss 3.0965e+00 (3.6298e+00)	Loss_base 1.0711e+00 (1.5578e+00)	Loss_inst 5.2926e-01 (7.5715e-01)	Loss_obj 5.4185e-01 (8.0066e-01)	Loss_clu 4.0508e+00 (4.1440e+00)
Epoch: [0/1]	[ 436/2756]	LR 1.8000000	MOM 0.9962420	Time  0.294 ( 0.315)	Data  0.000 ( 0.003)	Loss 3.3917e+00 (3.6293e+00)	Loss_base 1.3703e+00 (1.5574e+00)	Loss_inst 6.7190e-01 (7.5695e-01)	Loss_obj 6.9835e-01 (8.0042e-01)	Loss_clu 4.0428e+00 (4.1438e+00)
Epoch: [0/1]	[ 437/2756]	LR 1.8000000	MOM 0.9962431	Time  0.292 ( 0.315)	Data  0.000 ( 0.003)	Loss 3.0503e+00 (3.6279e+00)	Loss_base 1.0271e+00 (1.5562e+00)	Loss_inst 5.0334e-01 (7.5637e-01)	Loss_obj 5.2373e-01 (7.9979e-01)	Loss_clu 4.0465e+00 (4.1435e+00)
Epoch: [0/1]	[ 438/2756]	LR 1.8000000	MOM 0.9962441	Time  0.292 ( 0.315)	Data  0.000 ( 0.003)	Loss 3.3176e+00 (3.6272e+00)	Loss_base 1.2837e+00 (1.5555e+00)	Loss_inst 6.2922e-01 (7.5608e-01)	Loss_obj 6.5444e-01 (7.9946e-01)	Loss_clu 4.0678e+00 (4.1434e+00)
Epoch: [0/1]	[ 439/2756]	LR 1.8000000	MOM 0.9962452	Time  0.298 ( 0.315)	Data  0.000 ( 0.003)	Loss 3.3222e+00 (3.6265e+00)	Loss_base 1.2978e+00 (1.5550e+00)	Loss_inst 6.3971e-01 (7.5582e-01)	Loss_obj 6.5806e-01 (7.9914e-01)	Loss_clu 4.0489e+00 (4.1431e+00)
Epoch: [0/1]	[ 440/2756]	LR 1.8000000	MOM 0.9962463	Time  0.294 ( 0.315)	Data  0.000 ( 0.003)	Loss 3.3632e+00 (3.6259e+00)	Loss_base 1.3436e+00 (1.5545e+00)	Loss_inst 6.6335e-01 (7.5561e-01)	Loss_obj 6.8022e-01 (7.9887e-01)	Loss_clu 4.0394e+00 (4.1429e+00)
Epoch: [0/1]	[ 441/2756]	LR 1.8000000	MOM 0.9962474	Time  0.292 ( 0.315)	Data  0.000 ( 0.003)	Loss 3.3473e+00 (3.6253e+00)	Loss_base 1.3247e+00 (1.5540e+00)	Loss_inst 6.4954e-01 (7.5537e-01)	Loss_obj 6.7512e-01 (7.9859e-01)	Loss_clu 4.0454e+00 (4.1427e+00)
Epoch: [0/1]	[ 442/2756]	LR 1.8000000	MOM 0.9962485	Time  0.296 ( 0.315)	Data  0.000 ( 0.003)	Loss 3.2054e+00 (3.6244e+00)	Loss_base 1.1839e+00 (1.5531e+00)	Loss_inst 5.8141e-01 (7.5498e-01)	Loss_obj 6.0244e-01 (7.9815e-01)	Loss_clu 4.0431e+00 (4.1425e+00)
Epoch: [0/1]	[ 443/2756]	LR 1.8000000	MOM 0.9962496	Time  0.305 ( 0.315)	Data  0.000 ( 0.003)	Loss 3.4268e+00 (3.6239e+00)	Loss_base 1.4077e+00 (1.5528e+00)	Loss_inst 6.9197e-01 (7.5484e-01)	Loss_obj 7.1572e-01 (7.9796e-01)	Loss_clu 4.0382e+00 (4.1422e+00)
Epoch: [0/1]	[ 444/2756]	LR 1.8000000	MOM 0.9962507	Time  0.298 ( 0.315)	Data  0.000 ( 0.003)	Loss 3.4797e+00 (3.6236e+00)	Loss_base 1.4644e+00 (1.5526e+00)	Loss_inst 7.1886e-01 (7.5475e-01)	Loss_obj 7.4552e-01 (7.9784e-01)	Loss_clu 4.0306e+00 (4.1420e+00)
Epoch: [0/1]	[ 445/2756]	LR 1.8000000	MOM 0.9962518	Time  0.298 ( 0.315)	Data  0.000 ( 0.003)	Loss 3.4515e+00 (3.6232e+00)	Loss_base 1.4408e+00 (1.5523e+00)	Loss_inst 7.1028e-01 (7.5465e-01)	Loss_obj 7.3048e-01 (7.9769e-01)	Loss_clu 4.0214e+00 (4.1417e+00)
Epoch: [0/1]	[ 446/2756]	LR 1.8000000	MOM 0.9962530	Time  0.292 ( 0.315)	Data  0.000 ( 0.003)	Loss 3.3709e+00 (3.6226e+00)	Loss_base 1.3564e+00 (1.5519e+00)	Loss_inst 6.6651e-01 (7.5446e-01)	Loss_obj 6.8985e-01 (7.9745e-01)	Loss_clu 4.0292e+00 (4.1415e+00)
Epoch: [0/1]	[ 447/2756]	LR 1.8000000	MOM 0.9962541	Time  0.300 ( 0.315)	Data  0.000 ( 0.003)	Loss 3.3664e+00 (3.6221e+00)	Loss_base 1.3418e+00 (1.5514e+00)	Loss_inst 6.5955e-01 (7.5425e-01)	Loss_obj 6.8226e-01 (7.9719e-01)	Loss_clu 4.0492e+00 (4.1413e+00)
Epoch: [0/1]	[ 448/2756]	LR 1.8000000	MOM 0.9962552	Time  0.295 ( 0.315)	Data  0.000 ( 0.003)	Loss 3.0206e+00 (3.6207e+00)	Loss_base 9.8629e-01 (1.5502e+00)	Loss_inst 4.8154e-01 (7.5364e-01)	Loss_obj 5.0476e-01 (7.9654e-01)	Loss_clu 4.0685e+00 (4.1411e+00)
Epoch: [0/1]	[ 449/2756]	LR 1.8000000	MOM 0.9962563	Time  0.304 ( 0.315)	Data  0.000 ( 0.003)	Loss 3.3961e+00 (3.6202e+00)	Loss_base 1.3838e+00 (1.5498e+00)	Loss_inst 6.7948e-01 (7.5347e-01)	Loss_obj 7.0427e-01 (7.9634e-01)	Loss_clu 4.0247e+00 (4.1408e+00)
Epoch: [0/1]	[ 450/2756]	LR 1.8000000	MOM 0.9962574	Time  0.296 ( 0.315)	Data  0.000 ( 0.003)	Loss 3.0418e+00 (3.6189e+00)	Loss_base 1.0202e+00 (1.5486e+00)	Loss_inst 4.9807e-01 (7.5291e-01)	Loss_obj 5.2208e-01 (7.9573e-01)	Loss_clu 4.0433e+00 (4.1406e+00)
Epoch: [0/1]	[ 451/2756]	LR 1.8000000	MOM 0.9962585	Time  0.296 ( 0.315)	Data  0.000 ( 0.003)	Loss 3.2817e+00 (3.6182e+00)	Loss_base 1.2713e+00 (1.5480e+00)	Loss_inst 6.2459e-01 (7.5262e-01)	Loss_obj 6.4674e-01 (7.9540e-01)	Loss_clu 4.0207e+00 (4.1403e+00)
Epoch: [0/1]	[ 452/2756]	LR 1.8000000	MOM 0.9962597	Time  0.304 ( 0.315)	Data  0.000 ( 0.003)	Loss 3.3907e+00 (3.6177e+00)	Loss_base 1.3794e+00 (1.5476e+00)	Loss_inst 6.7807e-01 (7.5246e-01)	Loss_obj 7.0136e-01 (7.9519e-01)	Loss_clu 4.0226e+00 (4.1401e+00)
Epoch: [0/1]	[ 453/2756]	LR 1.8000000	MOM 0.9962608	Time  0.296 ( 0.315)	Data  0.000 ( 0.003)	Loss 3.1609e+00 (3.6167e+00)	Loss_base 1.1431e+00 (1.5468e+00)	Loss_inst 5.5985e-01 (7.5203e-01)	Loss_obj 5.8324e-01 (7.9472e-01)	Loss_clu 4.0356e+00 (4.1399e+00)
Epoch: [0/1]	[ 454/2756]	LR 1.8000000	MOM 0.9962619	Time  0.292 ( 0.315)	Data  0.000 ( 0.003)	Loss 3.1597e+00 (3.6157e+00)	Loss_base 1.1400e+00 (1.5459e+00)	Loss_inst 5.6280e-01 (7.5162e-01)	Loss_obj 5.7725e-01 (7.9425e-01)	Loss_clu 4.0392e+00 (4.1396e+00)
Epoch: [0/1]	[ 455/2756]	LR 1.8000000	MOM 0.9962630	Time  0.304 ( 0.315)	Data  0.000 ( 0.003)	Loss 3.2780e+00 (3.6149e+00)	Loss_base 1.2578e+00 (1.5452e+00)	Loss_inst 6.1948e-01 (7.5133e-01)	Loss_obj 6.3831e-01 (7.9390e-01)	Loss_clu 4.0405e+00 (4.1394e+00)
Epoch: [0/1]	[ 456/2756]	LR 1.8000000	MOM 0.9962642	Time  0.291 ( 0.315)	Data  0.000 ( 0.003)	Loss 3.2667e+00 (3.6142e+00)	Loss_base 1.2574e+00 (1.5446e+00)	Loss_inst 6.1917e-01 (7.5104e-01)	Loss_obj 6.3818e-01 (7.9356e-01)	Loss_clu 4.0186e+00 (4.1392e+00)
